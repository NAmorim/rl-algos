{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a951a47f-88f5-40f0-8fe3-5495f76633b5",
   "metadata": {
    "id": "a951a47f-88f5-40f0-8fe3-5495f76633b5"
   },
   "source": [
    "# Install needed deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c89b3-be5c-49c6-bb0d-4fea729bddee",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Don't forget to run ```apt-get update --fix-missing && sudo apt-get install build-essential``` and ```apt-get install zlib1g-dev``` in case you are running on an Ubuntu image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bede9272-b231-4d56-97ef-e2e180cf0655",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "bede9272-b231-4d56-97ef-e2e180cf0655",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "82aa9af4-5352-4e8b-dafa-83b334765f71",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-ta==0.3.14b in ./.venv/lib/python3.8/site-packages (0.3.14b0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.8/site-packages (from pandas-ta==0.3.14b) (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.8/site-packages (from pandas->pandas-ta==0.3.14b) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in ./.venv/lib/python3.8/site-packages (from pandas->pandas-ta==0.3.14b) (1.22.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas->pandas-ta==0.3.14b) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->pandas-ta==0.3.14b) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gym==0.21.0 in ./.venv/lib/python3.8/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in ./.venv/lib/python3.8/site-packages (from gym==0.21.0) (1.22.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./.venv/lib/python3.8/site-packages (from gym==0.21.0) (1.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.8/site-packages (7.7.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in ./.venv/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in ./.venv/lib/python3.8/site-packages (from ipywidgets) (5.2.0)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in ./.venv/lib/python3.8/site-packages (from ipywidgets) (8.1.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in ./.venv/lib/python3.8/site-packages (from ipywidgets) (3.6.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in ./.venv/lib/python3.8/site-packages (from ipywidgets) (1.1.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in ./.venv/lib/python3.8/site-packages (from ipywidgets) (6.9.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jupyter-core in ./.venv/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in ./.venv/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (3.0.28)\n",
      "Requirement already satisfied: backcall in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (44.0.0)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: pickleshare in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: notebook>=4.4.1 in ./.venv/lib/python3.8/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.4.10)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in ./.venv/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in ./.venv/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: jupyter-client<8.0 in ./.venv/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.2)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.4)\n",
      "Requirement already satisfied: attrs>=17.4.0 in ./.venv/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in ./.venv/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0; python_version < \"3.9\" in ./.venv/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (5.6.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens in ./.venv/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: executing in ./.venv/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./.venv/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.8/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.1)\n",
      "Requirement already satisfied: nbconvert>=5 in ./.venv/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.4.4)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./.venv/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.3)\n",
      "Requirement already satisfied: argon2-cffi in ./.venv/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in ./.venv/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in ./.venv/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: pyzmq>=17 in ./.venv/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: entrypoints in ./.venv/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in ./.venv/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in ./.venv/lib/python3.8/site-packages (from importlib-resources>=1.4.0; python_version < \"3.9\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.7.0)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.8/site-packages (from asttokens->stack-data->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in ./.venv/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./.venv/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: bleach in ./.venv/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./.venv/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: testpath in ./.venv/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: defusedxml in ./.venv/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in ./.venv/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.13)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.10.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./.venv/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.8/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3)\n",
      "Requirement already satisfied: webencodings in ./.venv/lib/python3.8/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.8/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.3.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in ./.venv/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./.venv/lib/python3.8/site-packages (from packaging->bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: stable-baselines3[extra] in ./.venv/lib/python3.8/site-packages (1.5.0)\n",
      "Requirement already satisfied: gym==0.21 in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (0.21.0)\n",
      "Requirement already satisfied: torch>=1.8.1 in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.11.0)\n",
      "Requirement already satisfied: cloudpickle in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.6.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.4.1)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (3.5.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.22.3)\n",
      "Requirement already satisfied: ale-py~=0.7.4; extra == \"extra\" in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (0.7.4)\n",
      "Requirement already satisfied: pillow; extra == \"extra\" in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (7.2.0)\n",
      "Requirement already satisfied: psutil; extra == \"extra\" in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (5.9.0)\n",
      "Requirement already satisfied: opencv-python; extra == \"extra\" in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (4.5.5.64)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2; extra == \"extra\" in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: tensorboard>=2.2.0; extra == \"extra\" in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.8/site-packages (from torch>=1.8.1->stable-baselines3[extra]) (4.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.8/site-packages (from pandas->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas->stable-baselines3[extra]) (2022.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (4.31.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (3.0.7)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0; python_version < \"3.10\" in ./.venv/lib/python3.8/site-packages (from ale-py~=0.7.4; extra == \"extra\"->stable-baselines3[extra]) (4.11.3)\n",
      "Requirement already satisfied: importlib-resources in ./.venv/lib/python3.8/site-packages (from ale-py~=0.7.4; extra == \"extra\"->stable-baselines3[extra]) (5.6.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (4.63.1)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (2.27.1)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (8.0.4)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license; extra == \"accept-rom-license\" in ./.venv/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (44.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (2.6.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (3.19.4)\n",
      "Requirement already satisfied: wheel>=0.26 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (2.0.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (3.3.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (1.44.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.8/site-packages (from importlib-metadata>=4.10.0; python_version < \"3.10\"->ale-py~=0.7.4; extra == \"extra\"->stable-baselines3[extra]) (3.7.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in ./.venv/lib/python3.8/site-packages (from requests->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.venv/lib/python3.8/site-packages (from requests->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in ./.venv/lib/python3.8/site-packages (from requests->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.8/site-packages (from requests->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (2021.10.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in ./.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.venv/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./.venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ta in ./.venv/lib/python3.8/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.8/site-packages (from ta) (1.22.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.8/site-packages (from ta) (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.8/site-packages (from pandas->ta) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas->ta) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->ta) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: quantstats in ./.venv/lib/python3.8/site-packages (0.0.50)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in ./.venv/lib/python3.8/site-packages (from quantstats) (0.11.2)\n",
      "Requirement already satisfied: tabulate>=0.8.0 in ./.venv/lib/python3.8/site-packages (from quantstats) (0.8.9)\n",
      "Requirement already satisfied: yfinance>=0.1.70 in ./.venv/lib/python3.8/site-packages (from quantstats) (0.1.70)\n",
      "Requirement already satisfied: pandas>=0.24.0 in ./.venv/lib/python3.8/site-packages (from quantstats) (1.4.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in ./.venv/lib/python3.8/site-packages (from quantstats) (1.8.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in ./.venv/lib/python3.8/site-packages (from quantstats) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in ./.venv/lib/python3.8/site-packages (from quantstats) (1.22.3)\n",
      "Requirement already satisfied: lxml>=4.5.1 in ./.venv/lib/python3.8/site-packages (from yfinance>=0.1.70->quantstats) (4.8.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in ./.venv/lib/python3.8/site-packages (from yfinance>=0.1.70->quantstats) (0.0.10)\n",
      "Requirement already satisfied: requests>=2.26 in ./.venv/lib/python3.8/site-packages (from yfinance>=0.1.70->quantstats) (2.27.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas>=0.24.0->quantstats) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.8/site-packages (from pandas>=0.24.0->quantstats) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib>=3.0.0->quantstats) (1.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.8/site-packages (from matplotlib>=3.0.0->quantstats) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.8/site-packages (from matplotlib>=3.0.0->quantstats) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./.venv/lib/python3.8/site-packages (from matplotlib>=3.0.0->quantstats) (3.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.8/site-packages (from matplotlib>=3.0.0->quantstats) (4.31.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib>=3.0.0->quantstats) (7.2.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in ./.venv/lib/python3.8/site-packages (from requests>=2.26->yfinance>=0.1.70->quantstats) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in ./.venv/lib/python3.8/site-packages (from requests>=2.26->yfinance>=0.1.70->quantstats) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.8/site-packages (from requests>=2.26->yfinance>=0.1.70->quantstats) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.venv/lib/python3.8/site-packages (from requests>=2.26->yfinance>=0.1.70->quantstats) (1.26.9)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=0.24.0->quantstats) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sklearn in ./.venv/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.8/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in ./.venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in ./.venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.22.3)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: feature_engine in ./.venv/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./.venv/lib/python3.8/site-packages (from feature_engine) (1.8.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in ./.venv/lib/python3.8/site-packages (from feature_engine) (1.0.2)\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in ./.venv/lib/python3.8/site-packages (from feature_engine) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in ./.venv/lib/python3.8/site-packages (from feature_engine) (1.22.3)\n",
      "Requirement already satisfied: pandas>=1.0.3 in ./.venv/lib/python3.8/site-packages (from feature_engine) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.8/site-packages (from scikit-learn>=0.22.2->feature_engine) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.venv/lib/python3.8/site-packages (from scikit-learn>=0.22.2->feature_engine) (1.1.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in ./.venv/lib/python3.8/site-packages (from statsmodels>=0.11.1->feature_engine) (0.5.2)\n",
      "Requirement already satisfied: packaging>=21.3 in ./.venv/lib/python3.8/site-packages (from statsmodels>=0.11.1->feature_engine) (21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas>=1.0.3->feature_engine) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.8/site-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.8/site-packages (from patsy>=0.5.2->statsmodels>=0.11.1->feature_engine) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./.venv/lib/python3.8/site-packages (from packaging>=21.3->statsmodels>=0.11.1->feature_engine) (3.0.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already up-to-date: mplfinance in ./.venv/lib/python3.8/site-packages (0.12.8b9)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in ./.venv/lib/python3.8/site-packages (from mplfinance) (3.5.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas in ./.venv/lib/python3.8/site-packages (from mplfinance) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib->mplfinance) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->mplfinance) (7.2.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17 in ./.venv/lib/python3.8/site-packages (from matplotlib->mplfinance) (1.22.3)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->mplfinance) (21.3)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in ./.venv/lib/python3.8/site-packages (from matplotlib->mplfinance) (0.11.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.2.1 in ./.venv/lib/python3.8/site-packages (from matplotlib->mplfinance) (3.0.7)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7 in ./.venv/lib/python3.8/site-packages (from matplotlib->mplfinance) (2.8.2)\n",
      "Requirement already satisfied, skipping upgrade: fonttools>=4.22.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->mplfinance) (4.31.2)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas->mplfinance) (2022.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->mplfinance) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas-ta==0.3.14b --pre\n",
    "%pip install gym==0.21.0\n",
    "%pip install ipywidgets\n",
    "%pip install stable-baselines3[extra]\n",
    "%pip install ta\n",
    "%pip install quantstats\n",
    "%pip install sklearn\n",
    "%pip install feature_engine\n",
    "%pip install --upgrade mplfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23c0bc4-b9bd-49e8-b79b-d11fc1aa8629",
   "metadata": {
    "id": "c23c0bc4-b9bd-49e8-b79b-d11fc1aa8629"
   },
   "source": [
    "# Prepare and fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "022f3a95-c2d5-4737-906c-270ee437c03b",
   "metadata": {
    "id": "022f3a95-c2d5-4737-906c-270ee437c03b"
   },
   "outputs": [],
   "source": [
    "from tensortrade.data.cdd import CryptoDataDownload\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "\n",
    "def prepare_data(df):\n",
    "    df['volume'] = np.int64(df['volume'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values(by='date', ascending=True, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['date'] = df['date'].dt.strftime('%Y-%m-%d %I:%M %p')\n",
    "    return df\n",
    "\n",
    "def fetch_data():\n",
    "    cdd = CryptoDataDownload()\n",
    "    bitfinex_data = cdd.fetch(\"Bitfinex\", \"USD\", \"BTC\", \"1h\")\n",
    "    bitfinex_data = bitfinex_data[['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    bitfinex_data = prepare_data(bitfinex_data)\n",
    "    return bitfinex_data\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv('data/' + filename, skiprows=1)\n",
    "    df.drop(columns=['symbol', 'volume_btc'], inplace=True)\n",
    "\n",
    "    # Fix timestamp from \"2019-10-17 09-AM\" to \"2019-10-17 09-00-00 AM\"\n",
    "    df['date'] = df['date'].str[:14] + '00-00 ' + df['date'].str[-2:]\n",
    "\n",
    "    return prepare_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7711877c-da93-4743-acf3-bd03d23f07c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-15 06:00 AM</td>\n",
       "      <td>8723.800000</td>\n",
       "      <td>8793.000000</td>\n",
       "      <td>8714.90000</td>\n",
       "      <td>8739.000000</td>\n",
       "      <td>8988053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-15 07:00 AM</td>\n",
       "      <td>8739.000000</td>\n",
       "      <td>8754.800000</td>\n",
       "      <td>8719.30000</td>\n",
       "      <td>8743.000000</td>\n",
       "      <td>2288904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-15 08:00 AM</td>\n",
       "      <td>8743.000000</td>\n",
       "      <td>8743.100000</td>\n",
       "      <td>8653.20000</td>\n",
       "      <td>8723.700000</td>\n",
       "      <td>8891773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-15 09:00 AM</td>\n",
       "      <td>8723.700000</td>\n",
       "      <td>8737.800000</td>\n",
       "      <td>8701.20000</td>\n",
       "      <td>8708.100000</td>\n",
       "      <td>2054868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-15 10:00 AM</td>\n",
       "      <td>8708.100000</td>\n",
       "      <td>8855.700000</td>\n",
       "      <td>8695.80000</td>\n",
       "      <td>8784.400000</td>\n",
       "      <td>17309722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34354</th>\n",
       "      <td>2022-04-17 09:00 PM</td>\n",
       "      <td>40279.000000</td>\n",
       "      <td>40310.948566</td>\n",
       "      <td>40152.00000</td>\n",
       "      <td>40227.829085</td>\n",
       "      <td>2411100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34355</th>\n",
       "      <td>2022-04-17 10:00 PM</td>\n",
       "      <td>40215.000000</td>\n",
       "      <td>40363.000000</td>\n",
       "      <td>39957.00000</td>\n",
       "      <td>40016.000000</td>\n",
       "      <td>8236277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34356</th>\n",
       "      <td>2022-04-17 11:00 PM</td>\n",
       "      <td>40021.000000</td>\n",
       "      <td>40021.000000</td>\n",
       "      <td>39563.00000</td>\n",
       "      <td>39707.552712</td>\n",
       "      <td>10678099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34357</th>\n",
       "      <td>2022-04-18 12:00 AM</td>\n",
       "      <td>39699.719303</td>\n",
       "      <td>39796.000000</td>\n",
       "      <td>39602.00000</td>\n",
       "      <td>39745.389366</td>\n",
       "      <td>5425275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34358</th>\n",
       "      <td>2022-04-18 01:00 AM</td>\n",
       "      <td>39744.000000</td>\n",
       "      <td>39851.641499</td>\n",
       "      <td>39731.22461</td>\n",
       "      <td>39796.573934</td>\n",
       "      <td>983800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34359 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date          open          high          low  \\\n",
       "0      2018-05-15 06:00 AM   8723.800000   8793.000000   8714.90000   \n",
       "1      2018-05-15 07:00 AM   8739.000000   8754.800000   8719.30000   \n",
       "2      2018-05-15 08:00 AM   8743.000000   8743.100000   8653.20000   \n",
       "3      2018-05-15 09:00 AM   8723.700000   8737.800000   8701.20000   \n",
       "4      2018-05-15 10:00 AM   8708.100000   8855.700000   8695.80000   \n",
       "...                    ...           ...           ...          ...   \n",
       "34354  2022-04-17 09:00 PM  40279.000000  40310.948566  40152.00000   \n",
       "34355  2022-04-17 10:00 PM  40215.000000  40363.000000  39957.00000   \n",
       "34356  2022-04-17 11:00 PM  40021.000000  40021.000000  39563.00000   \n",
       "34357  2022-04-18 12:00 AM  39699.719303  39796.000000  39602.00000   \n",
       "34358  2022-04-18 01:00 AM  39744.000000  39851.641499  39731.22461   \n",
       "\n",
       "              close    volume  \n",
       "0       8739.000000   8988053  \n",
       "1       8743.000000   2288904  \n",
       "2       8723.700000   8891773  \n",
       "3       8708.100000   2054868  \n",
       "4       8784.400000  17309722  \n",
       "...             ...       ...  \n",
       "34354  40227.829085   2411100  \n",
       "34355  40016.000000   8236277  \n",
       "34356  39707.552712  10678099  \n",
       "34357  39745.389366   5425275  \n",
       "34358  39796.573934    983800  \n",
       "\n",
       "[34359 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fetch_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdac31a-4ad2-4365-b061-bf0eaa5b4b49",
   "metadata": {},
   "source": [
    "## Create features for the feed module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe71f2a-5779-4e49-9b1a-a2952f07052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import ta as ta1\n",
    "import pandas_ta as ta\n",
    "\n",
    "import quantstats as qs\n",
    "qs.extend_pandas()\n",
    "\n",
    "def fix_dataset_inconsistencies_without_backfilling(dataframe, fill_value=None):\n",
    "    dataframe = dataframe.replace([-np.inf, np.inf], np.nan)\n",
    "\n",
    "    return dataframe.fillna(axis='index', method='pad').dropna(axis='columns')\n",
    "\n",
    "def fix_dataset_inconsistencies(dataframe, fill_value=None):\n",
    "    dataframe = dataframe.replace([-np.inf, np.inf], np.nan)\n",
    "\n",
    "    #This is done to avoid filling middle holes with backfilling.\n",
    "    if fill_value is None:\n",
    "        dataframe.iloc[0,:] = \\\n",
    "            dataframe.apply(lambda column: column.iloc[column.first_valid_index()], axis='index')\n",
    "    else:\n",
    "        dataframe.iloc[0,:] = \\\n",
    "            dataframe.iloc[0,:].fillna(fill_value)\n",
    "\n",
    "    return dataframe.fillna(axis='index', method='pad').dropna(axis='columns')\n",
    "\n",
    "def rsi(price: 'pd.Series[pd.Float64Dtype]', period: float) -> 'pd.Series[pd.Float64Dtype]':\n",
    "    r = price.diff()\n",
    "    upside = np.minimum(r, 0).abs()\n",
    "    downside = np.maximum(r, 0).abs()\n",
    "    rs = upside.ewm(alpha=1 / period).mean() / downside.ewm(alpha=1 / period).mean()\n",
    "    return 100*(1 - (1 + rs) ** -1)\n",
    "\n",
    "def macd(price: 'pd.Series[pd.Float64Dtype]', fast: float, slow: float, signal: float) -> 'pd.Series[pd.Float64Dtype]':\n",
    "    fm = price.ewm(span=fast, adjust=False).mean()\n",
    "    sm = price.ewm(span=slow, adjust=False).mean()\n",
    "    md = fm - sm\n",
    "    signal = md - md.ewm(span=signal, adjust=False).mean()\n",
    "    return signal\n",
    "\n",
    "def generate_all_default_quantstats_features(data):\n",
    "    excluded_indicators = [\n",
    "        'compare',\n",
    "        'greeks',\n",
    "        'information_ratio',\n",
    "        'omega',\n",
    "        'r2',\n",
    "        'r_squared',\n",
    "        'rolling_greeks',\n",
    "        'warn',\n",
    "    ]\n",
    "    \n",
    "    indicators_list = [f for f in dir(qs.stats) if f[0] != '_' and f not in excluded_indicators]\n",
    "    \n",
    "    df = data.copy()\n",
    "    df = df.set_index('date')\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "\n",
    "    for indicator_name in indicators_list:\n",
    "        try:\n",
    "            #print(indicator_name)\n",
    "            indicator = qs.stats.__dict__[indicator_name](df['close'])\n",
    "            if isinstance(indicator, pd.Series):\n",
    "                indicator = indicator.to_frame(name=indicator_name)\n",
    "                df = pd.concat([df, indicator], axis='columns')\n",
    "        except (pd.errors.InvalidIndexError, ValueError):\n",
    "            pass\n",
    "\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "\n",
    "def generate_features(data):\n",
    "\n",
    "    # Generate all default indicators from ta library\n",
    "    ta1.add_all_ta_features(data, \n",
    "                            'open', \n",
    "                            'high', \n",
    "                            'low', \n",
    "                            'close', \n",
    "                            'volume', \n",
    "                            fillna=True)\n",
    "\n",
    "    # Naming convention across most technical indicator libraries\n",
    "    data = data.rename(columns={'open': 'Open', \n",
    "                                'high': 'High', \n",
    "                                'low': 'Low', \n",
    "                                'close': 'Close', \n",
    "                                'volume': 'Volume'})\n",
    "    data = data.set_index('date')\n",
    "\n",
    "    # Custom indicators\n",
    "    features = pd.DataFrame.from_dict({\n",
    "        'prev_open': data['Open'].shift(1),\n",
    "        'prev_high': data['High'].shift(1),\n",
    "        'prev_low': data['Low'].shift(1),\n",
    "        'prev_close': data['Close'].shift(1),\n",
    "        'prev_volume': data['Volume'].shift(1),\n",
    "        'vol_5': data['Close'].rolling(window=5).std().abs(),\n",
    "        'vol_10': data['Close'].rolling(window=10).std().abs(),\n",
    "        'vol_20': data['Close'].rolling(window=20).std().abs(),\n",
    "        'vol_30': data['Close'].rolling(window=30).std().abs(),\n",
    "        'vol_50': data['Close'].rolling(window=50).std().abs(),\n",
    "        'vol_60': data['Close'].rolling(window=60).std().abs(),\n",
    "        'vol_100': data['Close'].rolling(window=100).std().abs(),\n",
    "        'vol_200': data['Close'].rolling(window=200).std().abs(),\n",
    "        'ma_5': data['Close'].rolling(window=5).mean(),\n",
    "        'ma_10': data['Close'].rolling(window=10).mean(),\n",
    "        'ma_20': data['Close'].rolling(window=20).mean(),\n",
    "        'ma_30': data['Close'].rolling(window=30).mean(),\n",
    "        'ma_50': data['Close'].rolling(window=50).mean(),\n",
    "        'ma_60': data['Close'].rolling(window=60).mean(),\n",
    "        'ma_100': data['Close'].rolling(window=100).mean(),\n",
    "        'ma_200': data['Close'].rolling(window=200).mean(),\n",
    "        'ema_5': ta1.trend.ema_indicator(data['Close'], window=5, fillna=True),\n",
    "        'ema_9': ta1.trend.ema_indicator(data['Close'], window=9, fillna=True),\n",
    "        'ema_21': ta1.trend.ema_indicator(data['Close'], window=21, fillna=True),\n",
    "        'ema_60': ta1.trend.ema_indicator(data['Close'], window=60, fillna=True),\n",
    "        'ema_64': ta1.trend.ema_indicator(data['Close'], window=64, fillna=True),\n",
    "        'ema_120': ta1.trend.ema_indicator(data['Close'], window=120, fillna=True),\n",
    "        'lr_open': np.log(data['Open']).diff().fillna(0),\n",
    "        'lr_high': np.log(data['High']).diff().fillna(0),\n",
    "        'lr_low': np.log(data['Low']).diff().fillna(0),\n",
    "        'lr_close': np.log(data['Close']).diff().fillna(0),\n",
    "        'r_volume': data['Close'].diff().fillna(0),\n",
    "        'rsi_5': rsi(data['Close'], period=5),\n",
    "        'rsi_10': rsi(data['Close'], period=10),\n",
    "        'rsi_100': rsi(data['Close'], period=100),\n",
    "        'rsi_7': rsi(data['Close'], period=7),\n",
    "        'rsi_28': rsi(data['Close'], period=28),\n",
    "        'rsi_6': rsi(data['Close'], period=6),\n",
    "        'rsi_14': rsi(data['Close'], period=14),\n",
    "        'rsi_26': rsi(data['Close'], period=24),\n",
    "        'macd_normal': macd(data['Close'], fast=12, slow=26, signal=9),\n",
    "        'macd_short': macd(data['Close'], fast=10, slow=50, signal=5),\n",
    "        'macd_long': macd(data['Close'], fast=200, slow=100, signal=50),\n",
    "        'macd_wolfpack': macd(data['Close'], fast=3, slow=8, signal=9),\n",
    "    })\n",
    "\n",
    "    # Concatenate both manually and automatically generated features\n",
    "    data = pd.concat([data, features], axis='columns').fillna(method='pad')\n",
    "\n",
    "    # Remove potential column duplicates\n",
    "    data = data.loc[:,~data.columns.duplicated()]\n",
    "\n",
    "    # Revert naming convention\n",
    "    data = data.rename(columns={'Open': 'open', \n",
    "                                'High': 'high', \n",
    "                                'Low': 'low', \n",
    "                                'Close': 'close', \n",
    "                                'Volume': 'volume'})\n",
    "\n",
    "    data = data.reset_index()\n",
    "\n",
    "    # Generate all default quantstats features\n",
    "    df_quantstats = generate_all_default_quantstats_features(data)\n",
    "\n",
    "    # Concatenate both manually and automatically generated features\n",
    "    data = pd.concat([data, df_quantstats], axis='columns').fillna(method='pad')\n",
    "\n",
    "    # Remove potential column duplicates\n",
    "    data = data.loc[:,~data.columns.duplicated()]\n",
    "\n",
    "    # A lot of indicators generate NaNs at the beginning of DataFrames, so remove them\n",
    "    data = data.iloc[200:]\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    data = fix_dataset_inconsistencies_without_backfilling(data, fill_value=None)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70679eb9-03fc-4ef6-b81c-a64b6eb026db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/ta/trend.py:769: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/ta/trend.py:774: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/ta/trend.py:938: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  self._psar_up = pd.Series(index=self._psar.index)\n",
      "/home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/ta/trend.py:939: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  self._psar_down = pd.Series(index=self._psar.index)\n",
      "/home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:57: RuntimeWarning: overflow encountered in accumulate\n",
      "  return bound(*args, **kwds)\n",
      "/home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/quantstats/utils.py:68: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  return _pd.concat(dfs, 1, sort=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(34159, 140)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = generate_features(data)\n",
    "# remove not needed features\n",
    "to_drop = ['others_dlr', 'compsum']\n",
    "data = data.drop(columns=to_drop)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ec36a-138e-4e5a-b475-b060acabd207",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Remove features with low variance before splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "501c9dd8-4188-44e5-852d-2f0f0fb4a7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_obv</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>volume_fi</th>\n",
       "      <th>...</th>\n",
       "      <th>rsi_26</th>\n",
       "      <th>macd_normal</th>\n",
       "      <th>macd_short</th>\n",
       "      <th>macd_long</th>\n",
       "      <th>macd_wolfpack</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>rolling_sharpe</th>\n",
       "      <th>rolling_sortino</th>\n",
       "      <th>rolling_volatility</th>\n",
       "      <th>to_drawdown_series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-23 02:00 PM</td>\n",
       "      <td>7897.300000</td>\n",
       "      <td>7898.800000</td>\n",
       "      <td>7849.80000</td>\n",
       "      <td>7877.400000</td>\n",
       "      <td>9341499</td>\n",
       "      <td>-1.219515e+08</td>\n",
       "      <td>-153103304</td>\n",
       "      <td>-0.175983</td>\n",
       "      <td>-1.548039e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>65.542059</td>\n",
       "      <td>11.190548</td>\n",
       "      <td>10.871904</td>\n",
       "      <td>31.873058</td>\n",
       "      <td>19.596642</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-0.811487</td>\n",
       "      <td>-1.144302</td>\n",
       "      <td>0.072620</td>\n",
       "      <td>-0.103251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-23 03:00 PM</td>\n",
       "      <td>7877.400000</td>\n",
       "      <td>7889.700000</td>\n",
       "      <td>7661.00000</td>\n",
       "      <td>7700.000000</td>\n",
       "      <td>23679375</td>\n",
       "      <td>-1.375548e+08</td>\n",
       "      <td>-176782679</td>\n",
       "      <td>-0.228723</td>\n",
       "      <td>-7.327921e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>72.698849</td>\n",
       "      <td>1.333779</td>\n",
       "      <td>-5.426751</td>\n",
       "      <td>34.355233</td>\n",
       "      <td>-24.639480</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-1.248391</td>\n",
       "      <td>-1.633909</td>\n",
       "      <td>0.079103</td>\n",
       "      <td>-0.123446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-23 04:00 PM</td>\n",
       "      <td>7700.000000</td>\n",
       "      <td>7700.100000</td>\n",
       "      <td>7548.10000</td>\n",
       "      <td>7605.400000</td>\n",
       "      <td>42144843</td>\n",
       "      <td>-1.479246e+08</td>\n",
       "      <td>-218927522</td>\n",
       "      <td>-0.216859</td>\n",
       "      <td>-1.197665e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>75.527202</td>\n",
       "      <td>-10.060459</td>\n",
       "      <td>-21.497215</td>\n",
       "      <td>37.504922</td>\n",
       "      <td>-51.837145</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-1.612964</td>\n",
       "      <td>-2.069373</td>\n",
       "      <td>0.080681</td>\n",
       "      <td>-0.134215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-23 05:00 PM</td>\n",
       "      <td>7605.400000</td>\n",
       "      <td>7623.600000</td>\n",
       "      <td>7441.80000</td>\n",
       "      <td>7511.100000</td>\n",
       "      <td>38711817</td>\n",
       "      <td>-1.571235e+08</td>\n",
       "      <td>-257639339</td>\n",
       "      <td>-0.221424</td>\n",
       "      <td>-1.548073e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>77.907846</td>\n",
       "      <td>-21.778972</td>\n",
       "      <td>-36.146245</td>\n",
       "      <td>41.269618</td>\n",
       "      <td>-66.773623</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-1.797159</td>\n",
       "      <td>-2.272346</td>\n",
       "      <td>0.082309</td>\n",
       "      <td>-0.144950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-23 06:00 PM</td>\n",
       "      <td>7511.100000</td>\n",
       "      <td>7551.600000</td>\n",
       "      <td>7403.00000</td>\n",
       "      <td>7489.100000</td>\n",
       "      <td>23046091</td>\n",
       "      <td>-1.534634e+08</td>\n",
       "      <td>-280685430</td>\n",
       "      <td>-0.149460</td>\n",
       "      <td>-1.399351e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>78.418914</td>\n",
       "      <td>-28.422775</td>\n",
       "      <td>-41.976877</td>\n",
       "      <td>44.917996</td>\n",
       "      <td>-57.191729</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-1.879146</td>\n",
       "      <td>-2.372706</td>\n",
       "      <td>0.082361</td>\n",
       "      <td>-0.147455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34154</th>\n",
       "      <td>2022-04-17 09:00 PM</td>\n",
       "      <td>40279.000000</td>\n",
       "      <td>40310.948566</td>\n",
       "      <td>40152.00000</td>\n",
       "      <td>40227.829085</td>\n",
       "      <td>2411100</td>\n",
       "      <td>1.034904e+10</td>\n",
       "      <td>-4091153067</td>\n",
       "      <td>0.069567</td>\n",
       "      <td>-2.279012e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>53.472527</td>\n",
       "      <td>-15.399788</td>\n",
       "      <td>-12.766689</td>\n",
       "      <td>-94.423742</td>\n",
       "      <td>-0.511128</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-1.143253</td>\n",
       "      <td>-1.301348</td>\n",
       "      <td>0.102899</td>\n",
       "      <td>-0.413597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34155</th>\n",
       "      <td>2022-04-17 10:00 PM</td>\n",
       "      <td>40215.000000</td>\n",
       "      <td>40363.000000</td>\n",
       "      <td>39957.00000</td>\n",
       "      <td>40016.000000</td>\n",
       "      <td>8236277</td>\n",
       "      <td>1.034319e+10</td>\n",
       "      <td>-4099389344</td>\n",
       "      <td>-0.012154</td>\n",
       "      <td>-2.511939e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>57.736870</td>\n",
       "      <td>-28.816185</td>\n",
       "      <td>-32.828145</td>\n",
       "      <td>-92.752200</td>\n",
       "      <td>-48.891523</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-1.258480</td>\n",
       "      <td>-1.430544</td>\n",
       "      <td>0.103106</td>\n",
       "      <td>-0.416685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34156</th>\n",
       "      <td>2022-04-17 11:00 PM</td>\n",
       "      <td>40021.000000</td>\n",
       "      <td>40021.000000</td>\n",
       "      <td>39563.00000</td>\n",
       "      <td>39707.552712</td>\n",
       "      <td>10678099</td>\n",
       "      <td>1.033926e+10</td>\n",
       "      <td>-4110067443</td>\n",
       "      <td>-0.088576</td>\n",
       "      <td>-6.858277e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>62.902948</td>\n",
       "      <td>-55.180302</td>\n",
       "      <td>-69.739910</td>\n",
       "      <td>-88.328100</td>\n",
       "      <td>-118.618577</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-1.563211</td>\n",
       "      <td>-1.760876</td>\n",
       "      <td>0.102909</td>\n",
       "      <td>-0.421181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34157</th>\n",
       "      <td>2022-04-18 12:00 AM</td>\n",
       "      <td>39699.719303</td>\n",
       "      <td>39796.000000</td>\n",
       "      <td>39602.00000</td>\n",
       "      <td>39745.389366</td>\n",
       "      <td>5425275</td>\n",
       "      <td>1.034185e+10</td>\n",
       "      <td>-4104642168</td>\n",
       "      <td>-0.040761</td>\n",
       "      <td>-5.585274e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>61.933905</td>\n",
       "      <td>-66.052950</td>\n",
       "      <td>-79.588620</td>\n",
       "      <td>-84.620542</td>\n",
       "      <td>-100.678703</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>-1.547567</td>\n",
       "      <td>-1.743567</td>\n",
       "      <td>0.102928</td>\n",
       "      <td>-0.420630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34158</th>\n",
       "      <td>2022-04-18 01:00 AM</td>\n",
       "      <td>39744.000000</td>\n",
       "      <td>39851.641499</td>\n",
       "      <td>39731.22461</td>\n",
       "      <td>39796.573934</td>\n",
       "      <td>983800</td>\n",
       "      <td>1.034193e+10</td>\n",
       "      <td>-4103658368</td>\n",
       "      <td>-0.046215</td>\n",
       "      <td>-4.715442e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>60.615748</td>\n",
       "      <td>-65.643501</td>\n",
       "      <td>-73.047388</td>\n",
       "      <td>-81.711769</td>\n",
       "      <td>-54.048473</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-1.570202</td>\n",
       "      <td>-1.768130</td>\n",
       "      <td>0.102873</td>\n",
       "      <td>-0.419883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34159 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date          open          high          low  \\\n",
       "0      2018-05-23 02:00 PM   7897.300000   7898.800000   7849.80000   \n",
       "1      2018-05-23 03:00 PM   7877.400000   7889.700000   7661.00000   \n",
       "2      2018-05-23 04:00 PM   7700.000000   7700.100000   7548.10000   \n",
       "3      2018-05-23 05:00 PM   7605.400000   7623.600000   7441.80000   \n",
       "4      2018-05-23 06:00 PM   7511.100000   7551.600000   7403.00000   \n",
       "...                    ...           ...           ...          ...   \n",
       "34154  2022-04-17 09:00 PM  40279.000000  40310.948566  40152.00000   \n",
       "34155  2022-04-17 10:00 PM  40215.000000  40363.000000  39957.00000   \n",
       "34156  2022-04-17 11:00 PM  40021.000000  40021.000000  39563.00000   \n",
       "34157  2022-04-18 12:00 AM  39699.719303  39796.000000  39602.00000   \n",
       "34158  2022-04-18 01:00 AM  39744.000000  39851.641499  39731.22461   \n",
       "\n",
       "              close    volume    volume_adi  volume_obv  volume_cmf  \\\n",
       "0       7877.400000   9341499 -1.219515e+08  -153103304   -0.175983   \n",
       "1       7700.000000  23679375 -1.375548e+08  -176782679   -0.228723   \n",
       "2       7605.400000  42144843 -1.479246e+08  -218927522   -0.216859   \n",
       "3       7511.100000  38711817 -1.571235e+08  -257639339   -0.221424   \n",
       "4       7489.100000  23046091 -1.534634e+08  -280685430   -0.149460   \n",
       "...             ...       ...           ...         ...         ...   \n",
       "34154  40227.829085   2411100  1.034904e+10 -4091153067    0.069567   \n",
       "34155  40016.000000   8236277  1.034319e+10 -4099389344   -0.012154   \n",
       "34156  39707.552712  10678099  1.033926e+10 -4110067443   -0.088576   \n",
       "34157  39745.389366   5425275  1.034185e+10 -4104642168   -0.040761   \n",
       "34158  39796.573934    983800  1.034193e+10 -4103658368   -0.046215   \n",
       "\n",
       "          volume_fi  ...     rsi_26  macd_normal  macd_short  macd_long  \\\n",
       "0     -1.548039e+08  ...  65.542059    11.190548   10.871904  31.873058   \n",
       "1     -7.327921e+08  ...  72.698849     1.333779   -5.426751  34.355233   \n",
       "2     -1.197665e+09  ...  75.527202   -10.060459  -21.497215  37.504922   \n",
       "3     -1.548073e+09  ...  77.907846   -21.778972  -36.146245  41.269618   \n",
       "4     -1.399351e+09  ...  78.418914   -28.422775  -41.976877  44.917996   \n",
       "...             ...  ...        ...          ...         ...        ...   \n",
       "34154 -2.279012e+06  ...  53.472527   -15.399788  -12.766689 -94.423742   \n",
       "34155 -2.511939e+08  ...  57.736870   -28.816185  -32.828145 -92.752200   \n",
       "34156 -6.858277e+08  ...  62.902948   -55.180302  -69.739910 -88.328100   \n",
       "34157 -5.585274e+08  ...  61.933905   -66.052950  -79.588620 -84.620542   \n",
       "34158 -4.715442e+08  ...  60.615748   -65.643501  -73.047388 -81.711769   \n",
       "\n",
       "       macd_wolfpack   pct_rank  rolling_sharpe  rolling_sortino  \\\n",
       "0          19.596642  10.000000       -0.811487        -1.144302   \n",
       "1         -24.639480   1.666667       -1.248391        -1.633909   \n",
       "2         -51.837145   1.666667       -1.612964        -2.069373   \n",
       "3         -66.773623   1.666667       -1.797159        -2.272346   \n",
       "4         -57.191729   1.666667       -1.879146        -2.372706   \n",
       "...              ...        ...             ...              ...   \n",
       "34154      -0.511128  15.000000       -1.143253        -1.301348   \n",
       "34155     -48.891523   1.666667       -1.258480        -1.430544   \n",
       "34156    -118.618577   1.666667       -1.563211        -1.760876   \n",
       "34157    -100.678703   3.333333       -1.547567        -1.743567   \n",
       "34158     -54.048473   5.000000       -1.570202        -1.768130   \n",
       "\n",
       "       rolling_volatility  to_drawdown_series  \n",
       "0                0.072620           -0.103251  \n",
       "1                0.079103           -0.123446  \n",
       "2                0.080681           -0.134215  \n",
       "3                0.082309           -0.144950  \n",
       "4                0.082361           -0.147455  \n",
       "...                   ...                 ...  \n",
       "34154            0.102899           -0.413597  \n",
       "34155            0.103106           -0.416685  \n",
       "34156            0.102909           -0.421181  \n",
       "34157            0.102928           -0.420630  \n",
       "34158            0.102873           -0.419883  \n",
       "\n",
       "[34159 rows x 140 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "date = data[['date']].copy()\n",
    "data = data.drop(columns=['date'])\n",
    "sel.fit(data)\n",
    "data[data.columns[sel.get_support(indices=True)]]\n",
    "data = pd.concat([date, data], axis='columns')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef6f85-8116-4be7-821d-6f5b897ade5b",
   "metadata": {
    "id": "f6ef6f85-8116-4be7-821d-6f5b897ade5b"
   },
   "source": [
    "# Setup which data to use for training and which data to use for evaluation of RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22d15ac6-4546-4a5d-bf7d-c117cb231f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(data):\n",
    "    X = data.copy()\n",
    "    y = X['close'].pct_change()\n",
    "\n",
    "    X_train_test, X_valid, y_train_test, y_valid = \\\n",
    "        train_test_split(data, data['close'].pct_change(), train_size=0.67, test_size=0.33, shuffle=False)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X_train_test, y_train_test, train_size=0.50, test_size=0.50, shuffle=False)\n",
    "\n",
    "    return X_train, X_test, X_valid, y_train, y_test, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18402c18-25ef-48ea-85e3-0d7178971e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_valid, y_train, y_test, y_valid = \\\n",
    "    split_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dddb3e-cc23-40a2-bdb5-a5da6b735f62",
   "metadata": {},
   "source": [
    "## Implement basic feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94b3f1ae-dbb1-4672-b034-fe454ff8874a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectBySingleFeaturePerformance(cv=5,\n",
       "                                 estimator=RandomForestClassifier(n_jobs=-1,\n",
       "                                                                  random_state=1990),\n",
       "                                 threshold=0.65)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from feature_engine.selection import SelectBySingleFeaturePerformance\n",
    "\n",
    "from scipy.stats import iqr\n",
    "\n",
    "\n",
    "def estimate_outliers(data):\n",
    "    return iqr(data) * 1.5\n",
    "\n",
    "def estimate_percent_gains(data, column='close'):\n",
    "    returns = get_returns(data, column=column)\n",
    "    gains = estimate_outliers(returns)\n",
    "    return gains\n",
    "\n",
    "def get_returns(data, column='close'):\n",
    "    return fix_dataset_inconsistencies(data[[column]].pct_change(), fill_value=0)\n",
    "\n",
    "def precalculate_ground_truths(data, column='close', threshold=None):\n",
    "    returns = get_returns(data, column=column)\n",
    "    gains = estimate_outliers(returns) if threshold is None else threshold\n",
    "    binary_gains = (returns[column] > gains).astype(int)\n",
    "    return binary_gains\n",
    "\n",
    "def is_null(data):\n",
    "    return data.isnull().sum().sum() > 0\n",
    "\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, \n",
    "                            random_state=1990, \n",
    "                            n_jobs=-1)\n",
    "\n",
    "sel = SelectBySingleFeaturePerformance(variables=None, \n",
    "                                       estimator=rf, \n",
    "                                       scoring=\"roc_auc\", \n",
    "                                       cv=5, \n",
    "                                       threshold=0.65)\n",
    "\n",
    "sel.fit(X_train, precalculate_ground_truths(X_train, column='close'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce149438-26b4-4351-a55f-2b307d122956",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_performance = pd.Series(sel.feature_performance_).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73845b81-1151-4aa0-b372-4901188d9faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# feature_performance.plot.bar(figsize=(40, 10))\n",
    "# plt.title('Performance of ML models trained with individual features')\n",
    "# plt.ylabel('roc-auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "228b820b-f0bf-4288-84e5-6db66c7c8647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_drop = sel.features_to_drop_\n",
    "to_drop = list(set(features_to_drop) - set(['open', 'high', 'low', 'close', 'volume']))\n",
    "len(to_drop)\n",
    "# features_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49a0a65e-b758-470d-a06e-35fd085b188c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11443, 16), (11443, 16), (11273, 16))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.drop(columns=to_drop)\n",
    "X_test = X_test.drop(columns=to_drop)\n",
    "X_valid = X_valid.drop(columns=to_drop)\n",
    "\n",
    "X_train.shape, X_test.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc593487-0e67-4940-9d06-8f84064470a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'open',\n",
       " 'high',\n",
       " 'low',\n",
       " 'close',\n",
       " 'volume',\n",
       " 'volume_em',\n",
       " 'volume_vpt',\n",
       " 'volatility_kchi',\n",
       " 'trend_aroon_up',\n",
       " 'momentum_stoch_rsi',\n",
       " 'others_dr',\n",
       " 'lr_high',\n",
       " 'lr_close',\n",
       " 'r_volume',\n",
       " 'macd_wolfpack']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6bfb53-d874-4dc9-9d29-abf27d42cff8",
   "metadata": {},
   "source": [
    "## Normalize the dataset subsets to make the model converge faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdef363e-b5ae-49f6-9acf-6a553fdbbcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "\n",
    "scaler_type = MinMaxScaler\n",
    "\n",
    "def get_feature_scalers(X, scaler_type=scaler_type):\n",
    "    scalers = []\n",
    "    for name in list(X.columns[X.columns != 'date']):\n",
    "        scalers.append(scaler_type().fit(X[name].values.reshape(-1, 1)))\n",
    "    return scalers\n",
    "\n",
    "def get_scaler_transforms(X, scalers):\n",
    "    X_scaled = []\n",
    "    for name, scaler in zip(list(X.columns[X.columns != 'date']), scalers):\n",
    "        X_scaled.append(scaler.transform(X[name].values.reshape(-1, 1)))\n",
    "    X_scaled = pd.concat([pd.DataFrame(column, columns=[name]) for name, column in \\\n",
    "                          zip(list(X.columns[X.columns != 'date']), X_scaled)], axis='columns')\n",
    "    return X_scaled\n",
    "\n",
    "def normalize_data(X_train, X_test, X_valid):\n",
    "    X_train_test = pd.concat([X_train, X_test], axis='index')\n",
    "    X_train_test_valid = pd.concat([X_train_test, X_valid], axis='index')\n",
    "\n",
    "    X_train_test_dates = X_train_test[['date']]\n",
    "    X_train_test_valid_dates = X_train_test_valid[['date']]\n",
    "\n",
    "    X_train_test = X_train_test.drop(columns=['date'])\n",
    "    X_train_test_valid = X_train_test_valid.drop(columns=['date'])\n",
    "\n",
    "    train_test_scalers = \\\n",
    "        get_feature_scalers(X_train_test, \n",
    "                            scaler_type=scaler_type)\n",
    "    train_test_valid_scalers = \\\n",
    "        get_feature_scalers(X_train_test_valid, \n",
    "                            scaler_type=scaler_type)\n",
    "\n",
    "    X_train_test_scaled = \\\n",
    "        get_scaler_transforms(X_train_test, \n",
    "                              train_test_scalers)\n",
    "    X_train_test_valid_scaled = \\\n",
    "        get_scaler_transforms(X_train_test_valid, \n",
    "                              train_test_scalers)\n",
    "    X_train_test_valid_scaled_leaking = \\\n",
    "        get_scaler_transforms(X_train_test_valid, \n",
    "                              train_test_valid_scalers)\n",
    "\n",
    "    X_train_test_scaled = \\\n",
    "        pd.concat([X_train_test_dates, \n",
    "                   X_train_test_scaled], \n",
    "                  axis='columns')\n",
    "    X_train_test_valid_scaled = \\\n",
    "        pd.concat([X_train_test_valid_dates, \n",
    "                   X_train_test_valid_scaled], \n",
    "                  axis='columns')\n",
    "    X_train_test_valid_scaled_leaking = \\\n",
    "        pd.concat([X_train_test_valid_dates, \n",
    "                   X_train_test_valid_scaled_leaking], \n",
    "                  axis='columns')\n",
    "\n",
    "    X_train_scaled = X_train_test_scaled.iloc[:X_train.shape[0]]\n",
    "    X_test_scaled = X_train_test_scaled.iloc[X_train.shape[0]:]\n",
    "    X_valid_scaled = X_train_test_valid_scaled.iloc[X_train_test.shape[0]:]\n",
    "    X_valid_scaled_leaking = X_train_test_valid_scaled_leaking.iloc[X_train_test.shape[0]:]\n",
    "\n",
    "    return (train_test_scalers, \n",
    "            train_test_valid_scalers, \n",
    "            X_train_scaled, \n",
    "            X_test_scaled, \n",
    "            X_valid_scaled, \n",
    "            X_valid_scaled_leaking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aee2204c-640c-4f7e-b082-1392f48c585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "train_test_scalers, train_test_valid_scalers, X_train_scaled, X_test_scaled, X_valid_scaled, X_valid_scaled_leaking = \\\n",
    "    normalize_data(X_train, X_test, X_valid)\n",
    "\n",
    "\n",
    "train_csv = os.path.join(cwd, 'train.csv')\n",
    "test_csv = os.path.join(cwd, 'test.csv')\n",
    "valid_csv = os.path.join(cwd, 'valid.csv')\n",
    "train_scaled_csv = os.path.join(cwd, 'train_scaled.csv')\n",
    "test_scaled_csv = os.path.join(cwd, 'test_scaled.csv')\n",
    "valid_scaled_csv = os.path.join(cwd, 'valid_scaled.csv')\n",
    "valid_scaled_leaking_csv = os.path.join(cwd, 'valid_scaled_leaking.csv')\n",
    "\n",
    "X_train.to_csv(train_csv, index=False)\n",
    "X_test.to_csv(test_csv, index=False)\n",
    "X_valid.to_csv(valid_csv, index=False)\n",
    "X_train.to_csv(train_scaled_csv, index=False)\n",
    "X_test.to_csv(test_scaled_csv, index=False)\n",
    "X_valid.to_csv(valid_scaled_csv, index=False)\n",
    "X_valid.to_csv(valid_scaled_leaking_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65e30d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import style\n",
    "import mplfinance as mpf\n",
    "\n",
    "style.use('dark_background')\n",
    "\n",
    "VOLUME_CHART_HEIGHT = 0.33\n",
    "\n",
    "UP_COLOR = '#27A59A'\n",
    "DOWN_COLOR = '#EF534F'\n",
    "UP_TEXT_COLOR = '#73D3CC'\n",
    "DOWN_TEXT_COLOR = '#DC2C27'\n",
    "\n",
    "\n",
    "def date2num(date):\n",
    "    return mdates.datestr2num(date)\n",
    "    \n",
    "\n",
    "\n",
    "class LiveTradingGraph:\n",
    "    \"\"\"A trading visualization using matplotlib made to render OpenAI gym environments\"\"\"\n",
    "\n",
    "    def __init__(self, df, title=None):\n",
    "        self.df = df.copy(deep=True) \n",
    "        self.df.index = pd.to_datetime(df.index)\n",
    "        self.net_worths = np.zeros(len(df['date']))\n",
    "\n",
    "        # Create a figure on screen and set the title\n",
    "        fig = plt.figure()\n",
    "        fig.suptitle(title)\n",
    "\n",
    "        # Create top subplot for net worth axis\n",
    "        self.net_worth_ax = plt.subplot2grid(\n",
    "            (6, 1), (0, 0), rowspan=2, colspan=1)\n",
    "\n",
    "        # Create bottom subplot for shared price/volume axis\n",
    "        self.price_ax = plt.subplot2grid(\n",
    "            (6, 1), (2, 0), rowspan=8, colspan=1, sharex=self.net_worth_ax)\n",
    "\n",
    "        # Create a new axis for volume which shares its x-axis with price\n",
    "        self.volume_ax = self.price_ax.twinx()\n",
    "\n",
    "        # Add padding to make graph easier to view\n",
    "        plt.subplots_adjust(left=0.11, bottom=0.24,\n",
    "                            right=0.90, top=0.90, wspace=0.2, hspace=0)\n",
    "\n",
    "        # Show the graph without blocking the rest of the program\n",
    "        plt.show(block=False)\n",
    "\n",
    "    def _render_net_worth(self, current_step, net_worth, step_range, dates):\n",
    "        # Clear the frame rendered last step\n",
    "        self.net_worth_ax.clear()\n",
    "\n",
    "        # Plot net worths\n",
    "        self.net_worth_ax.plot_date(\n",
    "            dates, self.net_worths[step_range], '-', label='Net Worth')\n",
    "\n",
    "        # Show legend, which uses the label we defined for the plot above\n",
    "        self.net_worth_ax.legend()\n",
    "        legend = self.net_worth_ax.legend(loc=2, ncol=2, prop={'size': 8})\n",
    "        legend.get_frame().set_alpha(0.4)\n",
    "\n",
    "        last_date = date2num(self.df['date'].values[current_step])\n",
    "        last_net_worth = self.net_worths[current_step]\n",
    "\n",
    "        # Annotate the current net worth on the net worth graph\n",
    "        self.net_worth_ax.annotate('{0:.2f}'.format(net_worth), (last_date, last_net_worth),\n",
    "                                   xytext=(last_date, last_net_worth),\n",
    "                                   bbox=dict(boxstyle='round',\n",
    "                                             fc='w', ec='k', lw=1),\n",
    "                                   color=\"black\",\n",
    "                                   fontsize=\"small\")\n",
    "\n",
    "        # Add space above and below min/max net worth\n",
    "        self.net_worth_ax.set_ylim(\n",
    "            min(self.net_worths[np.nonzero(self.net_worths)]) / 1.25, max(self.net_worths) * 1.25)\n",
    "\n",
    "    def _render_price(self, current_step, net_worth, dates, step_range):\n",
    "        self.price_ax.clear()\n",
    "\n",
    "        # Format data for OHCL candlestick graph\n",
    "        candlesticks = zip(dates,\n",
    "                           self.df['open'].values[step_range], self.df['close'].values[step_range],\n",
    "                           self.df['high'].values[step_range], self.df['low'].values[step_range])\n",
    "\n",
    "        # Plot price using candlestick graph from mpl_finance\n",
    "        # mpf.plot(self.price_ax, candlesticks, width=1,\n",
    "        #             colorup=UP_COLOR, colordown=DOWN_COLOR)\n",
    "\n",
    "        mpf.plot(self.df, type='candle', style='yahoo', volume=True)\n",
    "\n",
    "        last_date = date2num(self.df['date'].values[current_step])\n",
    "        last_close = self.df['close'].values[current_step]\n",
    "        last_high = self.df['high'].values[current_step]\n",
    "\n",
    "        # Print the current price to the price axis\n",
    "        self.price_ax.annotate('{0:.2f}'.format(last_close), (last_date, last_close),\n",
    "                               xytext=(last_date, last_high),\n",
    "                               bbox=dict(boxstyle='round',\n",
    "                                         fc='w', ec='k', lw=1),\n",
    "                               color=\"black\",\n",
    "                               fontsize=\"small\")\n",
    "\n",
    "        # Shift price axis up to give volume chart space\n",
    "        ylim = self.price_ax.get_ylim()\n",
    "        self.price_ax.set_ylim(ylim[0] - (ylim[1] - ylim[0])\n",
    "                               * VOLUME_CHART_HEIGHT, ylim[1])\n",
    "\n",
    "    def _render_volume(self, current_step, net_worth, dates, step_range):\n",
    "        self.volume_ax.clear()\n",
    "\n",
    "        volume = np.array(self.df['volume'].values[step_range])\n",
    "\n",
    "        pos = self.df['open'].values[step_range] - \\\n",
    "            self.df['close'].values[step_range] < 0\n",
    "        neg = self.df['open'].values[step_range] - \\\n",
    "            self.df['close'].values[step_range] > 0\n",
    "\n",
    "        # Color volume bars based on price direction on that date\n",
    "        self.volume_ax.bar(dates[pos], volume[pos], color=UP_COLOR,\n",
    "                           alpha=0.4, width=1, align='center')\n",
    "        self.volume_ax.bar(dates[neg], volume[neg], color=DOWN_COLOR,\n",
    "                           alpha=0.4, width=1, align='center')\n",
    "\n",
    "        # Cap volume axis height below price chart and hide ticks\n",
    "        self.volume_ax.set_ylim(0, max(volume) / VOLUME_CHART_HEIGHT)\n",
    "        self.volume_ax.yaxis.set_ticks([])\n",
    "\n",
    "    def _render_trades(self, current_step, trades, step_range):\n",
    "        # render only if there are trades\n",
    "        if len(trades) > 0:\n",
    "            for trade in trades:\n",
    "                if trade['step'] in step_range:\n",
    "                    date = date2num(self.df['date'].values[trade['step']])\n",
    "                    high = self.df['high'].values[trade['step']]\n",
    "                    low = self.df['low'].values[trade['step']]\n",
    "\n",
    "                    if trade['type'] == 'Buy':\n",
    "                        high_low = low\n",
    "                        color = UP_TEXT_COLOR\n",
    "                    else:\n",
    "                        high_low = high\n",
    "                        color = DOWN_TEXT_COLOR\n",
    "                    \n",
    "                    total = '{0:.2f}'.format(trade['total'])\n",
    "\n",
    "                    # Print the current price to the price axis\n",
    "                    self.price_ax.annotate(f'${total}', (date, high_low),\n",
    "                                        xytext=(date, high_low),\n",
    "                                        color=color,\n",
    "                                        fontsize=8,\n",
    "                                        arrowprops=(dict(color=color)))\n",
    "\n",
    "    def render(self, current_step, net_worth, trades, window_size=40):\n",
    "        self.net_worths[current_step] = net_worth\n",
    "\n",
    "        window_start = max(current_step - window_size, 0)\n",
    "        step_range = range(window_start, current_step + 1)\n",
    "\n",
    "        # Format dates as timestamps, necessary for candlestick graph\n",
    "        dates = np.array([date2num(x)\n",
    "                          for x in self.df['date'].values[step_range]])\n",
    "\n",
    "        self._render_net_worth(current_step, net_worth, step_range, dates)\n",
    "        self._render_price(current_step, net_worth, dates, step_range)\n",
    "        self._render_volume(current_step, net_worth, dates, step_range)\n",
    "        self._render_trades(current_step, trades, step_range)\n",
    "\n",
    "        # Format the date ticks to be more easily read\n",
    "        self.price_ax.set_xticklabels(self.df['date'].values[step_range], rotation=45,\n",
    "                                      horizontalalignment='right')\n",
    "\n",
    "        # Hide duplicate net worth date labels\n",
    "        plt.setp(self.net_worth_ax.get_xticklabels(), visible=False)\n",
    "\n",
    "        # Necessary to view frames before they are unrendered\n",
    "        plt.pause(0.001)\n",
    "\n",
    "    def close(self):\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77071777-9faf-4f19-9f3e-06d52d4805d5",
   "metadata": {
    "id": "77071777-9faf-4f19-9f3e-06d52d4805d5"
   },
   "source": [
    "# Defining the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5e14536-e09b-4a1e-b478-9d2c32fc67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "from gym import spaces\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# infinite number in python\n",
    "MAX_NET_WORTH = 2147483647\n",
    "MAX_NUM_QUOTE_OR_BASE_ASSET = 2147483647\n",
    "\n",
    "INITIAL_QUOTE_ASSET = 10000\n",
    "INITIAL_BASE_ASSET = 0\n",
    "OBSERVATION_WINDOW_SIZE = 24 # Probably we should put it as param ?\n",
    "\n",
    "class SimpleTradingEnv(gym.Env):\n",
    "    \n",
    "    metadata = {'render.modes': ['live', 'human', 'none']}\n",
    "    visualization = None\n",
    "\n",
    "    def __init__(self, df_scaled, df_normal, trading_fee):\n",
    "        \n",
    "        self.df_scaled = df_scaled.reset_index(drop=True)\n",
    "        self.df_normal = df_normal.reset_index(drop=True)\n",
    "        self.window_size = OBSERVATION_WINDOW_SIZE\n",
    "        self.prices, self.features = self._process_data(df_scaled)\n",
    "        # The shape of the observation is (window_size * features + environment_features) the environment_features are: quote_asset, base_asset, net_worth. The entire observation is flattened in a 1D np array. \n",
    "        self.obs_shape = ((OBSERVATION_WINDOW_SIZE * self.features.shape[1] + 3),)\n",
    "\n",
    "\n",
    "        # Action space\n",
    "        #self.action_space = spaces.Box(low=np.array([0, 0]), high=np.array([3.0, 1.0]), dtype=np.float32)\n",
    "        self.action_space = spaces.MultiDiscrete([3, 100])\n",
    "        # Observation space\n",
    "        self.observation_space = spaces.Box(low=-1, high = 1, shape=self.obs_shape, dtype=np.float32)\n",
    "\n",
    "        # Initialize the episode environment\n",
    "\n",
    "        self._start_candle = OBSERVATION_WINDOW_SIZE # We assume that the first observation is not the first row of the dataframe, in order to avoid the case where there are no calculated indicators.\n",
    "        self._end_candle = len(self.features) - 1\n",
    "        self._trading_fee = trading_fee\n",
    "\n",
    "        self._quote_asset = None\n",
    "        self._base_asset = None\n",
    "        self._done = None\n",
    "        self._current_candle = None\n",
    "        self._net_worth = None\n",
    "        self._previous_net_worth = None\n",
    "\n",
    "        # Render and analysis data\n",
    "        self._total_reward_accumulated = None\n",
    "        self.trade_history = None\n",
    "        self._first_rendering = None\n",
    "        \n",
    "\n",
    "    def reset(self):\n",
    "        self._done = False\n",
    "        self._current_candle = self._start_candle\n",
    "        self._quote_asset = INITIAL_QUOTE_ASSET\n",
    "        self._base_asset = INITIAL_BASE_ASSET \n",
    "        self._net_worth = INITIAL_QUOTE_ASSET # at the begining our net worth is the initial quote asset\n",
    "        self._previous_net_worth = INITIAL_QUOTE_ASSET # at the begining our previous net worth is the initial quote asset\n",
    "        self._total_reward_accumulated = 0.\n",
    "        self._first_rendering = True\n",
    "        self.trade_history = []\n",
    "        return self._get_observation()\n",
    "\n",
    "    def _take_action(self, action):\n",
    "        self._done = False\n",
    "        current_price = random.uniform(\n",
    "            self.df_normal.loc[self._current_candle, \"low\"], self.df_normal.loc[self._current_candle, \"high\"])\n",
    "\n",
    "        # print('action: ', action)\n",
    "        # print('action type: ', action[0])\n",
    "        # print('action amount: ', action[1])\n",
    "        action_type = action[0]\n",
    "        amount = action[1] / 100\n",
    "        \n",
    "        if action_type < 1:\n",
    "            # Buy % assets\n",
    "            # Determine the maximum amount of quote asset that can be bought\n",
    "            available_amount_to_buy_with = self._quote_asset / current_price\n",
    "            # Buy only the amount that agent chose\n",
    "            assets_bought = available_amount_to_buy_with * amount\n",
    "            # Update the quote asset balance\n",
    "            self._quote_asset -= assets_bought * current_price\n",
    "            # Update the base asset\n",
    "            self._base_asset += assets_bought\n",
    "            # substract trading fee from base asset based on the amount bought\n",
    "            self._base_asset -= self._trading_fee * assets_bought\n",
    "\n",
    "            # Add to trade history the amount bought if greater than 0\n",
    "            if assets_bought > 0:\n",
    "                self.trade_history.append({'step': self._current_candle, 'type': 'Buy', 'amount': assets_bought, 'price': current_price, 'total' : assets_bought * current_price, 'percent_amount': action[1]})\n",
    "        \n",
    "\n",
    "        elif action_type < 2:\n",
    "            # Sell % assets\n",
    "            # Determine the amount of base asset that can be sold\n",
    "            amount_to_sell = self._base_asset * amount\n",
    "            received_quote_asset = amount_to_sell * current_price\n",
    "            # Update the quote asset\n",
    "            self._quote_asset += received_quote_asset\n",
    "            # Update the base asset\n",
    "            self._base_asset -= amount_to_sell\n",
    "            \n",
    "            # substract trading fee from quote asset based on the amount sold\n",
    "            self._quote_asset -= self._trading_fee * received_quote_asset\n",
    "\n",
    "            # Add to trade history the amount sold if greater than 0\n",
    "            if amount_to_sell > 0:\n",
    "                self.trade_history.append({'step': self._current_candle, 'type': 'Sell', 'amount': amount_to_sell, 'price': current_price, 'total' : received_quote_asset, 'percent_amount': action[1]})\n",
    "\n",
    "        else:\n",
    "            # Hold\n",
    "            self.trade_history.append({'step': self._current_candle, 'type': 'Hold', 'amount': '0', 'price': current_price, 'total' : 0, 'percent_amount': action[1]})\n",
    "\n",
    "\n",
    "        # Update the current net worth\n",
    "        self._net_worth = self._base_asset * current_price + self._quote_asset\n",
    "\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Returns the next observation, reward, done and info.\n",
    "        \"\"\"\n",
    "        \n",
    "        self._take_action(action)\n",
    "\n",
    "        # Calculate reward comparing the current net worth with the previous net worth\n",
    "        reward = self._net_worth - self._previous_net_worth\n",
    "\n",
    "        self._total_reward_accumulated += reward\n",
    "\n",
    "        # Update the previous net worth to be the current net worth after the reward has been applied\n",
    "        self._previous_net_worth = self._net_worth\n",
    "\n",
    "        obs = self._get_observation()\n",
    "        # Update the info and add it to history data\n",
    "        info = dict (\n",
    "            total_reward_accumulated = self._total_reward_accumulated,\n",
    "            net_worth = self._net_worth,\n",
    "            last_action_type = self.trade_history[-1]['type'] if len(self.trade_history) > 0 else None,\n",
    "            last_action_amount = self.trade_history[-1]['amount'] if len(self.trade_history) > 0 else None,\n",
    "            current_step = self._current_candle\n",
    "        )\n",
    "\n",
    "        self._current_candle += 1\n",
    "\n",
    "        self._done = self._net_worth <= 0 or self._current_candle >= len(\n",
    "            self.df_scaled.loc[:, 'open'].values)\n",
    "        \n",
    "        return obs, reward, self._done, info\n",
    "\n",
    "\n",
    "    def _get_observation(self):\n",
    "        \"\"\"\n",
    "        Returns the current observation.\n",
    "        \"\"\"\n",
    "        data_frame = self.features[(self._current_candle - self.window_size):self._current_candle]\n",
    "        data_frame = data_frame.flatten()\n",
    "\n",
    "        # Scale all the values to be between -1 and 1\n",
    "        obs = np.append(data_frame, np.array([self._net_worth / MAX_NET_WORTH , self._quote_asset / MAX_NUM_QUOTE_OR_BASE_ASSET, self._base_asset / MAX_NUM_QUOTE_OR_BASE_ASSET], dtype=np.float32))\n",
    "\n",
    "        return obs\n",
    "\n",
    "\n",
    "    def render(self, mode='human', **kwargs):\n",
    "        \"\"\"\n",
    "        Renders a plot with trades made by the agent.\n",
    "        \"\"\"\n",
    "        \n",
    "        if mode == 'human':\n",
    "            print(f'Accumulated Reward: {self._total_reward_accumulated} ---- Current Net Worth: {self._net_worth}')\n",
    "            print(f'Current Quote asset: {self._quote_asset} ---- Current Base asset: {self._base_asset}')\n",
    "            print(f'Number of trades: {len(self.trade_history)}')\n",
    "        \n",
    "            if(len(self.trade_history) > 0):\n",
    "                print(f'Last Action: {self.trade_history[-1][\"type\"]} {self.trade_history[-1][\"amount\"]} assets ({self.trade_history[-1][\"percent_amount\"]} %) at price {self.trade_history[-1][\"price\"]}, total: {self.trade_history[-1][\"total\"]}')\n",
    "            print(f'--------------------------------------------------------------------------------------')\n",
    "        elif mode == 'live':\n",
    "            if self.visualization == None:\n",
    "                self.visualization = LiveTradingGraph(self.df_normal, kwargs.get('title', None))\n",
    "\n",
    "            if self._current_candle > OBSERVATION_WINDOW_SIZE:\n",
    "                self.visualization.render(self._current_candle, self._net_worth, self.trade_history, window_size=OBSERVATION_WINDOW_SIZE)\n",
    "\n",
    "    def close(self):\n",
    "        if self.visualization != None:\n",
    "            self.visualization.close()\n",
    "            self.visualization = None\n",
    "         \n",
    "\n",
    "    def _process_data(self, df_scaled):\n",
    "        \"\"\"\n",
    "        Processes the dataframe into features.\n",
    "        \"\"\"\n",
    "\n",
    "        prices = self.df_scaled.loc[:, 'close'].to_numpy(dtype=np.float32)\n",
    "\n",
    "        data_frame = df_scaled.iloc[:, 1:] # drop first column which is date TODO: Should be fixed outside of this class\n",
    "\n",
    "        # Convert df to numpy array\n",
    "        return prices, data_frame.to_numpy(dtype=np.float32)\n",
    "\n",
    "    def _generate_action_data_tuple(self, action, price):\n",
    "        \"\"\"\n",
    "        Returns the action type and amount as tuple\n",
    "        \"\"\"\n",
    "\n",
    "        action_type_name = self._get_human_readable_action(action)\n",
    "\n",
    "        amount = action[1]\n",
    "        return (action_type_name, amount, price)\n",
    "\n",
    "    def _get_human_readable_action(self, action):\n",
    "        # if action is lower than 1 than it's buy action, if action is lower than 2 than it's sell action otherwise it's hold action\n",
    "        action_type_name = None\n",
    "        if action[0] < 1:\n",
    "            action_type_name = 'Buy'\n",
    "        elif action[0] < 2:\n",
    "            action_type_name = 'Sell'\n",
    "        else:\n",
    "            action_type_name = 'Hold'\n",
    "        \n",
    "        return action_type_name    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b670e8a2",
   "metadata": {},
   "source": [
    "### Initialize, validate the environment and run a random test of x steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca8fc3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.logger import configure\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "n_envs = 20\n",
    "trading_fee = 0.0075\n",
    "env = SimpleTradingEnv(X_train_scaled, X_train, trading_fee)\n",
    "# check_env(env) ### Already tested and working :)\n",
    "env = make_vec_env(lambda: env,vec_env_cls=SubprocVecEnv, n_envs=n_envs)\n",
    "\n",
    "# obs = env.reset()\n",
    "# #Trying some random action sample\n",
    "# for i in range(5):\n",
    "#     # Take a random action\n",
    "#     actions = np.array([env.action_space.sample() for _ in range(env.num_envs)])\n",
    "#     print(actions)\n",
    "#     env.step_async(actions)\n",
    "#     obs, reward, done, info = env.step_wait()\n",
    "#     print(info)\n",
    "#     if done[0]:\n",
    "#         break\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219979f3",
   "metadata": {},
   "source": [
    "### Create an evaluation environment used to save only the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea018b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "# Separate evaluation env\n",
    "eval_env = SimpleTradingEnv(X_valid_scaled, X_valid, trading_fee)\n",
    "# check_env(eval_env) ### Already tested and working :)\n",
    "eval_env = make_vec_env(lambda: eval_env,vec_env_cls=SubprocVecEnv, n_envs=n_envs)\n",
    "# Use deterministic actions for evaluation\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path='model/PPO_best/',\n",
    "                             log_path='model/logs/', eval_freq=max(500000 // n_envs, 1),\n",
    "                             deterministic=False, render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0adeedc",
   "metadata": {},
   "source": [
    "### Create a checkpoint callback to save the model periodically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f260298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(save_freq=max(500000 // n_envs, 1), save_path='model/PPO/',\n",
    "                                         name_prefix='rl_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c019b2b-943a-4889-927f-38b34e52ac67",
   "metadata": {},
   "source": [
    "# Initialize the model and start learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "xEE0eNix7KSh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "xEE0eNix7KSh",
    "outputId": "16059380-7c2e-4b06-c4c6-ee28b0492ee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Logging to logs/PPO_2\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 3573  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 11    |\n",
      "|    total_timesteps | 40960 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1037         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062607853 |\n",
      "|    clip_fraction        | 0.0919       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | -4.36e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.98e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00727     |\n",
      "|    value_loss           | 6.46e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 873        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 140        |\n",
      "|    total_timesteps      | 122880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00892256 |\n",
      "|    clip_fraction        | 0.0757     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.69      |\n",
      "|    explained_variance   | -0.956     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 12.9       |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0098    |\n",
      "|    value_loss           | 26.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 811         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012961013 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.786       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 3.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 785         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014387883 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.66       |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.334       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 1.61        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.14e+04   |\n",
      "|    ep_rew_mean          | -1e+04     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 762        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 322        |\n",
      "|    total_timesteps      | 245760     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01714444 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.63      |\n",
      "|    explained_variance   | 0.878      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.174      |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    value_loss           | 1.38       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.14e+04     |\n",
      "|    ep_rew_mean          | -1e+04       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 739          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 387          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063747205 |\n",
      "|    clip_fraction        | 0.0307       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.62        |\n",
      "|    explained_variance   | -0.119       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    value_loss           | 3.82e+03     |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.callbacks import CallbackList\n",
    "\n",
    "cwd = os.getcwd()\n",
    "logdir = \"logs\"\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "\n",
    "\n",
    "callback_list = CallbackList([checkpoint_callback, eval_callback])\n",
    "\n",
    "number_of_epochs = 10000\n",
    "total_timesteps = len(X_train_scaled) * number_of_epochs\n",
    "\n",
    "model = PPO(MlpPolicy, env, verbose=1, tensorboard_log=logdir, device='cuda')\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps, tb_log_name=\"PPO\", callback=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76622b8-b54e-4376-ad23-1d7e2f538b70",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfdf445-13cb-4890-8524-209e8fca979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to load the model that performed the best, you can check it up in the tensorboard\n",
    "# usualy it's the one with the highest rollout/ep_rew_mean, you can identify it by looking at the step number\n",
    "model_path = \"model/PPO_best/best_model.zip\"\n",
    "loaded_model = PPO.load(model_path, env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1d1659-27b9-451a-b575-648a77db069b",
   "metadata": {},
   "source": [
    "# Run an evaluation test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce9eb9e-a3d3-41ef-b615-6a23eb9db0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward:-9985.84 +/- 4.46\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(loaded_model, env, n_eval_episodes=5, deterministic=False)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83707a6-6586-4d43-a757-f4b249795735",
   "metadata": {},
   "source": [
    "# Render results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85483ff5-7229-493a-9150-87f583e8b504",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: [ 0 73]\n",
      "Action: [ 1 21]\n",
      "Action: [ 0 24]\n",
      "Action: [0 7]\n",
      "Action: [ 1 32]\n",
      "Action: [ 0 62]\n",
      "Action: [ 1 55]\n",
      "Action: [0 7]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 83]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 44]\n",
      "Action: [ 0 12]\n",
      "Action: [ 0 37]\n",
      "Action: [ 0 37]\n",
      "Action: [1 0]\n",
      "Action: [ 0 13]\n",
      "Action: [0 0]\n",
      "Action: [ 0 15]\n",
      "Action: [ 0 76]\n",
      "Action: [ 0 76]\n",
      "Action: [1 6]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 78]\n",
      "Action: [ 1 94]\n",
      "Action: [ 1 32]\n",
      "Action: [ 1 65]\n",
      "Action: [ 0 92]\n",
      "Action: [ 1 87]\n",
      "Action: [ 0 53]\n",
      "Action: [ 1 19]\n",
      "Action: [ 0 17]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 51]\n",
      "Action: [ 1 24]\n",
      "Action: [ 1 11]\n",
      "Action: [ 1 25]\n",
      "Action: [ 0 43]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 94]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 87]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 85]\n",
      "Action: [0 7]\n",
      "Action: [ 0 44]\n",
      "Action: [1 3]\n",
      "Action: [ 0 94]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 70]\n",
      "Action: [ 1 92]\n",
      "Action: [ 0 14]\n",
      "Action: [ 1 19]\n",
      "Action: [ 1 66]\n",
      "Action: [ 1 57]\n",
      "Action: [ 0 46]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 15]\n",
      "Action: [ 1 30]\n",
      "Action: [ 1 90]\n",
      "Action: [ 1 19]\n",
      "Action: [1 7]\n",
      "Action: [ 1 73]\n",
      "Action: [ 1 29]\n",
      "Action: [0 1]\n",
      "Action: [ 0 62]\n",
      "Action: [0 1]\n",
      "Action: [ 1 35]\n",
      "Action: [ 0 98]\n",
      "Action: [ 1 16]\n",
      "Action: [ 0 86]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 87]\n",
      "Action: [ 0 46]\n",
      "Action: [ 1 20]\n",
      "Action: [ 1 41]\n",
      "Action: [ 0 45]\n",
      "Action: [ 0 37]\n",
      "Action: [ 0 48]\n",
      "Action: [ 1 17]\n",
      "Action: [1 9]\n",
      "Action: [ 0 45]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 49]\n",
      "Action: [0 1]\n",
      "Action: [0 1]\n",
      "Action: [ 0 65]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 68]\n",
      "Action: [ 0 47]\n",
      "Action: [ 1 91]\n",
      "Action: [1 9]\n",
      "Action: [1 5]\n",
      "Action: [0 7]\n",
      "Action: [0 1]\n",
      "Action: [ 1 98]\n",
      "Action: [ 0 19]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 13]\n",
      "Action: [1 1]\n",
      "Action: [ 0 45]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 43]\n",
      "Action: [ 0 30]\n",
      "Action: [ 0 19]\n",
      "Action: [ 0 85]\n",
      "Action: [ 1 80]\n",
      "Action: [ 1 81]\n",
      "Action: [ 0 51]\n",
      "Action: [ 1 68]\n",
      "Action: [ 0 59]\n",
      "Action: [ 0 25]\n",
      "Action: [ 0 64]\n",
      "Action: [ 0 80]\n",
      "Action: [0 9]\n",
      "Action: [ 1 78]\n",
      "Action: [ 0 37]\n",
      "Action: [ 0 66]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 23]\n",
      "Action: [ 0 88]\n",
      "Action: [ 0 76]\n",
      "Action: [ 1 53]\n",
      "Action: [ 1 74]\n",
      "Action: [ 0 65]\n",
      "Action: [ 0 79]\n",
      "Action: [ 0 36]\n",
      "Action: [ 0 65]\n",
      "Action: [ 1 97]\n",
      "Action: [ 1 10]\n",
      "Action: [1 8]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 44]\n",
      "Action: [ 0 29]\n",
      "Action: [0 4]\n",
      "Action: [ 1 23]\n",
      "Action: [ 0 86]\n",
      "Action: [ 0 37]\n",
      "Action: [ 0 37]\n",
      "Action: [0 1]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 83]\n",
      "Action: [ 0 19]\n",
      "Action: [ 0 54]\n",
      "Action: [ 0 69]\n",
      "Action: [1 6]\n",
      "Action: [ 1 10]\n",
      "Action: [ 0 19]\n",
      "Action: [0 8]\n",
      "Action: [1 7]\n",
      "Action: [ 1 29]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 66]\n",
      "Action: [0 6]\n",
      "Action: [ 0 44]\n",
      "Action: [ 0 63]\n",
      "Action: [ 1 64]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 89]\n",
      "Action: [ 1 75]\n",
      "Action: [ 1 44]\n",
      "Action: [ 0 37]\n",
      "Action: [ 0 92]\n",
      "Action: [ 0 27]\n",
      "Action: [ 1 42]\n",
      "Action: [ 1 64]\n",
      "Action: [ 1 98]\n",
      "Action: [ 1 34]\n",
      "Action: [ 1 24]\n",
      "Action: [ 1 80]\n",
      "Action: [ 0 14]\n",
      "Action: [ 0 54]\n",
      "Action: [ 0 43]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 46]\n",
      "Action: [1 8]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 47]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 39]\n",
      "Action: [ 0 35]\n",
      "Action: [ 0 15]\n",
      "Action: [0 1]\n",
      "Action: [ 0 53]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 86]\n",
      "Action: [0 7]\n",
      "Action: [0 2]\n",
      "Action: [ 0 35]\n",
      "Action: [ 0 14]\n",
      "Action: [ 1 55]\n",
      "Action: [0 7]\n",
      "Action: [ 0 53]\n",
      "Action: [ 1 24]\n",
      "Action: [ 0 60]\n",
      "Action: [ 1 51]\n",
      "Action: [ 0 20]\n",
      "Action: [ 1 56]\n",
      "Action: [ 1 27]\n",
      "Action: [ 1 72]\n",
      "Action: [ 0 67]\n",
      "Action: [ 1 62]\n",
      "Action: [ 1 64]\n",
      "Action: [0 1]\n",
      "Action: [ 1 69]\n",
      "Action: [ 1 37]\n",
      "Action: [ 1 49]\n",
      "Action: [ 1 63]\n",
      "Action: [ 1 39]\n",
      "Action: [ 1 39]\n",
      "Action: [ 0 78]\n",
      "Action: [ 0 24]\n",
      "Action: [ 0 84]\n",
      "Action: [ 1 87]\n",
      "Action: [1 5]\n",
      "Action: [ 1 57]\n",
      "Action: [ 1 92]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 14]\n",
      "Action: [1 6]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 57]\n",
      "Action: [0 4]\n",
      "Action: [ 1 11]\n",
      "Action: [ 1 69]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 16]\n",
      "Action: [ 1 92]\n",
      "Action: [ 1 15]\n",
      "Action: [ 1 61]\n",
      "Action: [ 0 71]\n",
      "Action: [ 1 57]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 70]\n",
      "Action: [ 1 14]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 84]\n",
      "Action: [ 0 49]\n",
      "Action: [ 1 87]\n",
      "Action: [ 0 86]\n",
      "Action: [ 0 44]\n",
      "Action: [ 0 74]\n",
      "Action: [ 1 49]\n",
      "Action: [ 0 60]\n",
      "Action: [0 4]\n",
      "Action: [ 1 78]\n",
      "Action: [ 0 84]\n",
      "Action: [ 1 57]\n",
      "Action: [ 0 10]\n",
      "Action: [ 0 43]\n",
      "Action: [ 1 39]\n",
      "Action: [0 8]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 87]\n",
      "Action: [ 0 43]\n",
      "Action: [ 1 35]\n",
      "Action: [ 0 45]\n",
      "Action: [ 1 31]\n",
      "Action: [ 1 85]\n",
      "Action: [ 0 12]\n",
      "Action: [0 1]\n",
      "Action: [ 1 61]\n",
      "Action: [ 0 87]\n",
      "Action: [ 0 17]\n",
      "Action: [0 3]\n",
      "Action: [0 9]\n",
      "Action: [ 1 50]\n",
      "Action: [ 0 78]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 46]\n",
      "Action: [ 0 80]\n",
      "Action: [ 1 85]\n",
      "Action: [ 1 91]\n",
      "Action: [0 7]\n",
      "Action: [ 0 57]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 19]\n",
      "Action: [ 0 86]\n",
      "Action: [ 0 75]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 49]\n",
      "Action: [ 0 52]\n",
      "Action: [ 0 82]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 11]\n",
      "Action: [0 9]\n",
      "Action: [0 8]\n",
      "Action: [ 1 64]\n",
      "Action: [ 1 98]\n",
      "Action: [1 1]\n",
      "Action: [0 1]\n",
      "Action: [ 1 48]\n",
      "Action: [ 1 51]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 32]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 26]\n",
      "Action: [ 0 81]\n",
      "Action: [ 0 16]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 22]\n",
      "Action: [ 0 44]\n",
      "Action: [ 0 60]\n",
      "Action: [ 1 85]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 75]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 72]\n",
      "Action: [ 0 32]\n",
      "Action: [ 0 64]\n",
      "Action: [ 0 46]\n",
      "Action: [ 0 77]\n",
      "Action: [ 1 77]\n",
      "Action: [1 5]\n",
      "Action: [0 0]\n",
      "Action: [ 1 71]\n",
      "Action: [ 1 97]\n",
      "Action: [1 9]\n",
      "Action: [1 1]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 10]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 51]\n",
      "Action: [ 1 21]\n",
      "Action: [0 8]\n",
      "Action: [ 1 87]\n",
      "Action: [ 1 45]\n",
      "Action: [1 1]\n",
      "Action: [0 8]\n",
      "Action: [1 0]\n",
      "Action: [ 0 82]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 86]\n",
      "Action: [ 0 20]\n",
      "Action: [ 1 62]\n",
      "Action: [ 1 55]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 77]\n",
      "Action: [ 0 27]\n",
      "Action: [ 0 73]\n",
      "Action: [ 1 64]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 80]\n",
      "Action: [ 0 46]\n",
      "Action: [0 1]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 81]\n",
      "Action: [ 1 88]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 89]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 32]\n",
      "Action: [ 1 88]\n",
      "Action: [ 1 98]\n",
      "Action: [0 8]\n",
      "Action: [1 1]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 80]\n",
      "Action: [ 0 64]\n",
      "Action: [ 0 77]\n",
      "Action: [1 1]\n",
      "Action: [0 1]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 83]\n",
      "Action: [ 0 41]\n",
      "Action: [ 0 77]\n",
      "Action: [0 1]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 63]\n",
      "Action: [ 0 20]\n",
      "Action: [ 1 73]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 85]\n",
      "Action: [ 1 52]\n",
      "Action: [ 0 98]\n",
      "Action: [ 1 45]\n",
      "Action: [ 1 70]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 90]\n",
      "Action: [ 1 86]\n",
      "Action: [ 0 50]\n",
      "Action: [ 0 78]\n",
      "Action: [ 0 10]\n",
      "Action: [ 1 89]\n",
      "Action: [0 1]\n",
      "Action: [ 1 29]\n",
      "Action: [ 1 52]\n",
      "Action: [ 0 23]\n",
      "Action: [ 0 33]\n",
      "Action: [0 0]\n",
      "Action: [ 0 82]\n",
      "Action: [ 0 56]\n",
      "Action: [ 1 30]\n",
      "Action: [ 0 50]\n",
      "Action: [ 1 17]\n",
      "Action: [ 0 14]\n",
      "Action: [ 0 74]\n",
      "Action: [1 8]\n",
      "Action: [ 0 70]\n",
      "Action: [ 1 14]\n",
      "Action: [ 0 25]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 77]\n",
      "Action: [ 0 17]\n",
      "Action: [ 1 44]\n",
      "Action: [ 0 48]\n",
      "Action: [1 8]\n",
      "Action: [ 1 49]\n",
      "Action: [ 1 24]\n",
      "Action: [ 0 66]\n",
      "Action: [1 3]\n",
      "Action: [ 0 48]\n",
      "Action: [ 0 14]\n",
      "Action: [1 7]\n",
      "Action: [ 1 76]\n",
      "Action: [ 0 70]\n",
      "Action: [ 0 47]\n",
      "Action: [ 0 56]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 63]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 47]\n",
      "Action: [ 1 15]\n",
      "Action: [ 0 29]\n",
      "Action: [ 1 73]\n",
      "Action: [ 0 80]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 52]\n",
      "Action: [ 1 95]\n",
      "Action: [ 0 39]\n",
      "Action: [ 1 44]\n",
      "Action: [0 1]\n",
      "Action: [ 0 66]\n",
      "Action: [ 1 37]\n",
      "Action: [ 0 90]\n",
      "Action: [ 1 93]\n",
      "Action: [ 0 35]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 32]\n",
      "Action: [ 0 39]\n",
      "Action: [ 1 61]\n",
      "Action: [0 9]\n",
      "Action: [ 0 88]\n",
      "Action: [1 2]\n",
      "Action: [ 0 46]\n",
      "Action: [ 1 85]\n",
      "Action: [ 0 68]\n",
      "Action: [ 0 94]\n",
      "Action: [0 1]\n",
      "Action: [ 1 51]\n",
      "Action: [1 9]\n",
      "Action: [ 0 69]\n",
      "Action: [ 1 46]\n",
      "Action: [0 8]\n",
      "Action: [ 1 92]\n",
      "Action: [ 0 17]\n",
      "Action: [ 1 44]\n",
      "Action: [ 1 92]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 45]\n",
      "Action: [ 1 86]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 16]\n",
      "Action: [ 0 97]\n",
      "Action: [ 0 41]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 35]\n",
      "Action: [ 0 78]\n",
      "Action: [ 0 42]\n",
      "Action: [ 0 43]\n",
      "Action: [ 1 55]\n",
      "Action: [ 1 13]\n",
      "Action: [1 0]\n",
      "Action: [ 1 46]\n",
      "Action: [ 0 54]\n",
      "Action: [0 5]\n",
      "Action: [0 0]\n",
      "Action: [ 0 83]\n",
      "Action: [0 6]\n",
      "Action: [ 0 64]\n",
      "Action: [ 0 66]\n",
      "Action: [ 1 20]\n",
      "Action: [1 1]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 88]\n",
      "Action: [ 0 43]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 50]\n",
      "Action: [ 0 72]\n",
      "Action: [ 0 17]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 87]\n",
      "Action: [0 9]\n",
      "Action: [ 0 24]\n",
      "Action: [ 1 10]\n",
      "Action: [ 0 71]\n",
      "Action: [ 1 16]\n",
      "Action: [ 1 78]\n",
      "Action: [ 0 70]\n",
      "Action: [ 0 77]\n",
      "Action: [ 1 38]\n",
      "Action: [0 1]\n",
      "Action: [ 0 76]\n",
      "Action: [ 1 51]\n",
      "Action: [ 0 45]\n",
      "Action: [ 0 57]\n",
      "Action: [ 1 35]\n",
      "Action: [ 1 69]\n",
      "Action: [ 1 97]\n",
      "Action: [1 6]\n",
      "Action: [0 2]\n",
      "Action: [ 0 49]\n",
      "Action: [0 1]\n",
      "Action: [ 0 86]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 88]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 52]\n",
      "Action: [ 1 33]\n",
      "Action: [0 3]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 65]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 47]\n",
      "Action: [ 0 75]\n",
      "Action: [ 0 37]\n",
      "Action: [0 8]\n",
      "Action: [1 8]\n",
      "Action: [ 1 62]\n",
      "Action: [ 1 79]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 62]\n",
      "Action: [ 1 46]\n",
      "Action: [ 0 17]\n",
      "Action: [ 1 64]\n",
      "Action: [ 1 99]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 63]\n",
      "Action: [ 1 80]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 57]\n",
      "Action: [ 0 24]\n",
      "Action: [ 1 32]\n",
      "Action: [ 0 60]\n",
      "Action: [ 0 50]\n",
      "Action: [ 0 15]\n",
      "Action: [ 0 42]\n",
      "Action: [ 0 60]\n",
      "Action: [ 1 53]\n",
      "Action: [ 1 39]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 16]\n",
      "Action: [ 0 75]\n",
      "Action: [1 1]\n",
      "Action: [ 0 83]\n",
      "Action: [ 0 92]\n",
      "Action: [ 1 74]\n",
      "Action: [ 0 50]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 14]\n",
      "Action: [ 0 99]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 96]\n",
      "Action: [ 1 80]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 49]\n",
      "Action: [ 1 48]\n",
      "Action: [ 1 99]\n",
      "Action: [ 1 10]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 45]\n",
      "Action: [ 1 44]\n",
      "Action: [ 0 72]\n",
      "Action: [ 0 19]\n",
      "Action: [ 1 88]\n",
      "Action: [ 1 46]\n",
      "Action: [ 0 29]\n",
      "Action: [1 1]\n",
      "Action: [ 0 98]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 62]\n",
      "Action: [ 0 70]\n",
      "Action: [ 1 47]\n",
      "Action: [1 8]\n",
      "Action: [ 1 34]\n",
      "Action: [ 0 88]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 32]\n",
      "Action: [ 0 80]\n",
      "Action: [ 1 85]\n",
      "Action: [ 1 51]\n",
      "Action: [ 0 31]\n",
      "Action: [ 1 51]\n",
      "Action: [ 1 85]\n",
      "Action: [ 1 77]\n",
      "Action: [ 1 50]\n",
      "Action: [ 0 52]\n",
      "Action: [ 1 96]\n",
      "Action: [0 1]\n",
      "Action: [ 0 70]\n",
      "Action: [ 0 71]\n",
      "Action: [ 0 81]\n",
      "Action: [ 1 99]\n",
      "Action: [ 0 35]\n",
      "Action: [ 1 57]\n",
      "Action: [ 0 12]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 17]\n",
      "Action: [ 1 41]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 16]\n",
      "Action: [ 1 80]\n",
      "Action: [ 1 39]\n",
      "Action: [ 1 15]\n",
      "Action: [1 3]\n",
      "Action: [1 1]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 71]\n",
      "Action: [ 0 88]\n",
      "Action: [ 1 14]\n",
      "Action: [ 0 76]\n",
      "Action: [ 0 52]\n",
      "Action: [ 0 81]\n",
      "Action: [0 4]\n",
      "Action: [ 0 35]\n",
      "Action: [ 0 16]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 75]\n",
      "Action: [0 8]\n",
      "Action: [ 0 74]\n",
      "Action: [ 0 74]\n",
      "Action: [ 0 71]\n",
      "Action: [ 1 30]\n",
      "Action: [ 1 73]\n",
      "Action: [ 0 64]\n",
      "Action: [ 1 82]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 15]\n",
      "Action: [ 0 98]\n",
      "Action: [ 1 29]\n",
      "Action: [ 1 45]\n",
      "Action: [ 0 37]\n",
      "Action: [ 0 90]\n",
      "Action: [ 1 39]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 39]\n",
      "Action: [ 0 42]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 72]\n",
      "Action: [ 1 77]\n",
      "Action: [ 1 39]\n",
      "Action: [ 1 78]\n",
      "Action: [ 1 77]\n",
      "Action: [0 6]\n",
      "Action: [ 0 10]\n",
      "Action: [ 0 54]\n",
      "Action: [ 0 15]\n",
      "Action: [ 1 97]\n",
      "Action: [ 0 45]\n",
      "Action: [ 1 16]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 42]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 36]\n",
      "Action: [ 1 17]\n",
      "Action: [0 4]\n",
      "Action: [ 0 14]\n",
      "Action: [ 0 92]\n",
      "Action: [ 1 80]\n",
      "Action: [ 0 52]\n",
      "Action: [ 0 36]\n",
      "Action: [ 0 76]\n",
      "Action: [ 1 17]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 20]\n",
      "Action: [ 1 53]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 19]\n",
      "Action: [ 0 39]\n",
      "Action: [1 1]\n",
      "Action: [ 1 25]\n",
      "Action: [ 0 69]\n",
      "Action: [ 1 35]\n",
      "Action: [ 0 65]\n",
      "Action: [ 0 31]\n",
      "Action: [ 1 98]\n",
      "Action: [ 0 32]\n",
      "Action: [ 1 60]\n",
      "Action: [ 0 80]\n",
      "Action: [0 1]\n",
      "Action: [ 1 65]\n",
      "Action: [ 1 53]\n",
      "Action: [ 0 12]\n",
      "Action: [ 0 80]\n",
      "Action: [ 1 10]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 86]\n",
      "Action: [ 0 86]\n",
      "Action: [ 1 87]\n",
      "Action: [0 1]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 60]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 23]\n",
      "Action: [ 1 45]\n",
      "Action: [ 0 83]\n",
      "Action: [ 1 21]\n",
      "Action: [ 0 69]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 75]\n",
      "Action: [ 1 44]\n",
      "Action: [ 0 48]\n",
      "Action: [ 0 56]\n",
      "Action: [ 0 35]\n",
      "Action: [ 0 30]\n",
      "Action: [ 1 70]\n",
      "Action: [ 1 96]\n",
      "Action: [ 0 62]\n",
      "Action: [ 1 34]\n",
      "Action: [ 1 56]\n",
      "Action: [0 7]\n",
      "Action: [ 0 34]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 44]\n",
      "Action: [ 1 43]\n",
      "Action: [ 0 37]\n",
      "Action: [ 0 22]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 55]\n",
      "Action: [ 1 41]\n",
      "Action: [ 1 65]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 65]\n",
      "Action: [ 0 10]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 42]\n",
      "Action: [ 1 51]\n",
      "Action: [ 1 56]\n",
      "Action: [0 1]\n",
      "Action: [ 1 76]\n",
      "Action: [ 0 71]\n",
      "Action: [ 1 86]\n",
      "Action: [ 0 43]\n",
      "Action: [ 1 12]\n",
      "Action: [ 0 23]\n",
      "Action: [ 0 63]\n",
      "Action: [ 0 57]\n",
      "Action: [ 0 92]\n",
      "Action: [ 1 99]\n",
      "Action: [ 1 29]\n",
      "Action: [ 1 83]\n",
      "Action: [0 6]\n",
      "Action: [ 1 15]\n",
      "Action: [ 0 15]\n",
      "Action: [ 0 52]\n",
      "Action: [ 0 67]\n",
      "Action: [ 1 32]\n",
      "Action: [ 1 22]\n",
      "Action: [ 0 84]\n",
      "Action: [ 1 16]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 21]\n",
      "Action: [0 3]\n",
      "Action: [0 8]\n",
      "Action: [ 0 33]\n",
      "Action: [ 1 12]\n",
      "Action: [ 1 57]\n",
      "Action: [ 1 25]\n",
      "Action: [ 1 82]\n",
      "Action: [ 0 78]\n",
      "Action: [ 1 76]\n",
      "Action: [ 0 98]\n",
      "Action: [ 0 42]\n",
      "Action: [ 0 45]\n",
      "Action: [ 0 46]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 81]\n",
      "Action: [ 1 14]\n",
      "Action: [ 0 46]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 50]\n",
      "Action: [ 0 34]\n",
      "Action: [ 0 22]\n",
      "Action: [0 2]\n",
      "Action: [ 0 36]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 41]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 65]\n",
      "Action: [ 0 29]\n",
      "Action: [ 1 45]\n",
      "Action: [ 0 11]\n",
      "Action: [1 1]\n",
      "Action: [ 1 46]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 13]\n",
      "Action: [0 1]\n",
      "Action: [ 1 49]\n",
      "Action: [ 0 57]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 10]\n",
      "Action: [ 0 21]\n",
      "Action: [ 1 62]\n",
      "Action: [ 1 67]\n",
      "Action: [ 0 36]\n",
      "Action: [ 0 33]\n",
      "Action: [ 0 67]\n",
      "Action: [ 1 92]\n",
      "Action: [0 1]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 87]\n",
      "Action: [ 0 68]\n",
      "Action: [ 0 64]\n",
      "Action: [ 0 30]\n",
      "Action: [ 0 55]\n",
      "Action: [0 1]\n",
      "Action: [0 1]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 43]\n",
      "Action: [ 0 17]\n",
      "Action: [ 0 68]\n",
      "Action: [ 0 37]\n",
      "Action: [0 1]\n",
      "Action: [0 1]\n",
      "Action: [ 0 29]\n",
      "Action: [0 6]\n",
      "Action: [ 0 43]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 60]\n",
      "Action: [ 0 41]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 74]\n",
      "Action: [ 1 41]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 49]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 96]\n",
      "Action: [ 0 73]\n",
      "Action: [0 1]\n",
      "Action: [1 1]\n",
      "Action: [ 0 73]\n",
      "Action: [0 1]\n",
      "Action: [0 4]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 42]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 70]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 86]\n",
      "Action: [ 0 86]\n",
      "Action: [ 1 85]\n",
      "Action: [ 0 80]\n",
      "Action: [ 1 97]\n",
      "Action: [ 1 10]\n",
      "Action: [1 2]\n",
      "Action: [1 5]\n",
      "Action: [ 0 44]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 57]\n",
      "Action: [ 0 99]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 50]\n",
      "Action: [ 1 65]\n",
      "Action: [ 0 95]\n",
      "Action: [ 0 82]\n",
      "Action: [ 0 55]\n",
      "Action: [0 0]\n",
      "Action: [ 0 76]\n",
      "Action: [ 0 45]\n",
      "Action: [ 0 80]\n",
      "Action: [ 1 89]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 26]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 30]\n",
      "Action: [ 0 33]\n",
      "Action: [ 1 49]\n",
      "Action: [ 0 15]\n",
      "Action: [ 0 17]\n",
      "Action: [ 0 48]\n",
      "Action: [ 0 45]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 87]\n",
      "Action: [1 1]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 18]\n",
      "Action: [1 2]\n",
      "Action: [ 0 98]\n",
      "Action: [ 1 46]\n",
      "Action: [1 8]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 73]\n",
      "Action: [0 1]\n",
      "Action: [0 7]\n",
      "Action: [ 0 94]\n",
      "Action: [0 8]\n",
      "Action: [1 7]\n",
      "Action: [ 1 56]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 73]\n",
      "Action: [ 1 43]\n",
      "Action: [ 1 32]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 65]\n",
      "Action: [ 0 66]\n",
      "Action: [ 1 57]\n",
      "Action: [ 0 45]\n",
      "Action: [ 1 46]\n",
      "Action: [ 1 20]\n",
      "Action: [ 1 80]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 44]\n",
      "Action: [ 1 86]\n",
      "Action: [ 1 52]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 39]\n",
      "Action: [ 1 60]\n",
      "Action: [1 2]\n",
      "Action: [ 0 62]\n",
      "Action: [ 0 12]\n",
      "Action: [0 8]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 64]\n",
      "Action: [0 6]\n",
      "Action: [ 1 48]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 50]\n",
      "Action: [ 0 48]\n",
      "Action: [1 1]\n",
      "Action: [ 1 50]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 66]\n",
      "Action: [ 0 62]\n",
      "Action: [ 1 37]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 34]\n",
      "Action: [ 0 75]\n",
      "Action: [ 0 15]\n",
      "Action: [0 6]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 14]\n",
      "Action: [ 0 32]\n",
      "Action: [ 1 71]\n",
      "Action: [ 1 15]\n",
      "Action: [ 1 41]\n",
      "Action: [ 0 97]\n",
      "Action: [ 1 48]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 92]\n",
      "Action: [ 1 76]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 79]\n",
      "Action: [ 1 39]\n",
      "Action: [ 0 97]\n",
      "Action: [ 1 92]\n",
      "Action: [ 1 78]\n",
      "Action: [ 0 50]\n",
      "Action: [ 0 66]\n",
      "Action: [ 1 86]\n",
      "Action: [ 1 80]\n",
      "Action: [ 1 16]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 70]\n",
      "Action: [ 0 97]\n",
      "Action: [ 1 50]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 44]\n",
      "Action: [ 0 78]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 39]\n",
      "Action: [ 1 39]\n",
      "Action: [ 0 71]\n",
      "Action: [ 0 99]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 87]\n",
      "Action: [ 1 50]\n",
      "Action: [ 0 15]\n",
      "Action: [ 0 14]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 47]\n",
      "Action: [ 0 46]\n",
      "Action: [ 1 76]\n",
      "Action: [ 0 73]\n",
      "Action: [ 1 89]\n",
      "Action: [ 0 15]\n",
      "Action: [ 1 68]\n",
      "Action: [ 0 89]\n",
      "Action: [ 1 78]\n",
      "Action: [ 1 85]\n",
      "Action: [ 0 85]\n",
      "Action: [ 1 98]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 97]\n",
      "Action: [ 1 41]\n",
      "Action: [ 0 57]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 46]\n",
      "Action: [ 0 37]\n",
      "Action: [ 0 14]\n",
      "Action: [1 4]\n",
      "Action: [ 1 15]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 62]\n",
      "Action: [1 1]\n",
      "Action: [ 0 77]\n",
      "Action: [ 1 49]\n",
      "Action: [ 0 27]\n",
      "Action: [ 1 33]\n",
      "Action: [ 0 52]\n",
      "Action: [ 0 27]\n",
      "Action: [ 0 53]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 44]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 78]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 86]\n",
      "Action: [ 0 91]\n",
      "Action: [1 1]\n",
      "Action: [ 0 50]\n",
      "Action: [ 0 51]\n",
      "Action: [1 3]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 29]\n",
      "Action: [ 1 14]\n",
      "Action: [ 1 86]\n",
      "Action: [ 0 34]\n",
      "Action: [ 1 55]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 60]\n",
      "Action: [ 0 19]\n",
      "Action: [0 1]\n",
      "Action: [ 0 74]\n",
      "Action: [ 1 59]\n",
      "Action: [ 1 10]\n",
      "Action: [ 0 87]\n",
      "Action: [0 6]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 52]\n",
      "Action: [ 1 57]\n",
      "Action: [ 1 45]\n",
      "Action: [ 0 44]\n",
      "Action: [ 1 53]\n",
      "Action: [ 0 14]\n",
      "Action: [ 0 36]\n",
      "Action: [ 0 19]\n",
      "Action: [ 0 85]\n",
      "Action: [ 1 37]\n",
      "Action: [ 1 64]\n",
      "Action: [ 0 62]\n",
      "Action: [ 0 95]\n",
      "Action: [1 1]\n",
      "Action: [ 0 61]\n",
      "Action: [ 1 85]\n",
      "Action: [ 0 81]\n",
      "Action: [0 7]\n",
      "Action: [ 0 51]\n",
      "Action: [ 1 70]\n",
      "Action: [ 1 26]\n",
      "Action: [ 0 49]\n",
      "Action: [ 0 39]\n",
      "Action: [ 1 10]\n",
      "Action: [ 1 54]\n",
      "Action: [ 1 98]\n",
      "Action: [ 0 88]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 82]\n",
      "Action: [ 1 41]\n",
      "Action: [ 1 48]\n",
      "Action: [1 5]\n",
      "Action: [ 1 21]\n",
      "Action: [0 1]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 28]\n",
      "Action: [ 0 25]\n",
      "Action: [ 0 33]\n",
      "Action: [ 1 73]\n",
      "Action: [ 0 75]\n",
      "Action: [1 6]\n",
      "Action: [ 1 97]\n",
      "Action: [ 0 60]\n",
      "Action: [1 3]\n",
      "Action: [ 1 36]\n",
      "Action: [ 1 60]\n",
      "Action: [ 0 10]\n",
      "Action: [ 0 91]\n",
      "Action: [1 8]\n",
      "Action: [ 1 45]\n",
      "Action: [ 1 39]\n",
      "Action: [ 0 77]\n",
      "Action: [ 1 62]\n",
      "Action: [ 1 97]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 24]\n",
      "Action: [ 1 83]\n",
      "Action: [ 0 60]\n",
      "Action: [ 0 49]\n",
      "Action: [ 1 77]\n",
      "Action: [ 1 75]\n",
      "Action: [ 1 47]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 34]\n",
      "Action: [ 1 78]\n",
      "Action: [ 1 86]\n",
      "Action: [ 0 35]\n",
      "Action: [ 1 62]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 62]\n",
      "Action: [ 0 48]\n",
      "Action: [ 1 61]\n",
      "Action: [ 0 21]\n",
      "Action: [ 0 64]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 68]\n",
      "Action: [ 1 39]\n",
      "Action: [ 0 58]\n",
      "Action: [ 0 48]\n",
      "Action: [ 1 52]\n",
      "Action: [ 0 45]\n",
      "Action: [ 0 70]\n",
      "Action: [ 0 55]\n",
      "Action: [ 1 32]\n",
      "Action: [ 0 13]\n",
      "Action: [1 1]\n",
      "Action: [1 1]\n",
      "Action: [ 0 77]\n",
      "Action: [ 1 65]\n",
      "Action: [ 0 62]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 71]\n",
      "Action: [ 1 49]\n",
      "Action: [ 1 25]\n",
      "Action: [ 0 94]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 27]\n",
      "Action: [ 1 85]\n",
      "Action: [ 1 95]\n",
      "Action: [ 1 51]\n",
      "Action: [ 1 13]\n",
      "Action: [1 1]\n",
      "Action: [ 0 89]\n",
      "Action: [ 0 49]\n",
      "Action: [ 0 98]\n",
      "Action: [ 0 61]\n",
      "Action: [0 1]\n",
      "Action: [ 0 69]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 32]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 17]\n",
      "Action: [1 1]\n",
      "Action: [ 0 50]\n",
      "Action: [1 9]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 55]\n",
      "Action: [ 1 49]\n",
      "Action: [1 1]\n",
      "Action: [ 1 32]\n",
      "Action: [ 0 62]\n",
      "Action: [1 3]\n",
      "Action: [ 1 76]\n",
      "Action: [ 0 90]\n",
      "Action: [ 0 50]\n",
      "Action: [ 1 92]\n",
      "Action: [ 0 23]\n",
      "Action: [ 0 97]\n",
      "Action: [ 1 55]\n",
      "Action: [ 1 60]\n",
      "Action: [0 8]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 73]\n",
      "Action: [ 0 35]\n",
      "Action: [0 0]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 96]\n",
      "Action: [0 6]\n",
      "Action: [0 1]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 61]\n",
      "Action: [ 0 29]\n",
      "Action: [ 1 55]\n",
      "Action: [ 1 42]\n",
      "Action: [ 1 38]\n",
      "Action: [1 1]\n",
      "Action: [ 0 56]\n",
      "Action: [ 0 60]\n",
      "Action: [ 0 76]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 37]\n",
      "Action: [ 1 80]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 17]\n",
      "Action: [0 1]\n",
      "Action: [ 1 49]\n",
      "Action: [ 1 14]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 45]\n",
      "Action: [ 1 97]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 45]\n",
      "Action: [ 1 44]\n",
      "Action: [ 1 97]\n",
      "Action: [ 0 17]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 78]\n",
      "Action: [ 0 97]\n",
      "Action: [ 1 77]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 44]\n",
      "Action: [ 0 55]\n",
      "Action: [ 1 48]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 83]\n",
      "Action: [1 3]\n",
      "Action: [ 0 57]\n",
      "Action: [0 1]\n",
      "Action: [ 0 61]\n",
      "Action: [1 1]\n",
      "Action: [ 1 88]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 28]\n",
      "Action: [ 1 37]\n",
      "Action: [ 0 68]\n",
      "Action: [ 1 62]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 96]\n",
      "Action: [1 8]\n",
      "Action: [1 1]\n",
      "Action: [1 8]\n",
      "Action: [ 0 34]\n",
      "Action: [ 0 85]\n",
      "Action: [ 1 32]\n",
      "Action: [ 0 59]\n",
      "Action: [ 0 33]\n",
      "Action: [1 6]\n",
      "Action: [ 0 63]\n",
      "Action: [ 1 86]\n",
      "Action: [ 0 15]\n",
      "Action: [ 1 69]\n",
      "Action: [ 0 81]\n",
      "Action: [ 0 23]\n",
      "Action: [ 1 69]\n",
      "Action: [0 8]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 88]\n",
      "Action: [ 1 44]\n",
      "Action: [ 0 74]\n",
      "Action: [ 0 81]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 60]\n",
      "Action: [ 0 62]\n",
      "Action: [ 0 44]\n",
      "Action: [ 1 47]\n",
      "Action: [ 1 88]\n",
      "Action: [ 1 64]\n",
      "Action: [ 1 10]\n",
      "Action: [ 0 14]\n",
      "Action: [ 1 50]\n",
      "Action: [0 6]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 61]\n",
      "Action: [ 0 57]\n",
      "Action: [ 0 62]\n",
      "Action: [ 1 36]\n",
      "Action: [ 0 89]\n",
      "Action: [ 0 34]\n",
      "Action: [ 1 32]\n",
      "Action: [ 0 51]\n",
      "Action: [1 5]\n",
      "Action: [ 1 73]\n",
      "Action: [ 0 86]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 21]\n",
      "Action: [ 1 14]\n",
      "Action: [ 0 39]\n",
      "Action: [ 1 48]\n",
      "Action: [ 0 52]\n",
      "Action: [ 1 80]\n",
      "Action: [ 0 48]\n",
      "Action: [ 1 85]\n",
      "Action: [ 1 55]\n",
      "Action: [ 0 92]\n",
      "Action: [ 1 59]\n",
      "Action: [ 0 81]\n",
      "Action: [ 1 73]\n",
      "Action: [ 0 30]\n",
      "Action: [ 0 20]\n",
      "Action: [ 1 53]\n",
      "Action: [ 1 64]\n",
      "Action: [ 1 60]\n",
      "Action: [ 0 24]\n",
      "Action: [ 0 53]\n",
      "Action: [ 1 80]\n",
      "Action: [ 1 27]\n",
      "Action: [0 1]\n",
      "Action: [1 6]\n",
      "Action: [1 1]\n",
      "Action: [ 0 37]\n",
      "Action: [0 0]\n",
      "Action: [ 1 54]\n",
      "Action: [ 1 82]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 70]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 13]\n",
      "Action: [0 1]\n",
      "Action: [1 0]\n",
      "Action: [ 1 97]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 32]\n",
      "Action: [ 1 46]\n",
      "Action: [ 1 87]\n",
      "Action: [ 0 47]\n",
      "Action: [ 0 16]\n",
      "Action: [ 0 67]\n",
      "Action: [ 0 35]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 32]\n",
      "Action: [ 0 86]\n",
      "Action: [ 0 64]\n",
      "Action: [ 1 34]\n",
      "Action: [ 1 61]\n",
      "Action: [0 6]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 32]\n",
      "Action: [ 0 83]\n",
      "Action: [ 1 15]\n",
      "Action: [ 1 88]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 34]\n",
      "Action: [0 1]\n",
      "Action: [ 0 24]\n",
      "Action: [ 0 80]\n",
      "Action: [ 1 78]\n",
      "Action: [ 1 88]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 85]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 83]\n",
      "Action: [ 0 98]\n",
      "Action: [ 0 46]\n",
      "Action: [ 0 74]\n",
      "Action: [ 0 92]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 57]\n",
      "Action: [ 0 62]\n",
      "Action: [ 1 44]\n",
      "Action: [ 0 64]\n",
      "Action: [ 0 60]\n",
      "Action: [0 1]\n",
      "Action: [ 1 32]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 15]\n",
      "Action: [ 0 85]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 20]\n",
      "Action: [ 1 12]\n",
      "Action: [ 1 91]\n",
      "Action: [1 1]\n",
      "Action: [ 1 52]\n",
      "Action: [ 0 64]\n",
      "Action: [ 0 53]\n",
      "Action: [ 1 54]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 63]\n",
      "Action: [ 1 65]\n",
      "Action: [0 3]\n",
      "Action: [0 1]\n",
      "Action: [0 6]\n",
      "Action: [ 1 60]\n",
      "Action: [ 1 10]\n",
      "Action: [ 0 77]\n",
      "Action: [ 1 55]\n",
      "Action: [ 0 47]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 59]\n",
      "Action: [ 1 49]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 26]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 86]\n",
      "Action: [ 1 37]\n",
      "Action: [ 1 14]\n",
      "Action: [ 0 34]\n",
      "Action: [ 1 68]\n",
      "Action: [ 0 42]\n",
      "Action: [ 0 80]\n",
      "Action: [ 1 69]\n",
      "Action: [ 1 37]\n",
      "Action: [ 0 80]\n",
      "Action: [0 4]\n",
      "Action: [1 6]\n",
      "Action: [ 0 10]\n",
      "Action: [ 1 77]\n",
      "Action: [ 0 43]\n",
      "Action: [1 8]\n",
      "Action: [1 5]\n",
      "Action: [ 0 46]\n",
      "Action: [ 1 48]\n",
      "Action: [ 1 70]\n",
      "Action: [ 1 48]\n",
      "Action: [1 1]\n",
      "Action: [ 1 95]\n",
      "Action: [ 0 86]\n",
      "Action: [ 1 35]\n",
      "Action: [ 0 96]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 75]\n",
      "Action: [ 0 30]\n",
      "Action: [ 1 17]\n",
      "Action: [ 1 29]\n",
      "Action: [1 1]\n",
      "Action: [ 0 41]\n",
      "Action: [ 0 97]\n",
      "Action: [ 0 17]\n",
      "Action: [ 1 76]\n",
      "Action: [ 1 96]\n",
      "Action: [ 1 97]\n",
      "Action: [ 0 12]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 56]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 55]\n",
      "Action: [ 0 34]\n",
      "Action: [0 1]\n",
      "Action: [ 0 34]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 51]\n",
      "Action: [ 1 64]\n",
      "Action: [ 1 94]\n",
      "Action: [ 0 77]\n",
      "Action: [ 1 91]\n",
      "Action: [0 8]\n",
      "Action: [ 1 62]\n",
      "Action: [ 1 78]\n",
      "Action: [0 3]\n",
      "Action: [ 0 23]\n",
      "Action: [0 0]\n",
      "Action: [ 1 47]\n",
      "Action: [ 0 83]\n",
      "Action: [ 1 35]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 44]\n",
      "Action: [1 1]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 77]\n",
      "Action: [1 1]\n",
      "Action: [ 0 74]\n",
      "Action: [ 0 49]\n",
      "Action: [ 0 51]\n",
      "Action: [ 1 36]\n",
      "Action: [ 0 52]\n",
      "Action: [1 8]\n",
      "Action: [ 0 15]\n",
      "Action: [ 0 51]\n",
      "Action: [ 1 57]\n",
      "Action: [ 1 85]\n",
      "Action: [ 0 14]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 48]\n",
      "Action: [ 0 88]\n",
      "Action: [0 1]\n",
      "Action: [0 3]\n",
      "Action: [ 1 41]\n",
      "Action: [ 1 74]\n",
      "Action: [ 0 15]\n",
      "Action: [ 0 45]\n",
      "Action: [ 1 88]\n",
      "Action: [ 1 73]\n",
      "Action: [ 0 84]\n",
      "Action: [0 8]\n",
      "Action: [ 1 77]\n",
      "Action: [ 0 15]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 42]\n",
      "Action: [1 1]\n",
      "Action: [ 1 13]\n",
      "Action: [1 8]\n",
      "Action: [ 0 34]\n",
      "Action: [ 0 43]\n",
      "Action: [ 0 82]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 56]\n",
      "Action: [ 1 79]\n",
      "Action: [ 0 47]\n",
      "Action: [ 0 99]\n",
      "Action: [ 1 53]\n",
      "Action: [ 0 92]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 74]\n",
      "Action: [ 1 87]\n",
      "Action: [ 0 60]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 49]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 35]\n",
      "Action: [ 0 73]\n",
      "Action: [ 0 70]\n",
      "Action: [ 1 64]\n",
      "Action: [ 1 77]\n",
      "Action: [ 0 39]\n",
      "Action: [ 1 88]\n",
      "Action: [1 1]\n",
      "Action: [ 1 56]\n",
      "Action: [ 1 12]\n",
      "Action: [ 0 31]\n",
      "Action: [ 0 45]\n",
      "Action: [ 1 82]\n",
      "Action: [0 8]\n",
      "Action: [ 1 39]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 94]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 53]\n",
      "Action: [0 3]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 79]\n",
      "Action: [ 0 56]\n",
      "Action: [ 0 52]\n",
      "Action: [ 0 12]\n",
      "Action: [ 1 29]\n",
      "Action: [1 1]\n",
      "Action: [ 1 52]\n",
      "Action: [ 1 47]\n",
      "Action: [ 1 69]\n",
      "Action: [0 6]\n",
      "Action: [ 0 37]\n",
      "Action: [0 8]\n",
      "Action: [ 0 21]\n",
      "Action: [ 0 17]\n",
      "Action: [ 1 95]\n",
      "Action: [ 1 44]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 17]\n",
      "Action: [ 1 77]\n",
      "Action: [ 1 39]\n",
      "Action: [ 0 14]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 34]\n",
      "Action: [ 1 39]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 75]\n",
      "Action: [ 1 86]\n",
      "Action: [ 0 74]\n",
      "Action: [ 0 69]\n",
      "Action: [ 0 14]\n",
      "Action: [ 0 60]\n",
      "Action: [ 1 41]\n",
      "Action: [ 1 88]\n",
      "Action: [ 1 23]\n",
      "Action: [1 1]\n",
      "Action: [ 1 55]\n",
      "Action: [ 0 81]\n",
      "Action: [ 0 88]\n",
      "Action: [ 1 62]\n",
      "Action: [ 1 92]\n",
      "Action: [ 0 81]\n",
      "Action: [ 0 10]\n",
      "Action: [ 0 14]\n",
      "Action: [ 0 80]\n",
      "Action: [ 1 20]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 48]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 91]\n",
      "Action: [1 0]\n",
      "Action: [ 0 85]\n",
      "Action: [ 1 23]\n",
      "Action: [ 0 32]\n",
      "Action: [ 0 50]\n",
      "Action: [ 0 50]\n",
      "Action: [ 0 37]\n",
      "Action: [ 0 68]\n",
      "Action: [ 1 78]\n",
      "Action: [0 8]\n",
      "Action: [ 1 14]\n",
      "Action: [ 0 10]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 41]\n",
      "Action: [1 2]\n",
      "Action: [ 0 89]\n",
      "Action: [ 0 32]\n",
      "Action: [ 0 44]\n",
      "Action: [ 1 34]\n",
      "Action: [ 0 14]\n",
      "Action: [ 0 32]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 50]\n",
      "Action: [ 1 42]\n",
      "Action: [ 0 48]\n",
      "Action: [ 0 64]\n",
      "Action: [ 1 95]\n",
      "Action: [0 8]\n",
      "Action: [ 1 47]\n",
      "Action: [ 1 46]\n",
      "Action: [ 0 62]\n",
      "Action: [ 1 64]\n",
      "Action: [ 0 52]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 62]\n",
      "Action: [ 0 47]\n",
      "Action: [ 0 11]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 74]\n",
      "Action: [ 0 81]\n",
      "Action: [ 0 88]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 33]\n",
      "Action: [ 0 71]\n",
      "Action: [0 1]\n",
      "Action: [0 8]\n",
      "Action: [ 1 97]\n",
      "Action: [ 1 45]\n",
      "Action: [ 1 27]\n",
      "Action: [ 1 83]\n",
      "Action: [ 0 57]\n",
      "Action: [ 0 48]\n",
      "Action: [ 1 76]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 15]\n",
      "Action: [1 1]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 95]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 88]\n",
      "Action: [ 0 71]\n",
      "Action: [ 1 65]\n",
      "Action: [ 1 48]\n",
      "Action: [ 0 78]\n",
      "Action: [ 0 85]\n",
      "Action: [ 0 52]\n",
      "Action: [ 0 85]\n",
      "Action: [ 0 19]\n",
      "Action: [ 1 66]\n",
      "Action: [ 0 91]\n",
      "Action: [1 7]\n",
      "Action: [ 1 78]\n",
      "Action: [1 8]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 60]\n",
      "Action: [1 1]\n",
      "Action: [0 2]\n",
      "Action: [ 0 35]\n",
      "Action: [ 0 36]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 62]\n",
      "Action: [ 0 53]\n",
      "Action: [ 0 56]\n",
      "Action: [ 1 86]\n",
      "Action: [ 1 88]\n",
      "Action: [ 1 10]\n",
      "Action: [ 0 53]\n",
      "Action: [ 0 49]\n",
      "Action: [ 1 45]\n",
      "Action: [0 1]\n",
      "Action: [ 0 34]\n",
      "Action: [ 0 70]\n",
      "Action: [ 1 29]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 50]\n",
      "Action: [ 0 41]\n",
      "Action: [ 0 81]\n",
      "Action: [ 1 36]\n",
      "Action: [ 1 37]\n",
      "Action: [ 1 79]\n",
      "Action: [ 1 87]\n",
      "Action: [ 1 39]\n",
      "Action: [ 1 11]\n",
      "Action: [ 1 88]\n",
      "Action: [ 1 47]\n",
      "Action: [ 0 70]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 62]\n",
      "Action: [ 1 54]\n",
      "Action: [ 0 63]\n",
      "Action: [ 1 44]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 65]\n",
      "Action: [ 1 19]\n",
      "Action: [ 1 80]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 87]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 43]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 50]\n",
      "Action: [ 1 20]\n",
      "Action: [ 1 19]\n",
      "Action: [0 6]\n",
      "Action: [ 1 23]\n",
      "Action: [ 1 60]\n",
      "Action: [ 0 79]\n",
      "Action: [ 0 36]\n",
      "Action: [0 8]\n",
      "Action: [ 1 67]\n",
      "Action: [0 3]\n",
      "Action: [ 1 77]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 15]\n",
      "Action: [0 1]\n",
      "Action: [ 0 60]\n",
      "Action: [1 7]\n",
      "Action: [0 7]\n",
      "Action: [ 0 44]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 68]\n",
      "Action: [ 0 83]\n",
      "Action: [ 0 64]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 27]\n",
      "Action: [ 1 17]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 55]\n",
      "Action: [ 0 56]\n",
      "Action: [ 0 42]\n",
      "Action: [ 1 29]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 15]\n",
      "Action: [ 0 24]\n",
      "Action: [1 1]\n",
      "Action: [ 0 77]\n",
      "Action: [ 1 21]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 45]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 10]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 78]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 33]\n",
      "Action: [ 0 80]\n",
      "Action: [ 1 35]\n",
      "Action: [1 5]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 76]\n",
      "Action: [ 0 78]\n",
      "Action: [ 1 62]\n",
      "Action: [ 1 71]\n",
      "Action: [ 0 48]\n",
      "Action: [ 1 35]\n",
      "Action: [ 1 51]\n",
      "Action: [ 0 52]\n",
      "Action: [ 0 61]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 39]\n",
      "Action: [ 1 52]\n",
      "Action: [ 0 43]\n",
      "Action: [ 0 51]\n",
      "Action: [ 1 59]\n",
      "Action: [ 0 59]\n",
      "Action: [0 7]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 62]\n",
      "Action: [0 9]\n",
      "Action: [ 0 47]\n",
      "Action: [ 0 81]\n",
      "Action: [ 0 62]\n",
      "Action: [ 0 76]\n",
      "Action: [ 0 68]\n",
      "Action: [1 1]\n",
      "Action: [0 3]\n",
      "Action: [ 0 30]\n",
      "Action: [ 1 70]\n",
      "Action: [ 1 28]\n",
      "Action: [ 0 34]\n",
      "Action: [ 0 95]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 87]\n",
      "Action: [ 0 48]\n",
      "Action: [ 0 68]\n",
      "Action: [ 1 76]\n",
      "Action: [ 0 77]\n",
      "Action: [ 1 14]\n",
      "Action: [ 1 54]\n",
      "Action: [ 1 37]\n",
      "Action: [ 1 88]\n",
      "Action: [1 6]\n",
      "Action: [ 0 57]\n",
      "Action: [ 0 49]\n",
      "Action: [ 1 41]\n",
      "Action: [0 2]\n",
      "Action: [ 0 11]\n",
      "Action: [0 0]\n",
      "Action: [0 1]\n",
      "Action: [0 1]\n",
      "Action: [ 0 62]\n",
      "Action: [ 1 53]\n",
      "Action: [ 1 52]\n",
      "Action: [1 5]\n",
      "Action: [ 0 66]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 32]\n",
      "Action: [ 0 60]\n",
      "Action: [ 0 41]\n",
      "Action: [ 0 14]\n",
      "Action: [ 1 84]\n",
      "Action: [ 1 27]\n",
      "Action: [ 0 77]\n",
      "Action: [ 1 77]\n",
      "Action: [ 1 57]\n",
      "Action: [ 0 44]\n",
      "Action: [ 1 39]\n",
      "Action: [ 0 87]\n",
      "Action: [ 1 42]\n",
      "Action: [ 1 25]\n",
      "Action: [ 0 15]\n",
      "Action: [ 1 26]\n",
      "Action: [1 1]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 41]\n",
      "Action: [ 1 93]\n",
      "Action: [ 1 86]\n",
      "Action: [ 1 55]\n",
      "Action: [ 1 29]\n",
      "Action: [ 1 17]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 12]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 85]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 90]\n",
      "Action: [ 1 46]\n",
      "Action: [ 0 67]\n",
      "Action: [0 7]\n",
      "Action: [ 0 81]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 38]\n",
      "Action: [0 1]\n",
      "Action: [ 0 92]\n",
      "Action: [ 0 20]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 40]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 56]\n",
      "Action: [ 1 14]\n",
      "Action: [ 0 12]\n",
      "Action: [ 0 70]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 41]\n",
      "Action: [0 0]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 99]\n",
      "Action: [ 1 37]\n",
      "Action: [ 0 72]\n",
      "Action: [ 0 50]\n",
      "Action: [ 0 20]\n",
      "Action: [ 1 55]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 17]\n",
      "Action: [ 0 24]\n",
      "Action: [ 1 12]\n",
      "Action: [ 1 29]\n",
      "Action: [ 1 44]\n",
      "Action: [ 0 21]\n",
      "Action: [ 1 46]\n",
      "Action: [ 1 28]\n",
      "Action: [ 1 64]\n",
      "Action: [ 0 78]\n",
      "Action: [0 0]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 21]\n",
      "Action: [ 1 75]\n",
      "Action: [ 0 15]\n",
      "Action: [ 0 15]\n",
      "Action: [ 0 30]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 63]\n",
      "Action: [ 1 30]\n",
      "Action: [ 0 45]\n",
      "Action: [ 0 13]\n",
      "Action: [0 1]\n",
      "Action: [ 1 15]\n",
      "Action: [ 1 68]\n",
      "Action: [0 1]\n",
      "Action: [ 0 47]\n",
      "Action: [ 0 39]\n",
      "Action: [ 1 22]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 86]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 88]\n",
      "Action: [ 1 32]\n",
      "Action: [0 1]\n",
      "Action: [1 8]\n",
      "Action: [ 0 28]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 10]\n",
      "Action: [ 0 62]\n",
      "Action: [ 1 39]\n",
      "Action: [ 0 60]\n",
      "Action: [ 1 14]\n",
      "Action: [ 1 47]\n",
      "Action: [ 0 15]\n",
      "Action: [ 0 20]\n",
      "Action: [ 1 64]\n",
      "Action: [ 1 62]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 37]\n",
      "Action: [ 1 93]\n",
      "Action: [ 1 93]\n",
      "Action: [ 0 62]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 47]\n",
      "Action: [ 1 78]\n",
      "Action: [ 0 80]\n",
      "Action: [ 1 52]\n",
      "Action: [ 0 15]\n",
      "Action: [ 1 42]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 44]\n",
      "Action: [ 0 34]\n",
      "Action: [ 0 85]\n",
      "Action: [ 0 64]\n",
      "Action: [ 0 89]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 46]\n",
      "Action: [ 0 44]\n",
      "Action: [ 1 53]\n",
      "Action: [ 0 13]\n",
      "Action: [1 9]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 90]\n",
      "Action: [ 0 44]\n",
      "Action: [ 1 37]\n",
      "Action: [0 5]\n",
      "Action: [ 0 67]\n",
      "Action: [ 1 49]\n",
      "Action: [ 0 49]\n",
      "Action: [ 0 75]\n",
      "Action: [ 1 99]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 50]\n",
      "Action: [ 1 43]\n",
      "Action: [ 0 76]\n",
      "Action: [ 0 18]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 43]\n",
      "Action: [ 1 41]\n",
      "Action: [ 1 43]\n",
      "Action: [0 3]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 71]\n",
      "Action: [ 0 79]\n",
      "Action: [ 0 71]\n",
      "Action: [ 0 45]\n",
      "Action: [ 1 96]\n",
      "Action: [ 0 64]\n",
      "Action: [ 1 64]\n",
      "Action: [ 0 98]\n",
      "Action: [ 1 43]\n",
      "Action: [ 0 21]\n",
      "Action: [ 0 46]\n",
      "Action: [ 1 32]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 63]\n",
      "Action: [ 1 42]\n",
      "Action: [0 1]\n",
      "Action: [ 0 57]\n",
      "Action: [ 1 66]\n",
      "Action: [ 1 52]\n",
      "Action: [ 1 39]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 32]\n",
      "Action: [ 1 51]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 50]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 37]\n",
      "Action: [ 0 15]\n",
      "Action: [ 1 95]\n",
      "Action: [ 1 48]\n",
      "Action: [ 1 88]\n",
      "Action: [ 1 51]\n",
      "Action: [ 0 41]\n",
      "Action: [1 7]\n",
      "Action: [ 1 76]\n",
      "Action: [ 1 24]\n",
      "Action: [ 0 70]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 79]\n",
      "Action: [ 0 53]\n",
      "Action: [1 1]\n",
      "Action: [ 1 44]\n",
      "Action: [ 1 57]\n",
      "Action: [ 0 94]\n",
      "Action: [ 0 88]\n",
      "Action: [ 0 39]\n",
      "Action: [ 1 41]\n",
      "Action: [ 0 52]\n",
      "Action: [ 0 68]\n",
      "Action: [0 1]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 19]\n",
      "Action: [ 0 44]\n",
      "Action: [ 1 24]\n",
      "Action: [1 6]\n",
      "Action: [ 0 42]\n",
      "Action: [ 1 32]\n",
      "Action: [1 0]\n",
      "Action: [ 1 48]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 72]\n",
      "Action: [ 0 52]\n",
      "Action: [1 1]\n",
      "Action: [1 1]\n",
      "Action: [ 0 52]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 61]\n",
      "Action: [ 0 40]\n",
      "Action: [1 8]\n",
      "Action: [ 1 98]\n",
      "Action: [ 1 37]\n",
      "Action: [ 1 63]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 41]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 46]\n",
      "Action: [ 0 32]\n",
      "Action: [ 1 30]\n",
      "Action: [ 1 41]\n",
      "Action: [ 0 87]\n",
      "Action: [ 1 84]\n",
      "Action: [ 1 29]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 44]\n",
      "Action: [ 1 70]\n",
      "Action: [ 1 88]\n",
      "Action: [ 1 98]\n",
      "Action: [ 1 15]\n",
      "Action: [1 1]\n",
      "Action: [ 0 50]\n",
      "Action: [ 0 63]\n",
      "Action: [ 0 36]\n",
      "Action: [0 3]\n",
      "Action: [ 1 53]\n",
      "Action: [ 1 44]\n",
      "Action: [ 1 65]\n",
      "Action: [ 1 21]\n",
      "Action: [ 1 85]\n",
      "Action: [ 0 40]\n",
      "Action: [ 0 15]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 36]\n",
      "Action: [ 0 83]\n",
      "Action: [ 1 49]\n",
      "Action: [ 0 63]\n",
      "Action: [0 0]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 81]\n",
      "Action: [ 1 83]\n",
      "Action: [ 0 44]\n",
      "Action: [ 0 71]\n",
      "Action: [ 0 27]\n",
      "Action: [ 0 72]\n",
      "Action: [0 1]\n",
      "Action: [ 0 42]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 26]\n",
      "Action: [ 0 53]\n",
      "Action: [ 0 31]\n",
      "Action: [ 1 23]\n",
      "Action: [ 1 44]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 57]\n",
      "Action: [ 1 30]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 15]\n",
      "Action: [ 0 40]\n",
      "Action: [ 1 62]\n",
      "Action: [ 1 64]\n",
      "Action: [ 0 14]\n",
      "Action: [ 1 32]\n",
      "Action: [ 1 37]\n",
      "Action: [ 0 14]\n",
      "Action: [ 0 64]\n",
      "Action: [ 1 65]\n",
      "Action: [ 1 55]\n",
      "Action: [ 0 27]\n",
      "Action: [ 0 38]\n",
      "Action: [1 0]\n",
      "Action: [ 0 70]\n",
      "Action: [ 0 82]\n",
      "Action: [1 6]\n",
      "Action: [ 0 99]\n",
      "Action: [ 1 34]\n",
      "Action: [ 1 39]\n",
      "Action: [ 1 17]\n",
      "Action: [ 0 85]\n",
      "Action: [ 0 94]\n",
      "Action: [ 0 42]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 72]\n",
      "Action: [ 0 51]\n",
      "Action: [1 0]\n",
      "Action: [ 0 45]\n",
      "Action: [ 0 39]\n",
      "Action: [0 0]\n",
      "Action: [ 0 96]\n",
      "Action: [ 1 88]\n",
      "Action: [1 5]\n",
      "Action: [ 0 31]\n",
      "Action: [ 1 77]\n",
      "Action: [ 0 83]\n",
      "Action: [ 1 30]\n",
      "Action: [ 1 44]\n",
      "Action: [ 0 97]\n",
      "Action: [ 1 19]\n",
      "Action: [ 0 26]\n",
      "Action: [1 6]\n",
      "Action: [ 1 51]\n",
      "Action: [ 0 92]\n",
      "Action: [ 1 32]\n",
      "Action: [ 1 73]\n",
      "Action: [ 0 36]\n",
      "Action: [ 1 97]\n",
      "Action: [ 0 59]\n",
      "Action: [0 6]\n",
      "Action: [ 0 78]\n",
      "Action: [0 1]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 29]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 65]\n",
      "Action: [ 1 37]\n",
      "Action: [ 0 60]\n",
      "Action: [ 0 83]\n",
      "Action: [ 1 80]\n",
      "Action: [ 0 97]\n",
      "Action: [ 1 55]\n",
      "Action: [ 1 92]\n",
      "Action: [ 0 41]\n",
      "Action: [ 1 27]\n",
      "Action: [ 0 45]\n",
      "Action: [ 0 85]\n",
      "Action: [ 0 53]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 83]\n",
      "Action: [1 5]\n",
      "Action: [ 1 48]\n",
      "Action: [ 0 77]\n",
      "Action: [ 1 41]\n",
      "Action: [ 0 10]\n",
      "Action: [ 1 83]\n",
      "Action: [ 0 36]\n",
      "Action: [ 0 70]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 70]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 17]\n",
      "Action: [ 1 77]\n",
      "Action: [ 1 88]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 19]\n",
      "Action: [ 0 50]\n",
      "Action: [ 1 67]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 23]\n",
      "Action: [ 0 31]\n",
      "Action: [ 1 54]\n",
      "Action: [ 1 17]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 10]\n",
      "Action: [ 0 90]\n",
      "Action: [ 1 39]\n",
      "Action: [ 0 32]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 83]\n",
      "Action: [1 8]\n",
      "Action: [1 5]\n",
      "Action: [ 1 72]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 88]\n",
      "Action: [ 1 99]\n",
      "Action: [ 0 75]\n",
      "Action: [ 0 17]\n",
      "Action: [ 0 81]\n",
      "Action: [ 0 52]\n",
      "Action: [0 1]\n",
      "Action: [ 1 25]\n",
      "Action: [ 0 48]\n",
      "Action: [ 1 98]\n",
      "Action: [ 0 37]\n",
      "Action: [ 0 26]\n",
      "Action: [ 1 14]\n",
      "Action: [ 0 80]\n",
      "Action: [ 1 35]\n",
      "Action: [ 1 93]\n",
      "Action: [ 0 10]\n",
      "Action: [ 0 48]\n",
      "Action: [ 1 77]\n",
      "Action: [0 6]\n",
      "Action: [ 0 65]\n",
      "Action: [ 1 94]\n",
      "Action: [ 0 96]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 48]\n",
      "Action: [ 1 52]\n",
      "Action: [ 1 35]\n",
      "Action: [ 0 88]\n",
      "Action: [1 5]\n",
      "Action: [ 1 65]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 51]\n",
      "Action: [ 0 85]\n",
      "Action: [ 0 86]\n",
      "Action: [0 2]\n",
      "Action: [ 0 14]\n",
      "Action: [0 2]\n",
      "Action: [ 1 80]\n",
      "Action: [ 1 79]\n",
      "Action: [ 0 33]\n",
      "Action: [ 1 99]\n",
      "Action: [ 0 60]\n",
      "Action: [ 1 85]\n",
      "Action: [ 0 23]\n",
      "Action: [ 1 63]\n",
      "Action: [1 3]\n",
      "Action: [ 0 53]\n",
      "Action: [ 0 56]\n",
      "Action: [ 0 57]\n",
      "Action: [1 0]\n",
      "Action: [ 1 73]\n",
      "Action: [ 0 41]\n",
      "Action: [ 0 94]\n",
      "Action: [ 1 19]\n",
      "Action: [ 0 83]\n",
      "Action: [ 0 22]\n",
      "Action: [ 0 64]\n",
      "Action: [ 1 98]\n",
      "Action: [ 0 81]\n",
      "Action: [ 0 50]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 86]\n",
      "Action: [ 1 57]\n",
      "Action: [ 0 83]\n",
      "Action: [ 1 95]\n",
      "Action: [ 0 41]\n",
      "Action: [ 0 60]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 16]\n",
      "Action: [ 0 53]\n",
      "Action: [ 1 32]\n",
      "Action: [ 0 85]\n",
      "Action: [ 1 14]\n",
      "Action: [ 1 73]\n",
      "Action: [ 0 46]\n",
      "Action: [ 1 29]\n",
      "Action: [ 1 65]\n",
      "Action: [ 0 83]\n",
      "Action: [0 1]\n",
      "Action: [ 0 54]\n",
      "Action: [ 1 33]\n",
      "Action: [ 0 29]\n",
      "Action: [1 8]\n",
      "Action: [ 1 37]\n",
      "Action: [ 0 79]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 54]\n",
      "Action: [0 6]\n",
      "Action: [0 1]\n",
      "Action: [ 0 11]\n",
      "Action: [ 1 87]\n",
      "Action: [ 1 45]\n",
      "Action: [ 1 93]\n",
      "Action: [ 1 61]\n",
      "Action: [0 9]\n",
      "Action: [ 0 27]\n",
      "Action: [ 0 81]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 97]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 16]\n",
      "Action: [ 0 91]\n",
      "Action: [1 4]\n",
      "Action: [ 0 54]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 44]\n",
      "Action: [ 1 59]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 65]\n",
      "Action: [ 0 32]\n",
      "Action: [ 1 78]\n",
      "Action: [ 0 54]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 20]\n",
      "Action: [1 5]\n",
      "Action: [ 0 60]\n",
      "Action: [ 0 32]\n",
      "Action: [ 0 88]\n",
      "Action: [ 1 45]\n",
      "Action: [ 0 64]\n",
      "Action: [ 0 32]\n",
      "Action: [ 1 47]\n",
      "Action: [ 0 44]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 99]\n",
      "Action: [ 0 20]\n",
      "Action: [1 8]\n",
      "Action: [ 1 31]\n",
      "Action: [ 1 85]\n",
      "Action: [ 1 87]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 37]\n",
      "Action: [ 0 63]\n",
      "Action: [ 0 52]\n",
      "Action: [ 0 44]\n",
      "Action: [0 4]\n",
      "Action: [ 0 44]\n",
      "Action: [ 0 54]\n",
      "Action: [ 1 37]\n",
      "Action: [ 0 25]\n",
      "Action: [ 0 69]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 98]\n",
      "Action: [ 0 62]\n",
      "Action: [ 0 54]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 41]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 74]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 14]\n",
      "Action: [0 2]\n",
      "Action: [ 1 79]\n",
      "Action: [1 7]\n",
      "Action: [ 1 24]\n",
      "Action: [ 0 75]\n",
      "Action: [0 1]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 22]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 83]\n",
      "Action: [ 1 68]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 28]\n",
      "Action: [ 0 36]\n",
      "Action: [ 0 46]\n",
      "Action: [0 1]\n",
      "Action: [ 0 39]\n",
      "Action: [ 1 57]\n",
      "Action: [ 1 99]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 67]\n",
      "Action: [ 0 65]\n",
      "Action: [ 0 85]\n",
      "Action: [ 0 44]\n",
      "Action: [0 1]\n",
      "Action: [ 0 74]\n",
      "Action: [ 0 39]\n",
      "Action: [ 1 70]\n",
      "Action: [ 1 74]\n",
      "Action: [ 1 34]\n",
      "Action: [ 0 53]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 88]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 74]\n",
      "Action: [ 0 26]\n",
      "Action: [ 1 12]\n",
      "Action: [0 8]\n",
      "Action: [ 0 10]\n",
      "Action: [ 0 74]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 65]\n",
      "Action: [ 0 98]\n",
      "Action: [ 0 29]\n",
      "Action: [ 1 53]\n",
      "Action: [ 1 24]\n",
      "Action: [ 0 41]\n",
      "Action: [1 1]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 55]\n",
      "Action: [ 1 19]\n",
      "Action: [ 1 68]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 52]\n",
      "Action: [ 1 54]\n",
      "Action: [ 1 49]\n",
      "Action: [ 0 77]\n",
      "Action: [ 1 37]\n",
      "Action: [ 1 37]\n",
      "Action: [ 1 55]\n",
      "Action: [ 0 16]\n",
      "Action: [ 1 55]\n",
      "Action: [ 1 88]\n",
      "Action: [ 0 39]\n",
      "Action: [ 1 20]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 42]\n",
      "Action: [ 1 53]\n",
      "Action: [ 0 87]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 59]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 55]\n",
      "Action: [ 1 30]\n",
      "Action: [ 0 28]\n",
      "Action: [0 0]\n",
      "Action: [ 1 27]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 95]\n",
      "Action: [ 0 85]\n",
      "Action: [ 0 83]\n",
      "Action: [ 0 86]\n",
      "Action: [ 1 42]\n",
      "Action: [0 0]\n",
      "Action: [ 1 80]\n",
      "Action: [0 8]\n",
      "Action: [ 1 92]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 87]\n",
      "Action: [ 0 10]\n",
      "Action: [ 0 57]\n",
      "Action: [ 1 84]\n",
      "Action: [ 0 73]\n",
      "Action: [ 0 51]\n",
      "Action: [ 1 46]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 44]\n",
      "Action: [ 0 47]\n",
      "Action: [ 0 61]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 14]\n",
      "Action: [ 1 10]\n",
      "Action: [ 1 88]\n",
      "Action: [1 8]\n",
      "Action: [ 1 62]\n",
      "Action: [ 1 15]\n",
      "Action: [ 0 70]\n",
      "Action: [0 1]\n",
      "Action: [ 1 46]\n",
      "Action: [ 1 85]\n",
      "Action: [ 0 15]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 86]\n",
      "Action: [ 0 75]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 10]\n",
      "Action: [ 0 69]\n",
      "Action: [ 0 49]\n",
      "Action: [ 0 44]\n",
      "Action: [ 0 46]\n",
      "Action: [ 0 80]\n",
      "Action: [ 1 56]\n",
      "Action: [ 1 10]\n",
      "Action: [0 1]\n",
      "Action: [ 1 15]\n",
      "Action: [0 2]\n",
      "Action: [ 1 31]\n",
      "Action: [0 3]\n",
      "Action: [ 1 30]\n",
      "Action: [ 0 69]\n",
      "Action: [ 0 36]\n",
      "Action: [ 1 98]\n",
      "Action: [ 0 33]\n",
      "Action: [ 1 83]\n",
      "Action: [1 1]\n",
      "Action: [ 0 55]\n",
      "Action: [0 7]\n",
      "Action: [ 0 22]\n",
      "Action: [ 0 41]\n",
      "Action: [ 1 36]\n",
      "Action: [ 1 69]\n",
      "Action: [ 0 49]\n",
      "Action: [ 0 45]\n",
      "Action: [ 0 54]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 45]\n",
      "Action: [ 1 85]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 88]\n",
      "Action: [ 1 14]\n",
      "Action: [ 1 84]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 71]\n",
      "Action: [ 1 32]\n",
      "Action: [ 0 89]\n",
      "Action: [ 1 80]\n",
      "Action: [ 1 14]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 55]\n",
      "Action: [ 1 54]\n",
      "Action: [1 0]\n",
      "Action: [ 0 32]\n",
      "Action: [ 0 20]\n",
      "Action: [ 1 90]\n",
      "Action: [ 0 20]\n",
      "Action: [1 0]\n",
      "Action: [ 0 66]\n",
      "Action: [ 0 21]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 34]\n",
      "Action: [ 0 50]\n",
      "Action: [ 0 12]\n",
      "Action: [ 1 32]\n",
      "Action: [ 1 53]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 10]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 53]\n",
      "Action: [ 0 76]\n",
      "Action: [ 1 68]\n",
      "Action: [ 0 48]\n",
      "Action: [ 0 30]\n",
      "Action: [1 6]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 44]\n",
      "Action: [ 1 97]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 16]\n",
      "Action: [ 0 79]\n",
      "Action: [ 0 86]\n",
      "Action: [ 1 88]\n",
      "Action: [ 1 17]\n",
      "Action: [ 1 14]\n",
      "Action: [ 0 53]\n",
      "Action: [ 0 46]\n",
      "Action: [ 1 69]\n",
      "Action: [ 0 81]\n",
      "Action: [ 0 83]\n",
      "Action: [ 0 17]\n",
      "Action: [ 1 77]\n",
      "Action: [ 0 23]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 88]\n",
      "Action: [ 1 42]\n",
      "Action: [ 0 35]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 87]\n",
      "Action: [ 1 30]\n",
      "Action: [ 0 51]\n",
      "Action: [ 1 39]\n",
      "Action: [0 1]\n",
      "Action: [ 1 15]\n",
      "Action: [ 0 69]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 57]\n",
      "Action: [ 1 41]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 48]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 37]\n",
      "Action: [ 0 55]\n",
      "Action: [ 1 29]\n",
      "Action: [ 1 64]\n",
      "Action: [ 0 85]\n",
      "Action: [ 0 39]\n",
      "Action: [ 0 93]\n",
      "Action: [ 0 64]\n",
      "Action: [ 1 95]\n",
      "Action: [0 4]\n",
      "Action: [ 0 86]\n",
      "Action: [ 1 76]\n",
      "Action: [ 0 76]\n",
      "Action: [ 1 45]\n",
      "Action: [ 0 56]\n",
      "Action: [ 0 86]\n",
      "Action: [ 0 64]\n",
      "Action: [ 0 99]\n",
      "Action: [0 1]\n",
      "Action: [ 0 17]\n",
      "Action: [ 1 80]\n",
      "Action: [1 7]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 63]\n",
      "Action: [ 0 44]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 83]\n",
      "Action: [ 0 46]\n",
      "Action: [ 1 14]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 12]\n",
      "Action: [ 1 60]\n",
      "Action: [0 7]\n",
      "Action: [ 1 98]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 54]\n",
      "Action: [ 0 10]\n",
      "Action: [ 1 73]\n",
      "Action: [ 1 55]\n",
      "Action: [ 0 65]\n",
      "Action: [ 0 81]\n",
      "Action: [ 0 88]\n",
      "Action: [ 0 43]\n",
      "Action: [ 0 62]\n",
      "Action: [ 0 76]\n",
      "Action: [ 1 49]\n",
      "Action: [ 0 45]\n",
      "Action: [ 0 74]\n",
      "Action: [ 1 39]\n",
      "Action: [ 0 46]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 69]\n",
      "Action: [ 1 47]\n",
      "Action: [ 0 16]\n",
      "Action: [ 0 28]\n",
      "Action: [ 1 95]\n",
      "Action: [ 0 45]\n",
      "Action: [ 1 49]\n",
      "Action: [ 1 98]\n",
      "Action: [ 0 86]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 49]\n",
      "Action: [ 1 90]\n",
      "Action: [ 1 50]\n",
      "Action: [ 0 20]\n",
      "Action: [ 1 64]\n",
      "Action: [ 0 33]\n",
      "Action: [ 0 53]\n",
      "Action: [ 0 54]\n",
      "Action: [ 0 85]\n",
      "Action: [ 0 98]\n",
      "Action: [1 8]\n",
      "Action: [0 1]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 76]\n",
      "Action: [ 0 60]\n",
      "Action: [1 5]\n",
      "Action: [ 1 39]\n",
      "Action: [ 1 33]\n",
      "Action: [ 1 73]\n",
      "Action: [ 0 30]\n",
      "Action: [ 0 76]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 55]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 43]\n",
      "Action: [ 1 95]\n",
      "Action: [ 0 80]\n",
      "Action: [1 1]\n",
      "Action: [ 0 51]\n",
      "Action: [ 1 55]\n",
      "Action: [ 1 65]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 77]\n",
      "Action: [ 0 88]\n",
      "Action: [0 0]\n",
      "Action: [ 0 72]\n",
      "Action: [ 1 95]\n",
      "Action: [ 0 10]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 41]\n",
      "Action: [ 0 38]\n",
      "Action: [1 1]\n",
      "Action: [ 1 57]\n",
      "Action: [ 1 11]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 48]\n",
      "Action: [ 1 36]\n",
      "Action: [ 1 38]\n",
      "Action: [1 0]\n",
      "Action: [ 0 76]\n",
      "Action: [ 1 83]\n",
      "Action: [ 0 30]\n",
      "Action: [ 0 12]\n",
      "Action: [0 3]\n",
      "Action: [ 1 36]\n",
      "Action: [ 0 61]\n",
      "Action: [ 1 83]\n",
      "Action: [1 7]\n",
      "Action: [ 0 34]\n",
      "Action: [ 1 24]\n",
      "Action: [ 0 62]\n",
      "Action: [ 0 78]\n",
      "Action: [ 0 83]\n",
      "Action: [ 0 30]\n",
      "Action: [ 1 29]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 10]\n",
      "Action: [0 5]\n",
      "Action: [ 0 75]\n",
      "Action: [ 0 44]\n",
      "Action: [ 1 32]\n",
      "Action: [ 1 29]\n",
      "Action: [1 1]\n",
      "Action: [ 1 24]\n",
      "Action: [ 1 60]\n",
      "Action: [ 0 98]\n",
      "Action: [ 0 32]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 55]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 51]\n",
      "Action: [ 1 88]\n",
      "Action: [1 1]\n",
      "Action: [ 1 23]\n",
      "Action: [ 1 68]\n",
      "Action: [ 0 17]\n",
      "Action: [ 0 29]\n",
      "Action: [ 1 19]\n",
      "Action: [ 1 51]\n",
      "Action: [ 1 53]\n",
      "Action: [ 0 89]\n",
      "Action: [ 0 32]\n",
      "Action: [ 0 17]\n",
      "Action: [ 0 78]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 94]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 45]\n",
      "Action: [ 1 10]\n",
      "Action: [ 0 92]\n",
      "Action: [ 1 83]\n",
      "Action: [ 0 48]\n",
      "Action: [ 0 14]\n",
      "Action: [ 0 99]\n",
      "Action: [ 0 14]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 59]\n",
      "Action: [ 1 49]\n",
      "Action: [ 1 11]\n",
      "Action: [ 1 39]\n",
      "Action: [ 1 33]\n",
      "Action: [ 1 13]\n",
      "Action: [1 0]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 29]\n",
      "Action: [ 1 23]\n",
      "Action: [ 0 83]\n",
      "Action: [0 1]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 39]\n",
      "Action: [1 8]\n",
      "Action: [ 0 95]\n",
      "Action: [ 1 78]\n",
      "Action: [ 0 85]\n",
      "Action: [ 0 78]\n",
      "Action: [ 0 69]\n",
      "Action: [ 0 88]\n",
      "Action: [ 0 25]\n",
      "Action: [0 5]\n",
      "Action: [ 1 53]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 43]\n",
      "Action: [ 0 53]\n",
      "Action: [ 1 19]\n",
      "Action: [ 1 73]\n",
      "Action: [ 0 32]\n",
      "Action: [ 1 36]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 86]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 92]\n",
      "Action: [ 0 97]\n",
      "Action: [ 1 86]\n",
      "Action: [ 1 57]\n",
      "Action: [ 0 41]\n",
      "Action: [ 0 15]\n",
      "Action: [1 1]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 87]\n",
      "Action: [ 1 88]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 85]\n",
      "Action: [ 1 32]\n",
      "Action: [ 0 89]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 49]\n",
      "Action: [ 0 21]\n",
      "Action: [ 1 31]\n",
      "Action: [ 0 89]\n",
      "Action: [ 0 12]\n",
      "Action: [ 0 35]\n",
      "Action: [ 0 77]\n",
      "Action: [0 1]\n",
      "Action: [ 0 81]\n",
      "Action: [ 0 13]\n",
      "Action: [0 1]\n",
      "Action: [ 1 18]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 83]\n",
      "Action: [0 1]\n",
      "Action: [ 1 78]\n",
      "Action: [ 0 86]\n",
      "Action: [1 4]\n",
      "Action: [ 1 83]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 67]\n",
      "Action: [ 0 29]\n",
      "Action: [ 1 14]\n",
      "Action: [0 7]\n",
      "Action: [0 0]\n",
      "Action: [ 0 78]\n",
      "Action: [ 1 49]\n",
      "Action: [ 1 35]\n",
      "Action: [ 1 17]\n",
      "Action: [ 0 55]\n",
      "Action: [1 1]\n",
      "Action: [ 1 86]\n",
      "Action: [1 1]\n",
      "Action: [ 0 87]\n",
      "Action: [ 1 44]\n",
      "Action: [ 1 73]\n",
      "Action: [ 1 31]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 57]\n",
      "Action: [ 0 77]\n",
      "Action: [ 1 78]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 19]\n",
      "Action: [ 1 39]\n",
      "Action: [ 0 83]\n",
      "Action: [ 0 55]\n",
      "Action: [ 1 15]\n",
      "Action: [ 0 19]\n",
      "Action: [ 0 73]\n",
      "Action: [ 1 40]\n",
      "Action: [ 0 63]\n",
      "Action: [ 0 32]\n",
      "Action: [0 2]\n",
      "Action: [1 1]\n",
      "Action: [ 0 36]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 92]\n",
      "Action: [ 0 34]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 50]\n",
      "Action: [ 0 53]\n",
      "Action: [ 1 64]\n",
      "Action: [0 1]\n",
      "Action: [ 1 62]\n",
      "Action: [ 1 88]\n",
      "Action: [ 0 65]\n",
      "Action: [ 1 98]\n",
      "Action: [ 0 42]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 76]\n",
      "Action: [ 1 73]\n",
      "Action: [0 1]\n",
      "Action: [ 0 30]\n",
      "Action: [ 0 20]\n",
      "Action: [ 1 33]\n",
      "Action: [ 0 14]\n",
      "Action: [0 1]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 41]\n",
      "Action: [ 0 76]\n",
      "Action: [ 1 85]\n",
      "Action: [ 0 54]\n",
      "Action: [ 0 89]\n",
      "Action: [ 1 99]\n",
      "Action: [1 1]\n",
      "Action: [1 6]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 14]\n",
      "Action: [ 0 64]\n",
      "Action: [ 1 55]\n",
      "Action: [ 0 79]\n",
      "Action: [ 0 20]\n",
      "Action: [ 0 49]\n",
      "Action: [ 1 83]\n",
      "Action: [0 1]\n",
      "Action: [ 1 70]\n",
      "Action: [ 1 81]\n",
      "Action: [0 5]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 81]\n",
      "Action: [ 0 61]\n",
      "Action: [ 0 68]\n",
      "Action: [ 0 56]\n",
      "Action: [ 0 32]\n",
      "Action: [ 1 79]\n",
      "Action: [ 0 45]\n",
      "Action: [ 0 50]\n",
      "Action: [ 0 36]\n",
      "Action: [ 1 62]\n",
      "Action: [ 1 77]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 17]\n",
      "Action: [ 0 14]\n",
      "Action: [0 2]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 80]\n",
      "Action: [ 1 87]\n",
      "Action: [ 1 33]\n",
      "Action: [ 0 26]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 98]\n",
      "Action: [ 0 66]\n",
      "Action: [1 1]\n",
      "Action: [ 1 66]\n",
      "Action: [ 1 96]\n",
      "Action: [ 0 94]\n",
      "Action: [ 1 41]\n",
      "Action: [ 1 57]\n",
      "Action: [ 0 68]\n",
      "Action: [0 1]\n",
      "Action: [1 7]\n",
      "Action: [ 1 61]\n",
      "Action: [ 1 46]\n",
      "Action: [ 1 48]\n",
      "Action: [ 1 19]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 64]\n",
      "Action: [ 1 83]\n",
      "Action: [0 1]\n",
      "Action: [0 1]\n",
      "Action: [ 0 99]\n",
      "Action: [ 1 41]\n",
      "Action: [ 0 73]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 72]\n",
      "Action: [ 0 73]\n",
      "Action: [ 1 66]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 49]\n",
      "Action: [ 0 52]\n",
      "Action: [ 1 36]\n",
      "Action: [ 1 73]\n",
      "Action: [ 0 82]\n",
      "Action: [ 0 10]\n",
      "Action: [ 1 19]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 73]\n",
      "Action: [ 0 44]\n",
      "Action: [ 0 14]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 98]\n",
      "Action: [ 1 92]\n",
      "Action: [ 1 81]\n",
      "Action: [ 0 53]\n",
      "Action: [ 0 43]\n",
      "Action: [ 0 95]\n",
      "Action: [ 0 66]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 24]\n",
      "Action: [ 1 78]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 14]\n",
      "Action: [ 0 60]\n",
      "Action: [ 1 97]\n",
      "Action: [ 0 10]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 40]\n",
      "Action: [ 1 35]\n",
      "Action: [ 0 88]\n",
      "Action: [ 1 33]\n",
      "Action: [ 1 49]\n",
      "Action: [ 1 65]\n",
      "Action: [ 1 48]\n",
      "Action: [ 0 84]\n",
      "Action: [ 0 45]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 64]\n",
      "Action: [ 1 24]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 71]\n",
      "Action: [ 1 52]\n",
      "Action: [ 1 68]\n",
      "Action: [ 0 48]\n",
      "Action: [ 1 29]\n",
      "Action: [ 1 41]\n",
      "Action: [ 0 42]\n",
      "Action: [ 0 23]\n",
      "Action: [ 0 12]\n",
      "Action: [ 0 38]\n",
      "Action: [1 1]\n",
      "Action: [1 1]\n",
      "Action: [ 0 14]\n",
      "Action: [ 0 37]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 60]\n",
      "Action: [ 0 16]\n",
      "Action: [ 1 63]\n",
      "Action: [ 0 76]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 14]\n",
      "Action: [ 0 86]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 96]\n",
      "Action: [ 1 71]\n",
      "Action: [ 0 77]\n",
      "Action: [ 1 53]\n",
      "Action: [ 0 84]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 11]\n",
      "Action: [ 1 91]\n",
      "Action: [0 1]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 97]\n",
      "Action: [ 0 88]\n",
      "Action: [ 0 23]\n",
      "Action: [0 7]\n",
      "Action: [ 1 95]\n",
      "Action: [ 0 35]\n",
      "Action: [ 0 93]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 68]\n",
      "Action: [0 6]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 95]\n",
      "Action: [ 1 76]\n",
      "Action: [0 5]\n",
      "Action: [ 0 62]\n",
      "Action: [ 1 39]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 35]\n",
      "Action: [ 1 52]\n",
      "Action: [ 0 85]\n",
      "Action: [ 0 24]\n",
      "Action: [0 8]\n",
      "Action: [ 1 91]\n",
      "Action: [0 3]\n",
      "Action: [ 1 31]\n",
      "Action: [ 1 29]\n",
      "Action: [1 8]\n",
      "Action: [ 0 52]\n",
      "Action: [ 0 86]\n",
      "Action: [ 1 66]\n",
      "Action: [ 1 76]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 65]\n",
      "Action: [ 1 72]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 19]\n",
      "Action: [ 1 45]\n",
      "Action: [ 1 54]\n",
      "Action: [ 0 71]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 92]\n",
      "Action: [ 1 99]\n",
      "Action: [ 1 95]\n",
      "Action: [ 0 51]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 97]\n",
      "Action: [ 0 78]\n",
      "Action: [ 1 54]\n",
      "Action: [ 1 29]\n",
      "Action: [ 1 96]\n",
      "Action: [ 1 15]\n",
      "Action: [ 1 50]\n",
      "Action: [ 0 78]\n",
      "Action: [ 0 44]\n",
      "Action: [ 0 58]\n",
      "Action: [ 1 37]\n",
      "Action: [ 1 40]\n",
      "Action: [ 1 83]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 84]\n",
      "Action: [ 1 13]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 97]\n",
      "Action: [ 0 84]\n",
      "Action: [ 1 91]\n",
      "Action: [ 0 19]\n",
      "Action: [ 0 10]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 39]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 23]\n",
      "Action: [ 0 68]\n",
      "Action: [0 7]\n",
      "Action: [ 0 55]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 77]\n",
      "Action: [ 0 44]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 72]\n",
      "Action: [1 2]\n",
      "Action: [ 0 38]\n",
      "Action: [ 1 77]\n",
      "Action: [ 0 60]\n",
      "Action: [ 0 85]\n",
      "Action: [ 1 76]\n",
      "Action: [ 1 17]\n",
      "Action: [ 0 24]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 15]\n",
      "Action: [1 0]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 59]\n",
      "Action: [0 7]\n",
      "Action: [ 1 23]\n",
      "Action: [ 1 32]\n",
      "Action: [ 0 50]\n",
      "Action: [ 1 37]\n",
      "Action: [ 0 75]\n",
      "Action: [1 0]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 30]\n",
      "Action: [ 0 34]\n",
      "Action: [0 1]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 52]\n",
      "Action: [ 1 20]\n",
      "Action: [ 0 14]\n",
      "Action: [ 0 92]\n",
      "Action: [ 0 43]\n",
      "Action: [1 1]\n",
      "Action: [ 0 10]\n",
      "Action: [1 1]\n",
      "Action: [0 1]\n",
      "Action: [0 1]\n",
      "Action: [0 7]\n",
      "Action: [ 1 34]\n",
      "Action: [ 0 55]\n",
      "Action: [1 1]\n",
      "Action: [ 0 80]\n",
      "Action: [ 1 83]\n",
      "Action: [ 1 48]\n",
      "Action: [ 0 15]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 55]\n",
      "Action: [ 0 13]\n",
      "Action: [0 1]\n",
      "Action: [ 0 14]\n",
      "Action: [ 1 47]\n",
      "Action: [0 3]\n",
      "Action: [ 0 85]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 80]\n",
      "Action: [ 0 10]\n",
      "Action: [0 1]\n",
      "Action: [ 0 52]\n",
      "Action: [ 1 86]\n",
      "Action: [ 1 50]\n",
      "Action: [ 0 96]\n",
      "Action: [ 0 41]\n",
      "Action: [ 1 14]\n",
      "Action: [ 1 26]\n",
      "Action: [1 5]\n",
      "Action: [ 0 77]\n",
      "Action: [ 1 17]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 92]\n",
      "Action: [0 8]\n",
      "Action: [ 1 53]\n",
      "Action: [ 1 40]\n",
      "Action: [ 1 47]\n",
      "Action: [1 1]\n",
      "Action: [ 1 30]\n",
      "Action: [ 1 30]\n",
      "Action: [ 0 60]\n",
      "Action: [ 0 38]\n",
      "Action: [ 0 88]\n",
      "Action: [ 1 30]\n",
      "Action: [ 0 60]\n",
      "Action: [ 0 82]\n",
      "Action: [ 1 49]\n",
      "Action: [ 1 17]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 30]\n",
      "Action: [ 0 18]\n",
      "Action: [ 1 10]\n",
      "Action: [ 1 24]\n",
      "Action: [ 0 49]\n",
      "Action: [ 1 60]\n",
      "Action: [ 0 30]\n",
      "Action: [ 0 52]\n",
      "Action: [ 1 71]\n",
      "Action: [ 1 46]\n",
      "Action: [ 0 31]\n",
      "Action: [ 1 57]\n",
      "Action: [ 1 86]\n",
      "Action: [ 0 44]\n",
      "Action: [ 0 86]\n",
      "Action: [ 1 52]\n",
      "Action: [1 8]\n",
      "Action: [0 1]\n",
      "Action: [0 9]\n",
      "Action: [ 0 96]\n",
      "Action: [ 0 50]\n",
      "Action: [ 0 13]\n",
      "Action: [ 1 64]\n",
      "Action: [ 0 55]\n",
      "Action: [ 1 64]\n",
      "Action: [0 1]\n",
      "Action: [ 1 55]\n",
      "Action: [0 1]\n",
      "Action: [ 0 17]\n",
      "Action: [ 0 17]\n",
      "Action: [ 0 27]\n",
      "Action: [ 1 47]\n",
      "Action: [ 1 67]\n",
      "Action: [ 1 59]\n",
      "Action: [ 1 84]\n",
      "Action: [ 0 82]\n",
      "Action: [ 1 37]\n",
      "Action: [ 0 62]\n",
      "Action: [ 0 60]\n",
      "Action: [0 8]\n",
      "Action: [ 1 71]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 34]\n",
      "Action: [ 0 57]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 52]\n",
      "Action: [ 0 10]\n",
      "Action: [ 1 51]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 18]\n",
      "Action: [ 1 65]\n",
      "Action: [ 0 13]\n",
      "Action: [ 0 50]\n",
      "Action: [1 1]\n",
      "Action: [ 1 39]\n",
      "Action: [ 1 24]\n",
      "Action: [ 0 61]\n",
      "Action: [ 1 15]\n",
      "Action: [ 1 79]\n",
      "Action: [ 0 92]\n",
      "Action: [ 0 91]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 76]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 86]\n",
      "Action: [ 0 68]\n",
      "Action: [ 0 60]\n",
      "Action: [ 0 14]\n",
      "Action: [ 1 32]\n",
      "Action: [0 7]\n",
      "Action: [ 0 82]\n",
      "Action: [ 0 26]\n",
      "Action: [ 0 31]\n",
      "Action: [1 9]\n",
      "Action: [0 8]\n",
      "Action: [ 1 78]\n",
      "Action: [0 3]\n",
      "Action: [ 1 76]\n",
      "Action: [ 0 19]\n",
      "Action: [ 0 96]\n",
      "Action: [ 0 55]\n",
      "Action: [ 1 52]\n",
      "Action: [ 0 51]\n",
      "Action: [ 1 78]\n",
      "Action: [ 0 56]\n",
      "Action: [1 2]\n",
      "Action: [ 0 40]\n",
      "Action: [ 1 21]\n",
      "Action: [ 1 85]\n",
      "Action: [ 1 13]\n",
      "Action: [0 8]\n",
      "Action: [ 0 98]\n",
      "Action: [ 1 36]\n",
      "Action: [ 1 55]\n",
      "Action: [ 0 93]\n",
      "Action: [0 5]\n",
      "Action: [ 1 92]\n",
      "Action: [0 1]\n",
      "Action: [ 0 28]\n",
      "Action: [ 1 88]\n",
      "Action: [ 1 39]\n",
      "Action: [ 1 46]\n",
      "Action: [ 0 37]\n",
      "Action: [ 1 83]\n",
      "Action: [ 1 38]\n",
      "Action: [ 1 51]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 20]\n",
      "Action: [ 1 17]\n",
      "Action: [0 3]\n",
      "Action: [ 1 88]\n",
      "Action: [ 1 96]\n",
      "Action: [0 1]\n",
      "Action: [ 1 97]\n",
      "Action: [ 0 46]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 15]\n",
      "Action: [ 1 41]\n",
      "Action: [1 1]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 50]\n",
      "Action: [ 0 97]\n",
      "Action: [ 0 99]\n",
      "Action: [ 1 60]\n",
      "Action: [1 5]\n",
      "Action: [0 1]\n",
      "Action: [ 0 29]\n",
      "Action: [ 0 34]\n",
      "Action: [ 1 13]\n",
      "Action: [ 1 62]\n",
      "Action: [ 0 45]\n",
      "Action: [ 1 36]\n",
      "Action: [ 1 53]\n",
      "Action: [ 1 73]\n",
      "Action: [ 0 41]\n",
      "Action: [ 0 87]\n",
      "Action: [ 0 36]\n",
      "Action: [ 1 42]\n",
      "Action: [ 0 38]\n",
      "Action: [1 7]\n",
      "Action: [ 1 17]\n",
      "Action: [1 2]\n",
      "Action: [ 0 34]\n",
      "Action: [ 0 51]\n",
      "Action: [ 0 63]\n",
      "Action: [ 1 91]\n",
      "Action: [ 1 37]\n",
      "Action: [ 0 60]\n",
      "Action: [ 1 88]\n",
      "Action: [ 0 50]\n",
      "Action: [ 1 83]\n",
      "Action: [ 1 91]\n",
      "Action: [0 1]\n",
      "Action: [ 0 17]\n",
      "Action: [ 1 77]\n",
      "Action: [ 1 86]\n",
      "Action: [ 1 59]\n",
      "Action: [ 0 40]\n",
      "Action: [ 1 78]\n",
      "Action: [ 0 23]\n",
      "Action: [ 1 77]\n",
      "Action: [ 0 18]\n",
      "Action: [ 0 80]\n",
      "Action: [ 0 44]\n",
      "Action: [ 1 55]\n",
      "Action: [ 0 15]\n",
      "Action: [ 0 30]\n",
      "Action: [ 0 88]\n",
      "Action: [ 0 91]\n",
      "Action: [ 0 95]\n",
      "Action: [ 1 30]\n",
      "Action: [ 1 59]\n",
      "Action: [ 0 37]\n",
      "Action: [ 0 97]\n",
      "Action: [0 9]\n",
      "Action: [ 0 21]\n",
      "Action: [ 1 74]\n",
      "Action: [ 0 32]\n",
      "Action: [0 4]\n",
      "Action: [ 0 21]\n",
      "Action: [ 1 38]\n",
      "Action: [ 0 36]\n",
      "Action: [ 0 81]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env.ipynb Cell 41'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env.ipynb#ch0000041vscode-remote?line=2'>3</a>\u001b[0m obs \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env.ipynb#ch0000041vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(steps):\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env.ipynb#ch0000041vscode-remote?line=4'>5</a>\u001b[0m     action, _state \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39;49mpredict(obs, deterministic\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env.ipynb#ch0000041vscode-remote?line=5'>6</a>\u001b[0m     \u001b[39mif\u001b[39;00m action[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m :\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env.ipynb#ch0000041vscode-remote?line=6'>7</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAction: \u001b[39m\u001b[39m{\u001b[39;00maction[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/base_class.py:562\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/base_class.py?line=541'>542</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/base_class.py?line=542'>543</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/base_class.py?line=543'>544</a>\u001b[0m     observation: np\u001b[39m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/base_class.py?line=546'>547</a>\u001b[0m     deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/base_class.py?line=547'>548</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[np\u001b[39m.\u001b[39mndarray, Optional[Tuple[np\u001b[39m.\u001b[39mndarray, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]]]:\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/base_class.py?line=548'>549</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/base_class.py?line=549'>550</a>\u001b[0m \u001b[39m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/base_class.py?line=550'>551</a>\u001b[0m \u001b[39m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/base_class.py?line=559'>560</a>\u001b[0m \u001b[39m        (used in recurrent policies)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/base_class.py?line=560'>561</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/base_class.py?line=561'>562</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy\u001b[39m.\u001b[39;49mpredict(observation, state, episode_start, deterministic)\n",
      "File \u001b[0;32m~/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py:338\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=334'>335</a>\u001b[0m observation, vectorized_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_to_tensor(observation)\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=336'>337</a>\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=337'>338</a>\u001b[0m     actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(observation, deterministic\u001b[39m=\u001b[39;49mdeterministic)\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=338'>339</a>\u001b[0m \u001b[39m# Convert to numpy\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=339'>340</a>\u001b[0m actions \u001b[39m=\u001b[39m actions\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py:630\u001b[0m, in \u001b[0;36mActorCriticPolicy._predict\u001b[0;34m(self, observation, deterministic)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=621'>622</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, observation: th\u001b[39m.\u001b[39mTensor, deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m th\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=622'>623</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=623'>624</a>\u001b[0m \u001b[39m    Get the action according to the policy for a given observation.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=624'>625</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=627'>628</a>\u001b[0m \u001b[39m    :return: Taken action according to the policy\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=628'>629</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=629'>630</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_distribution(observation)\u001b[39m.\u001b[39mget_actions(deterministic\u001b[39m=\u001b[39mdeterministic)\n",
      "File \u001b[0;32m~/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py:659\u001b[0m, in \u001b[0;36mActorCriticPolicy.get_distribution\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=656'>657</a>\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_features(obs)\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=657'>658</a>\u001b[0m latent_pi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_extractor\u001b[39m.\u001b[39mforward_actor(features)\n\u001b[0;32m--> <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=658'>659</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_action_dist_from_latent(latent_pi)\n",
      "File \u001b[0;32m~/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py:613\u001b[0m, in \u001b[0;36mActorCriticPolicy._get_action_dist_from_latent\u001b[0;34m(self, latent_pi)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=609'>610</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist\u001b[39m.\u001b[39mproba_distribution(action_logits\u001b[39m=\u001b[39mmean_actions)\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=610'>611</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist, MultiCategoricalDistribution):\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=611'>612</a>\u001b[0m     \u001b[39m# Here mean_actions are the flattened logits\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=612'>613</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_dist\u001b[39m.\u001b[39;49mproba_distribution(action_logits\u001b[39m=\u001b[39;49mmean_actions)\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=613'>614</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist, BernoulliDistribution):\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=614'>615</a>\u001b[0m     \u001b[39m# Here mean_actions are the logits (before rounding to get the binary actions)\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/policies.py?line=615'>616</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dist\u001b[39m.\u001b[39mproba_distribution(action_logits\u001b[39m=\u001b[39mmean_actions)\n",
      "File \u001b[0;32m~/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/distributions.py:326\u001b[0m, in \u001b[0;36mMultiCategoricalDistribution.proba_distribution\u001b[0;34m(self, action_logits)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/distributions.py?line=324'>325</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mproba_distribution\u001b[39m(\u001b[39mself\u001b[39m, action_logits: th\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMultiCategoricalDistribution\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/distributions.py?line=325'>326</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribution \u001b[39m=\u001b[39m [Categorical(logits\u001b[39m=\u001b[39msplit) \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m th\u001b[39m.\u001b[39msplit(action_logits, \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dims), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/distributions.py?line=326'>327</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/distributions.py:326\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/distributions.py?line=324'>325</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mproba_distribution\u001b[39m(\u001b[39mself\u001b[39m, action_logits: th\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMultiCategoricalDistribution\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/distributions.py?line=325'>326</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribution \u001b[39m=\u001b[39m [Categorical(logits\u001b[39m=\u001b[39;49msplit) \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m th\u001b[39m.\u001b[39msplit(action_logits, \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_dims), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)]\n\u001b[1;32m    <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/stable_baselines3/common/distributions.py?line=326'>327</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Projects/rl-algos/.venv/lib/python3.8/site-packages/torch/distributions/categorical.py:60\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/torch/distributions/categorical.py?line=57'>58</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`logits` parameter must be at least one-dimensional.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/torch/distributions/categorical.py?line=58'>59</a>\u001b[0m     \u001b[39m# Normalize\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/torch/distributions/categorical.py?line=59'>60</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogits \u001b[39m=\u001b[39m logits \u001b[39m-\u001b[39m logits\u001b[39m.\u001b[39;49mlogsumexp(dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, keepdim\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/torch/distributions/categorical.py?line=60'>61</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_param \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobs \u001b[39mif\u001b[39;00m probs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogits\n\u001b[1;32m     <a href='file:///home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/torch/distributions/categorical.py?line=61'>62</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_events \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_param\u001b[39m.\u001b[39msize()[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "steps = 100000\n",
    "render_interval = steps // 10\n",
    "obs = env.reset()\n",
    "for i in range(steps):\n",
    "    action, _state = loaded_model.predict(obs, deterministic=False)\n",
    "    if action[0][0] < 2 :\n",
    "        print(f\"Action: {action[0]}\")\n",
    "    # env.step_async(action)\n",
    "    # obs, reward, done, info =  env.step_wait()\n",
    "    # print('obs:', obs)\n",
    "    # print('action:', action)\n",
    "    # print('reward:', reward)\n",
    "    # print('done:', done)\n",
    "    # print('info:', info)\n",
    "    # # if (i % render_interval) == 0:\n",
    "    # #     env.env_method('render')\n",
    "    # # if done:\n",
    "    # #     obs = env.env_method('reset')\n",
    "# env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a0e79-0a3f-4990-b278-42d85b0822d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SubprocVecEnv' object has no attribute 'env'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env.ipynb Cell 43'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env.ipynb#ch0000043vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(env\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39mtrade_history)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SubprocVecEnv' object has no attribute 'env'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(env.env.trade_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb69ad6-2bc7-48c2-b706-fdb99b688141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23346b2-bbbc-4a96-9dfe-9c9c60440987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TensorTrade.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
