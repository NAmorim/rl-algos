{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a951a47f-88f5-40f0-8fe3-5495f76633b5",
   "metadata": {
    "id": "a951a47f-88f5-40f0-8fe3-5495f76633b5"
   },
   "source": [
    "# Install needed deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c89b3-be5c-49c6-bb0d-4fea729bddee",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Don't forget to run ```apt-get update --fix-missing && sudo apt-get install build-essential``` and ```apt-get install zlib1g-dev``` in case you are running on an Ubuntu image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bede9272-b231-4d56-97ef-e2e180cf0655",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "bede9272-b231-4d56-97ef-e2e180cf0655",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "82aa9af4-5352-4e8b-dafa-83b334765f71",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-ta==0.3.14b in ./.venv/lib/python3.8/site-packages (0.3.14b0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.8/site-packages (from pandas-ta==0.3.14b) (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.8/site-packages (from pandas->pandas-ta==0.3.14b) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in ./.venv/lib/python3.8/site-packages (from pandas->pandas-ta==0.3.14b) (1.22.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas->pandas-ta==0.3.14b) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->pandas-ta==0.3.14b) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: gym==0.21.0 in ./.venv/lib/python3.8/site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in ./.venv/lib/python3.8/site-packages (from gym==0.21.0) (1.22.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in ./.venv/lib/python3.8/site-packages (from gym==0.21.0) (1.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.8/site-packages (7.7.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in ./.venv/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in ./.venv/lib/python3.8/site-packages (from ipywidgets) (5.2.0)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in ./.venv/lib/python3.8/site-packages (from ipywidgets) (8.1.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in ./.venv/lib/python3.8/site-packages (from ipywidgets) (3.6.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in ./.venv/lib/python3.8/site-packages (from ipywidgets) (1.1.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in ./.venv/lib/python3.8/site-packages (from ipywidgets) (6.9.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jupyter-core in ./.venv/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in ./.venv/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (3.0.28)\n",
      "Requirement already satisfied: backcall in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (44.0.0)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: pickleshare in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: notebook>=4.4.1 in ./.venv/lib/python3.8/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.4.10)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in ./.venv/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.0)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in ./.venv/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: jupyter-client<8.0 in ./.venv/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.2)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.4)\n",
      "Requirement already satisfied: attrs>=17.4.0 in ./.venv/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in ./.venv/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0; python_version < \"3.9\" in ./.venv/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (5.6.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: asttokens in ./.venv/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: executing in ./.venv/lib/python3.8/site-packages (from stack-data->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./.venv/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.8/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.1)\n",
      "Requirement already satisfied: nbconvert>=5 in ./.venv/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.4.4)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./.venv/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.3)\n",
      "Requirement already satisfied: argon2-cffi in ./.venv/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in ./.venv/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in ./.venv/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: pyzmq>=17 in ./.venv/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: entrypoints in ./.venv/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in ./.venv/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in ./.venv/lib/python3.8/site-packages (from importlib-resources>=1.4.0; python_version < \"3.9\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.7.0)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.8/site-packages (from asttokens->stack-data->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in ./.venv/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./.venv/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: bleach in ./.venv/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./.venv/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: testpath in ./.venv/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: defusedxml in ./.venv/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in ./.venv/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.13)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.8/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.10.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./.venv/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.8/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3)\n",
      "Requirement already satisfied: webencodings in ./.venv/lib/python3.8/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.8/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.3.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in ./.venv/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./.venv/lib/python3.8/site-packages (from packaging->bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: stable-baselines3[extra] in ./.venv/lib/python3.8/site-packages (1.5.0)\n",
      "Requirement already satisfied: gym==0.21 in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (0.21.0)\n",
      "Requirement already satisfied: torch>=1.8.1 in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.11.0)\n",
      "Requirement already satisfied: cloudpickle in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.6.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.4.1)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (3.5.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (1.22.3)\n",
      "Requirement already satisfied: ale-py~=0.7.4; extra == \"extra\" in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (0.7.4)\n",
      "Requirement already satisfied: pillow; extra == \"extra\" in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (7.2.0)\n",
      "Requirement already satisfied: psutil; extra == \"extra\" in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (5.9.0)\n",
      "Requirement already satisfied: opencv-python; extra == \"extra\" in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (4.5.5.64)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2; extra == \"extra\" in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: tensorboard>=2.2.0; extra == \"extra\" in ./.venv/lib/python3.8/site-packages (from stable-baselines3[extra]) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.8/site-packages (from torch>=1.8.1->stable-baselines3[extra]) (4.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.8/site-packages (from pandas->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas->stable-baselines3[extra]) (2022.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (4.31.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./.venv/lib/python3.8/site-packages (from matplotlib->stable-baselines3[extra]) (3.0.7)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0; python_version < \"3.10\" in ./.venv/lib/python3.8/site-packages (from ale-py~=0.7.4; extra == \"extra\"->stable-baselines3[extra]) (4.11.3)\n",
      "Requirement already satisfied: importlib-resources in ./.venv/lib/python3.8/site-packages (from ale-py~=0.7.4; extra == \"extra\"->stable-baselines3[extra]) (5.6.0)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (4.63.1)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (2.27.1)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (8.0.4)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license; extra == \"accept-rom-license\" in ./.venv/lib/python3.8/site-packages (from autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (44.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (2.6.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (3.19.4)\n",
      "Requirement already satisfied: wheel>=0.26 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (2.0.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (3.3.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (1.44.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./.venv/lib/python3.8/site-packages (from tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.8/site-packages (from importlib-metadata>=4.10.0; python_version < \"3.10\"->ale-py~=0.7.4; extra == \"extra\"->stable-baselines3[extra]) (3.7.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in ./.venv/lib/python3.8/site-packages (from requests->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.venv/lib/python3.8/site-packages (from requests->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in ./.venv/lib/python3.8/site-packages (from requests->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.8/site-packages (from requests->autorom[accept-rom-license]~=0.4.2; extra == \"extra\"->stable-baselines3[extra]) (2021.10.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in ./.venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.venv/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./.venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0; extra == \"extra\"->stable-baselines3[extra]) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ta in ./.venv/lib/python3.8/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.8/site-packages (from ta) (1.22.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.8/site-packages (from ta) (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.8/site-packages (from pandas->ta) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas->ta) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->ta) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: quantstats in ./.venv/lib/python3.8/site-packages (0.0.50)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in ./.venv/lib/python3.8/site-packages (from quantstats) (0.11.2)\n",
      "Requirement already satisfied: tabulate>=0.8.0 in ./.venv/lib/python3.8/site-packages (from quantstats) (0.8.9)\n",
      "Requirement already satisfied: yfinance>=0.1.70 in ./.venv/lib/python3.8/site-packages (from quantstats) (0.1.70)\n",
      "Requirement already satisfied: pandas>=0.24.0 in ./.venv/lib/python3.8/site-packages (from quantstats) (1.4.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in ./.venv/lib/python3.8/site-packages (from quantstats) (1.8.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in ./.venv/lib/python3.8/site-packages (from quantstats) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in ./.venv/lib/python3.8/site-packages (from quantstats) (1.22.3)\n",
      "Requirement already satisfied: lxml>=4.5.1 in ./.venv/lib/python3.8/site-packages (from yfinance>=0.1.70->quantstats) (4.8.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in ./.venv/lib/python3.8/site-packages (from yfinance>=0.1.70->quantstats) (0.0.10)\n",
      "Requirement already satisfied: requests>=2.26 in ./.venv/lib/python3.8/site-packages (from yfinance>=0.1.70->quantstats) (2.27.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas>=0.24.0->quantstats) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.8/site-packages (from pandas>=0.24.0->quantstats) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib>=3.0.0->quantstats) (1.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.8/site-packages (from matplotlib>=3.0.0->quantstats) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.8/site-packages (from matplotlib>=3.0.0->quantstats) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./.venv/lib/python3.8/site-packages (from matplotlib>=3.0.0->quantstats) (3.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.8/site-packages (from matplotlib>=3.0.0->quantstats) (4.31.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib>=3.0.0->quantstats) (7.2.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in ./.venv/lib/python3.8/site-packages (from requests>=2.26->yfinance>=0.1.70->quantstats) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in ./.venv/lib/python3.8/site-packages (from requests>=2.26->yfinance>=0.1.70->quantstats) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.8/site-packages (from requests>=2.26->yfinance>=0.1.70->quantstats) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.venv/lib/python3.8/site-packages (from requests>=2.26->yfinance>=0.1.70->quantstats) (1.26.9)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=0.24.0->quantstats) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sklearn in ./.venv/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.8/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in ./.venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in ./.venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.22.3)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.venv/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: feature_engine in ./.venv/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./.venv/lib/python3.8/site-packages (from feature_engine) (1.8.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in ./.venv/lib/python3.8/site-packages (from feature_engine) (1.0.2)\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in ./.venv/lib/python3.8/site-packages (from feature_engine) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in ./.venv/lib/python3.8/site-packages (from feature_engine) (1.22.3)\n",
      "Requirement already satisfied: pandas>=1.0.3 in ./.venv/lib/python3.8/site-packages (from feature_engine) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.8/site-packages (from scikit-learn>=0.22.2->feature_engine) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.venv/lib/python3.8/site-packages (from scikit-learn>=0.22.2->feature_engine) (1.1.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in ./.venv/lib/python3.8/site-packages (from statsmodels>=0.11.1->feature_engine) (0.5.2)\n",
      "Requirement already satisfied: packaging>=21.3 in ./.venv/lib/python3.8/site-packages (from statsmodels>=0.11.1->feature_engine) (21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas>=1.0.3->feature_engine) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.venv/lib/python3.8/site-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.8/site-packages (from patsy>=0.5.2->statsmodels>=0.11.1->feature_engine) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./.venv/lib/python3.8/site-packages (from packaging>=21.3->statsmodels>=0.11.1->feature_engine) (3.0.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already up-to-date: mplfinance in ./.venv/lib/python3.8/site-packages (0.12.8b9)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in ./.venv/lib/python3.8/site-packages (from mplfinance) (3.5.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas in ./.venv/lib/python3.8/site-packages (from mplfinance) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in ./.venv/lib/python3.8/site-packages (from matplotlib->mplfinance) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->mplfinance) (7.2.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17 in ./.venv/lib/python3.8/site-packages (from matplotlib->mplfinance) (1.22.3)\n",
      "Requirement already satisfied, skipping upgrade: packaging>=20.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->mplfinance) (21.3)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in ./.venv/lib/python3.8/site-packages (from matplotlib->mplfinance) (0.11.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.2.1 in ./.venv/lib/python3.8/site-packages (from matplotlib->mplfinance) (3.0.7)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7 in ./.venv/lib/python3.8/site-packages (from matplotlib->mplfinance) (2.8.2)\n",
      "Requirement already satisfied, skipping upgrade: fonttools>=4.22.0 in ./.venv/lib/python3.8/site-packages (from matplotlib->mplfinance) (4.31.2)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2020.1 in ./.venv/lib/python3.8/site-packages (from pandas->mplfinance) (2022.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in ./.venv/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->mplfinance) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas-ta==0.3.14b --pre\n",
    "%pip install gym==0.21.0\n",
    "%pip install ipywidgets\n",
    "%pip install stable-baselines3[extra]\n",
    "%pip install ta\n",
    "%pip install quantstats\n",
    "%pip install sklearn\n",
    "%pip install feature_engine\n",
    "%pip install --upgrade mplfinance\n",
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23c0bc4-b9bd-49e8-b79b-d11fc1aa8629",
   "metadata": {
    "id": "c23c0bc4-b9bd-49e8-b79b-d11fc1aa8629"
   },
   "source": [
    "# Prepare and fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "022f3a95-c2d5-4737-906c-270ee437c03b",
   "metadata": {
    "id": "022f3a95-c2d5-4737-906c-270ee437c03b"
   },
   "outputs": [],
   "source": [
    "from tensortrade.data.cdd import CryptoDataDownload\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "\n",
    "def prepare_data(df):\n",
    "    df['volume'] = np.int64(df['volume'])\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values(by='date', ascending=True, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['date'] = df['date'].dt.strftime('%Y-%m-%d %I:%M %p')\n",
    "    return df\n",
    "\n",
    "def fetch_data():\n",
    "    cdd = CryptoDataDownload()\n",
    "    bitfinex_data = cdd.fetch(\"Bitfinex\", \"USD\", \"BTC\", \"1h\")\n",
    "    bitfinex_data = bitfinex_data[['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    bitfinex_data = prepare_data(bitfinex_data)\n",
    "    return bitfinex_data\n",
    "\n",
    "def load_csv(filename):\n",
    "    df = pd.read_csv('data/' + filename, skiprows=1)\n",
    "    df.drop(columns=['symbol', 'volume_btc'], inplace=True)\n",
    "\n",
    "    # Fix timestamp from \"2019-10-17 09-AM\" to \"2019-10-17 09-00-00 AM\"\n",
    "    df['date'] = df['date'].str[:14] + '00-00 ' + df['date'].str[-2:]\n",
    "\n",
    "    return prepare_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7711877c-da93-4743-acf3-bd03d23f07c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-15 06:00 AM</td>\n",
       "      <td>8723.800000</td>\n",
       "      <td>8793.000000</td>\n",
       "      <td>8714.90000</td>\n",
       "      <td>8739.000000</td>\n",
       "      <td>8988053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-15 07:00 AM</td>\n",
       "      <td>8739.000000</td>\n",
       "      <td>8754.800000</td>\n",
       "      <td>8719.30000</td>\n",
       "      <td>8743.000000</td>\n",
       "      <td>2288904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-15 08:00 AM</td>\n",
       "      <td>8743.000000</td>\n",
       "      <td>8743.100000</td>\n",
       "      <td>8653.20000</td>\n",
       "      <td>8723.700000</td>\n",
       "      <td>8891773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-15 09:00 AM</td>\n",
       "      <td>8723.700000</td>\n",
       "      <td>8737.800000</td>\n",
       "      <td>8701.20000</td>\n",
       "      <td>8708.100000</td>\n",
       "      <td>2054868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-15 10:00 AM</td>\n",
       "      <td>8708.100000</td>\n",
       "      <td>8855.700000</td>\n",
       "      <td>8695.80000</td>\n",
       "      <td>8784.400000</td>\n",
       "      <td>17309722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34354</th>\n",
       "      <td>2022-04-17 09:00 PM</td>\n",
       "      <td>40279.000000</td>\n",
       "      <td>40310.948566</td>\n",
       "      <td>40152.00000</td>\n",
       "      <td>40227.829085</td>\n",
       "      <td>2411100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34355</th>\n",
       "      <td>2022-04-17 10:00 PM</td>\n",
       "      <td>40215.000000</td>\n",
       "      <td>40363.000000</td>\n",
       "      <td>39957.00000</td>\n",
       "      <td>40016.000000</td>\n",
       "      <td>8236277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34356</th>\n",
       "      <td>2022-04-17 11:00 PM</td>\n",
       "      <td>40021.000000</td>\n",
       "      <td>40021.000000</td>\n",
       "      <td>39563.00000</td>\n",
       "      <td>39707.552712</td>\n",
       "      <td>10678099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34357</th>\n",
       "      <td>2022-04-18 12:00 AM</td>\n",
       "      <td>39699.719303</td>\n",
       "      <td>39796.000000</td>\n",
       "      <td>39602.00000</td>\n",
       "      <td>39745.389366</td>\n",
       "      <td>5425275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34358</th>\n",
       "      <td>2022-04-18 01:00 AM</td>\n",
       "      <td>39744.000000</td>\n",
       "      <td>39851.641499</td>\n",
       "      <td>39731.22461</td>\n",
       "      <td>39796.573934</td>\n",
       "      <td>983800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34359 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date          open          high          low  \\\n",
       "0      2018-05-15 06:00 AM   8723.800000   8793.000000   8714.90000   \n",
       "1      2018-05-15 07:00 AM   8739.000000   8754.800000   8719.30000   \n",
       "2      2018-05-15 08:00 AM   8743.000000   8743.100000   8653.20000   \n",
       "3      2018-05-15 09:00 AM   8723.700000   8737.800000   8701.20000   \n",
       "4      2018-05-15 10:00 AM   8708.100000   8855.700000   8695.80000   \n",
       "...                    ...           ...           ...          ...   \n",
       "34354  2022-04-17 09:00 PM  40279.000000  40310.948566  40152.00000   \n",
       "34355  2022-04-17 10:00 PM  40215.000000  40363.000000  39957.00000   \n",
       "34356  2022-04-17 11:00 PM  40021.000000  40021.000000  39563.00000   \n",
       "34357  2022-04-18 12:00 AM  39699.719303  39796.000000  39602.00000   \n",
       "34358  2022-04-18 01:00 AM  39744.000000  39851.641499  39731.22461   \n",
       "\n",
       "              close    volume  \n",
       "0       8739.000000   8988053  \n",
       "1       8743.000000   2288904  \n",
       "2       8723.700000   8891773  \n",
       "3       8708.100000   2054868  \n",
       "4       8784.400000  17309722  \n",
       "...             ...       ...  \n",
       "34354  40227.829085   2411100  \n",
       "34355  40016.000000   8236277  \n",
       "34356  39707.552712  10678099  \n",
       "34357  39745.389366   5425275  \n",
       "34358  39796.573934    983800  \n",
       "\n",
       "[34359 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fetch_data()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdac31a-4ad2-4365-b061-bf0eaa5b4b49",
   "metadata": {},
   "source": [
    "## Create features for the feed module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe71f2a-5779-4e49-9b1a-a2952f07052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import ta as ta1\n",
    "import pandas_ta as ta\n",
    "\n",
    "import quantstats as qs\n",
    "qs.extend_pandas()\n",
    "\n",
    "def fix_dataset_inconsistencies_without_backfilling(dataframe, fill_value=None):\n",
    "    dataframe = dataframe.replace([-np.inf, np.inf], np.nan)\n",
    "\n",
    "    return dataframe.fillna(axis='index', method='pad').dropna(axis='columns')\n",
    "\n",
    "def fix_dataset_inconsistencies(dataframe, fill_value=None):\n",
    "    dataframe = dataframe.replace([-np.inf, np.inf], np.nan)\n",
    "\n",
    "    #This is done to avoid filling middle holes with backfilling.\n",
    "    if fill_value is None:\n",
    "        dataframe.iloc[0,:] = \\\n",
    "            dataframe.apply(lambda column: column.iloc[column.first_valid_index()], axis='index')\n",
    "    else:\n",
    "        dataframe.iloc[0,:] = \\\n",
    "            dataframe.iloc[0,:].fillna(fill_value)\n",
    "\n",
    "    return dataframe.fillna(axis='index', method='pad').dropna(axis='columns')\n",
    "\n",
    "def rsi(price: 'pd.Series[pd.Float64Dtype]', period: float) -> 'pd.Series[pd.Float64Dtype]':\n",
    "    r = price.diff()\n",
    "    upside = np.minimum(r, 0).abs()\n",
    "    downside = np.maximum(r, 0).abs()\n",
    "    rs = upside.ewm(alpha=1 / period).mean() / downside.ewm(alpha=1 / period).mean()\n",
    "    return 100*(1 - (1 + rs) ** -1)\n",
    "\n",
    "def macd(price: 'pd.Series[pd.Float64Dtype]', fast: float, slow: float, signal: float) -> 'pd.Series[pd.Float64Dtype]':\n",
    "    fm = price.ewm(span=fast, adjust=False).mean()\n",
    "    sm = price.ewm(span=slow, adjust=False).mean()\n",
    "    md = fm - sm\n",
    "    signal = md - md.ewm(span=signal, adjust=False).mean()\n",
    "    return signal\n",
    "\n",
    "def generate_all_default_quantstats_features(data):\n",
    "    excluded_indicators = [\n",
    "        'compare',\n",
    "        'greeks',\n",
    "        'information_ratio',\n",
    "        'omega',\n",
    "        'r2',\n",
    "        'r_squared',\n",
    "        'rolling_greeks',\n",
    "        'warn',\n",
    "    ]\n",
    "    \n",
    "    indicators_list = [f for f in dir(qs.stats) if f[0] != '_' and f not in excluded_indicators]\n",
    "    \n",
    "    df = data.copy()\n",
    "    df = df.set_index('date')\n",
    "    df.index = pd.DatetimeIndex(df.index)\n",
    "\n",
    "    for indicator_name in indicators_list:\n",
    "        try:\n",
    "            #print(indicator_name)\n",
    "            indicator = qs.stats.__dict__[indicator_name](df['close'])\n",
    "            if isinstance(indicator, pd.Series):\n",
    "                indicator = indicator.to_frame(name=indicator_name)\n",
    "                df = pd.concat([df, indicator], axis='columns')\n",
    "        except (pd.errors.InvalidIndexError, ValueError):\n",
    "            pass\n",
    "\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "\n",
    "def generate_features(data):\n",
    "\n",
    "    # Generate all default indicators from ta library\n",
    "    ta1.add_all_ta_features(data, \n",
    "                            'open', \n",
    "                            'high', \n",
    "                            'low', \n",
    "                            'close', \n",
    "                            'volume', \n",
    "                            fillna=True)\n",
    "\n",
    "    # Naming convention across most technical indicator libraries\n",
    "    data = data.rename(columns={'open': 'Open', \n",
    "                                'high': 'High', \n",
    "                                'low': 'Low', \n",
    "                                'close': 'Close', \n",
    "                                'volume': 'Volume'})\n",
    "    data = data.set_index('date')\n",
    "\n",
    "    # Custom indicators\n",
    "    features = pd.DataFrame.from_dict({\n",
    "        'prev_open': data['Open'].shift(1),\n",
    "        'prev_high': data['High'].shift(1),\n",
    "        'prev_low': data['Low'].shift(1),\n",
    "        'prev_close': data['Close'].shift(1),\n",
    "        'prev_volume': data['Volume'].shift(1),\n",
    "        'vol_5': data['Close'].rolling(window=5).std().abs(),\n",
    "        'vol_10': data['Close'].rolling(window=10).std().abs(),\n",
    "        'vol_20': data['Close'].rolling(window=20).std().abs(),\n",
    "        'vol_30': data['Close'].rolling(window=30).std().abs(),\n",
    "        'vol_50': data['Close'].rolling(window=50).std().abs(),\n",
    "        'vol_60': data['Close'].rolling(window=60).std().abs(),\n",
    "        'vol_100': data['Close'].rolling(window=100).std().abs(),\n",
    "        'vol_200': data['Close'].rolling(window=200).std().abs(),\n",
    "        'ma_5': data['Close'].rolling(window=5).mean(),\n",
    "        'ma_10': data['Close'].rolling(window=10).mean(),\n",
    "        'ma_20': data['Close'].rolling(window=20).mean(),\n",
    "        'ma_30': data['Close'].rolling(window=30).mean(),\n",
    "        'ma_50': data['Close'].rolling(window=50).mean(),\n",
    "        'ma_60': data['Close'].rolling(window=60).mean(),\n",
    "        'ma_100': data['Close'].rolling(window=100).mean(),\n",
    "        'ma_200': data['Close'].rolling(window=200).mean(),\n",
    "        'ema_5': ta1.trend.ema_indicator(data['Close'], window=5, fillna=True),\n",
    "        'ema_9': ta1.trend.ema_indicator(data['Close'], window=9, fillna=True),\n",
    "        'ema_21': ta1.trend.ema_indicator(data['Close'], window=21, fillna=True),\n",
    "        'ema_60': ta1.trend.ema_indicator(data['Close'], window=60, fillna=True),\n",
    "        'ema_64': ta1.trend.ema_indicator(data['Close'], window=64, fillna=True),\n",
    "        'ema_120': ta1.trend.ema_indicator(data['Close'], window=120, fillna=True),\n",
    "        'lr_open': np.log(data['Open']).diff().fillna(0),\n",
    "        'lr_high': np.log(data['High']).diff().fillna(0),\n",
    "        'lr_low': np.log(data['Low']).diff().fillna(0),\n",
    "        'lr_close': np.log(data['Close']).diff().fillna(0),\n",
    "        'r_volume': data['Close'].diff().fillna(0),\n",
    "        'rsi_5': rsi(data['Close'], period=5),\n",
    "        'rsi_10': rsi(data['Close'], period=10),\n",
    "        'rsi_100': rsi(data['Close'], period=100),\n",
    "        'rsi_7': rsi(data['Close'], period=7),\n",
    "        'rsi_28': rsi(data['Close'], period=28),\n",
    "        'rsi_6': rsi(data['Close'], period=6),\n",
    "        'rsi_14': rsi(data['Close'], period=14),\n",
    "        'rsi_26': rsi(data['Close'], period=24),\n",
    "        'macd_normal': macd(data['Close'], fast=12, slow=26, signal=9),\n",
    "        'macd_short': macd(data['Close'], fast=10, slow=50, signal=5),\n",
    "        'macd_long': macd(data['Close'], fast=200, slow=100, signal=50),\n",
    "        'macd_wolfpack': macd(data['Close'], fast=3, slow=8, signal=9),\n",
    "    })\n",
    "\n",
    "    # Concatenate both manually and automatically generated features\n",
    "    data = pd.concat([data, features], axis='columns').fillna(method='pad')\n",
    "\n",
    "    # Remove potential column duplicates\n",
    "    data = data.loc[:,~data.columns.duplicated()]\n",
    "\n",
    "    # Revert naming convention\n",
    "    data = data.rename(columns={'Open': 'open', \n",
    "                                'High': 'high', \n",
    "                                'Low': 'low', \n",
    "                                'Close': 'close', \n",
    "                                'Volume': 'volume'})\n",
    "\n",
    "    data = data.reset_index()\n",
    "\n",
    "    # Generate all default quantstats features\n",
    "    df_quantstats = generate_all_default_quantstats_features(data)\n",
    "\n",
    "    # Concatenate both manually and automatically generated features\n",
    "    data = pd.concat([data, df_quantstats], axis='columns').fillna(method='pad')\n",
    "\n",
    "    # Remove potential column duplicates\n",
    "    data = data.loc[:,~data.columns.duplicated()]\n",
    "\n",
    "    # A lot of indicators generate NaNs at the beginning of DataFrames, so remove them\n",
    "    data = data.iloc[200:]\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    data = fix_dataset_inconsistencies_without_backfilling(data, fill_value=None)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70679eb9-03fc-4ef6-b81c-a64b6eb026db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/ta/trend.py:769: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[idx] = 100 * (self._dip[idx] / value)\n",
      "/home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/ta/trend.py:774: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[idx] = 100 * (self._din[idx] / value)\n",
      "/home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/ta/trend.py:938: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  self._psar_up = pd.Series(index=self._psar.index)\n",
      "/home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/ta/trend.py:939: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  self._psar_down = pd.Series(index=self._psar.index)\n",
      "/home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:57: RuntimeWarning: overflow encountered in accumulate\n",
      "  return bound(*args, **kwds)\n",
      "/home/alexandrustefan/Projects/rl-algos/.venv/lib/python3.8/site-packages/quantstats/utils.py:68: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  return _pd.concat(dfs, 1, sort=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(34159, 140)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = generate_features(data)\n",
    "# remove not needed features\n",
    "to_drop = ['others_dlr', 'compsum']\n",
    "data = data.drop(columns=to_drop)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ec36a-138e-4e5a-b475-b060acabd207",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Remove features with low variance before splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "501c9dd8-4188-44e5-852d-2f0f0fb4a7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_obv</th>\n",
       "      <th>volume_cmf</th>\n",
       "      <th>volume_fi</th>\n",
       "      <th>...</th>\n",
       "      <th>rsi_26</th>\n",
       "      <th>macd_normal</th>\n",
       "      <th>macd_short</th>\n",
       "      <th>macd_long</th>\n",
       "      <th>macd_wolfpack</th>\n",
       "      <th>pct_rank</th>\n",
       "      <th>rolling_sharpe</th>\n",
       "      <th>rolling_sortino</th>\n",
       "      <th>rolling_volatility</th>\n",
       "      <th>to_drawdown_series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-23 02:00 PM</td>\n",
       "      <td>7897.300000</td>\n",
       "      <td>7898.800000</td>\n",
       "      <td>7849.80000</td>\n",
       "      <td>7877.400000</td>\n",
       "      <td>9341499</td>\n",
       "      <td>-1.219515e+08</td>\n",
       "      <td>-153103304</td>\n",
       "      <td>-0.175983</td>\n",
       "      <td>-1.548039e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>65.542059</td>\n",
       "      <td>11.190548</td>\n",
       "      <td>10.871904</td>\n",
       "      <td>31.873058</td>\n",
       "      <td>19.596642</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-0.811487</td>\n",
       "      <td>-1.144302</td>\n",
       "      <td>0.072620</td>\n",
       "      <td>-0.103251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-23 03:00 PM</td>\n",
       "      <td>7877.400000</td>\n",
       "      <td>7889.700000</td>\n",
       "      <td>7661.00000</td>\n",
       "      <td>7700.000000</td>\n",
       "      <td>23679375</td>\n",
       "      <td>-1.375548e+08</td>\n",
       "      <td>-176782679</td>\n",
       "      <td>-0.228723</td>\n",
       "      <td>-7.327921e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>72.698849</td>\n",
       "      <td>1.333779</td>\n",
       "      <td>-5.426751</td>\n",
       "      <td>34.355233</td>\n",
       "      <td>-24.639480</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-1.248391</td>\n",
       "      <td>-1.633909</td>\n",
       "      <td>0.079103</td>\n",
       "      <td>-0.123446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-23 04:00 PM</td>\n",
       "      <td>7700.000000</td>\n",
       "      <td>7700.100000</td>\n",
       "      <td>7548.10000</td>\n",
       "      <td>7605.400000</td>\n",
       "      <td>42144843</td>\n",
       "      <td>-1.479246e+08</td>\n",
       "      <td>-218927522</td>\n",
       "      <td>-0.216859</td>\n",
       "      <td>-1.197665e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>75.527202</td>\n",
       "      <td>-10.060459</td>\n",
       "      <td>-21.497215</td>\n",
       "      <td>37.504922</td>\n",
       "      <td>-51.837145</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-1.612964</td>\n",
       "      <td>-2.069373</td>\n",
       "      <td>0.080681</td>\n",
       "      <td>-0.134215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-23 05:00 PM</td>\n",
       "      <td>7605.400000</td>\n",
       "      <td>7623.600000</td>\n",
       "      <td>7441.80000</td>\n",
       "      <td>7511.100000</td>\n",
       "      <td>38711817</td>\n",
       "      <td>-1.571235e+08</td>\n",
       "      <td>-257639339</td>\n",
       "      <td>-0.221424</td>\n",
       "      <td>-1.548073e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>77.907846</td>\n",
       "      <td>-21.778972</td>\n",
       "      <td>-36.146245</td>\n",
       "      <td>41.269618</td>\n",
       "      <td>-66.773623</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-1.797159</td>\n",
       "      <td>-2.272346</td>\n",
       "      <td>0.082309</td>\n",
       "      <td>-0.144950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-23 06:00 PM</td>\n",
       "      <td>7511.100000</td>\n",
       "      <td>7551.600000</td>\n",
       "      <td>7403.00000</td>\n",
       "      <td>7489.100000</td>\n",
       "      <td>23046091</td>\n",
       "      <td>-1.534634e+08</td>\n",
       "      <td>-280685430</td>\n",
       "      <td>-0.149460</td>\n",
       "      <td>-1.399351e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>78.418914</td>\n",
       "      <td>-28.422775</td>\n",
       "      <td>-41.976877</td>\n",
       "      <td>44.917996</td>\n",
       "      <td>-57.191729</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-1.879146</td>\n",
       "      <td>-2.372706</td>\n",
       "      <td>0.082361</td>\n",
       "      <td>-0.147455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34154</th>\n",
       "      <td>2022-04-17 09:00 PM</td>\n",
       "      <td>40279.000000</td>\n",
       "      <td>40310.948566</td>\n",
       "      <td>40152.00000</td>\n",
       "      <td>40227.829085</td>\n",
       "      <td>2411100</td>\n",
       "      <td>1.034904e+10</td>\n",
       "      <td>-4091153067</td>\n",
       "      <td>0.069567</td>\n",
       "      <td>-2.279012e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>53.472527</td>\n",
       "      <td>-15.399788</td>\n",
       "      <td>-12.766689</td>\n",
       "      <td>-94.423742</td>\n",
       "      <td>-0.511128</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-1.143253</td>\n",
       "      <td>-1.301348</td>\n",
       "      <td>0.102899</td>\n",
       "      <td>-0.413597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34155</th>\n",
       "      <td>2022-04-17 10:00 PM</td>\n",
       "      <td>40215.000000</td>\n",
       "      <td>40363.000000</td>\n",
       "      <td>39957.00000</td>\n",
       "      <td>40016.000000</td>\n",
       "      <td>8236277</td>\n",
       "      <td>1.034319e+10</td>\n",
       "      <td>-4099389344</td>\n",
       "      <td>-0.012154</td>\n",
       "      <td>-2.511939e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>57.736870</td>\n",
       "      <td>-28.816185</td>\n",
       "      <td>-32.828145</td>\n",
       "      <td>-92.752200</td>\n",
       "      <td>-48.891523</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-1.258480</td>\n",
       "      <td>-1.430544</td>\n",
       "      <td>0.103106</td>\n",
       "      <td>-0.416685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34156</th>\n",
       "      <td>2022-04-17 11:00 PM</td>\n",
       "      <td>40021.000000</td>\n",
       "      <td>40021.000000</td>\n",
       "      <td>39563.00000</td>\n",
       "      <td>39707.552712</td>\n",
       "      <td>10678099</td>\n",
       "      <td>1.033926e+10</td>\n",
       "      <td>-4110067443</td>\n",
       "      <td>-0.088576</td>\n",
       "      <td>-6.858277e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>62.902948</td>\n",
       "      <td>-55.180302</td>\n",
       "      <td>-69.739910</td>\n",
       "      <td>-88.328100</td>\n",
       "      <td>-118.618577</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-1.563211</td>\n",
       "      <td>-1.760876</td>\n",
       "      <td>0.102909</td>\n",
       "      <td>-0.421181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34157</th>\n",
       "      <td>2022-04-18 12:00 AM</td>\n",
       "      <td>39699.719303</td>\n",
       "      <td>39796.000000</td>\n",
       "      <td>39602.00000</td>\n",
       "      <td>39745.389366</td>\n",
       "      <td>5425275</td>\n",
       "      <td>1.034185e+10</td>\n",
       "      <td>-4104642168</td>\n",
       "      <td>-0.040761</td>\n",
       "      <td>-5.585274e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>61.933905</td>\n",
       "      <td>-66.052950</td>\n",
       "      <td>-79.588620</td>\n",
       "      <td>-84.620542</td>\n",
       "      <td>-100.678703</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>-1.547567</td>\n",
       "      <td>-1.743567</td>\n",
       "      <td>0.102928</td>\n",
       "      <td>-0.420630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34158</th>\n",
       "      <td>2022-04-18 01:00 AM</td>\n",
       "      <td>39744.000000</td>\n",
       "      <td>39851.641499</td>\n",
       "      <td>39731.22461</td>\n",
       "      <td>39796.573934</td>\n",
       "      <td>983800</td>\n",
       "      <td>1.034193e+10</td>\n",
       "      <td>-4103658368</td>\n",
       "      <td>-0.046215</td>\n",
       "      <td>-4.715442e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>60.615748</td>\n",
       "      <td>-65.643501</td>\n",
       "      <td>-73.047388</td>\n",
       "      <td>-81.711769</td>\n",
       "      <td>-54.048473</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-1.570202</td>\n",
       "      <td>-1.768130</td>\n",
       "      <td>0.102873</td>\n",
       "      <td>-0.419883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34159 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date          open          high          low  \\\n",
       "0      2018-05-23 02:00 PM   7897.300000   7898.800000   7849.80000   \n",
       "1      2018-05-23 03:00 PM   7877.400000   7889.700000   7661.00000   \n",
       "2      2018-05-23 04:00 PM   7700.000000   7700.100000   7548.10000   \n",
       "3      2018-05-23 05:00 PM   7605.400000   7623.600000   7441.80000   \n",
       "4      2018-05-23 06:00 PM   7511.100000   7551.600000   7403.00000   \n",
       "...                    ...           ...           ...          ...   \n",
       "34154  2022-04-17 09:00 PM  40279.000000  40310.948566  40152.00000   \n",
       "34155  2022-04-17 10:00 PM  40215.000000  40363.000000  39957.00000   \n",
       "34156  2022-04-17 11:00 PM  40021.000000  40021.000000  39563.00000   \n",
       "34157  2022-04-18 12:00 AM  39699.719303  39796.000000  39602.00000   \n",
       "34158  2022-04-18 01:00 AM  39744.000000  39851.641499  39731.22461   \n",
       "\n",
       "              close    volume    volume_adi  volume_obv  volume_cmf  \\\n",
       "0       7877.400000   9341499 -1.219515e+08  -153103304   -0.175983   \n",
       "1       7700.000000  23679375 -1.375548e+08  -176782679   -0.228723   \n",
       "2       7605.400000  42144843 -1.479246e+08  -218927522   -0.216859   \n",
       "3       7511.100000  38711817 -1.571235e+08  -257639339   -0.221424   \n",
       "4       7489.100000  23046091 -1.534634e+08  -280685430   -0.149460   \n",
       "...             ...       ...           ...         ...         ...   \n",
       "34154  40227.829085   2411100  1.034904e+10 -4091153067    0.069567   \n",
       "34155  40016.000000   8236277  1.034319e+10 -4099389344   -0.012154   \n",
       "34156  39707.552712  10678099  1.033926e+10 -4110067443   -0.088576   \n",
       "34157  39745.389366   5425275  1.034185e+10 -4104642168   -0.040761   \n",
       "34158  39796.573934    983800  1.034193e+10 -4103658368   -0.046215   \n",
       "\n",
       "          volume_fi  ...     rsi_26  macd_normal  macd_short  macd_long  \\\n",
       "0     -1.548039e+08  ...  65.542059    11.190548   10.871904  31.873058   \n",
       "1     -7.327921e+08  ...  72.698849     1.333779   -5.426751  34.355233   \n",
       "2     -1.197665e+09  ...  75.527202   -10.060459  -21.497215  37.504922   \n",
       "3     -1.548073e+09  ...  77.907846   -21.778972  -36.146245  41.269618   \n",
       "4     -1.399351e+09  ...  78.418914   -28.422775  -41.976877  44.917996   \n",
       "...             ...  ...        ...          ...         ...        ...   \n",
       "34154 -2.279012e+06  ...  53.472527   -15.399788  -12.766689 -94.423742   \n",
       "34155 -2.511939e+08  ...  57.736870   -28.816185  -32.828145 -92.752200   \n",
       "34156 -6.858277e+08  ...  62.902948   -55.180302  -69.739910 -88.328100   \n",
       "34157 -5.585274e+08  ...  61.933905   -66.052950  -79.588620 -84.620542   \n",
       "34158 -4.715442e+08  ...  60.615748   -65.643501  -73.047388 -81.711769   \n",
       "\n",
       "       macd_wolfpack   pct_rank  rolling_sharpe  rolling_sortino  \\\n",
       "0          19.596642  10.000000       -0.811487        -1.144302   \n",
       "1         -24.639480   1.666667       -1.248391        -1.633909   \n",
       "2         -51.837145   1.666667       -1.612964        -2.069373   \n",
       "3         -66.773623   1.666667       -1.797159        -2.272346   \n",
       "4         -57.191729   1.666667       -1.879146        -2.372706   \n",
       "...              ...        ...             ...              ...   \n",
       "34154      -0.511128  15.000000       -1.143253        -1.301348   \n",
       "34155     -48.891523   1.666667       -1.258480        -1.430544   \n",
       "34156    -118.618577   1.666667       -1.563211        -1.760876   \n",
       "34157    -100.678703   3.333333       -1.547567        -1.743567   \n",
       "34158     -54.048473   5.000000       -1.570202        -1.768130   \n",
       "\n",
       "       rolling_volatility  to_drawdown_series  \n",
       "0                0.072620           -0.103251  \n",
       "1                0.079103           -0.123446  \n",
       "2                0.080681           -0.134215  \n",
       "3                0.082309           -0.144950  \n",
       "4                0.082361           -0.147455  \n",
       "...                   ...                 ...  \n",
       "34154            0.102899           -0.413597  \n",
       "34155            0.103106           -0.416685  \n",
       "34156            0.102909           -0.421181  \n",
       "34157            0.102928           -0.420630  \n",
       "34158            0.102873           -0.419883  \n",
       "\n",
       "[34159 rows x 140 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "date = data[['date']].copy()\n",
    "data = data.drop(columns=['date'])\n",
    "sel.fit(data)\n",
    "data[data.columns[sel.get_support(indices=True)]]\n",
    "data = pd.concat([date, data], axis='columns')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ef6f85-8116-4be7-821d-6f5b897ade5b",
   "metadata": {
    "id": "f6ef6f85-8116-4be7-821d-6f5b897ade5b"
   },
   "source": [
    "# Setup which data to use for training and which data to use for evaluation of RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d15ac6-4546-4a5d-bf7d-c117cb231f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(data):\n",
    "    X = data.copy()\n",
    "    y = X['close'].pct_change()\n",
    "\n",
    "    X_train_test, X_valid, y_train_test, y_valid = \\\n",
    "        train_test_split(data, data['close'].pct_change(), train_size=0.67, test_size=0.33, shuffle=False)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X_train_test, y_train_test, train_size=0.50, test_size=0.50, shuffle=False)\n",
    "\n",
    "    return X_train, X_test, X_valid, y_train, y_test, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18402c18-25ef-48ea-85e3-0d7178971e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_valid, y_train, y_test, y_valid = \\\n",
    "    split_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dddb3e-cc23-40a2-bdb5-a5da6b735f62",
   "metadata": {},
   "source": [
    "## Implement basic feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94b3f1ae-dbb1-4672-b034-fe454ff8874a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectBySingleFeaturePerformance(cv=5,\n",
       "                                 estimator=RandomForestClassifier(n_jobs=-1,\n",
       "                                                                  random_state=1990),\n",
       "                                 threshold=0.65)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from feature_engine.selection import SelectBySingleFeaturePerformance\n",
    "\n",
    "from scipy.stats import iqr\n",
    "\n",
    "\n",
    "def estimate_outliers(data):\n",
    "    return iqr(data) * 1.5\n",
    "\n",
    "def estimate_percent_gains(data, column='close'):\n",
    "    returns = get_returns(data, column=column)\n",
    "    gains = estimate_outliers(returns)\n",
    "    return gains\n",
    "\n",
    "def get_returns(data, column='close'):\n",
    "    return fix_dataset_inconsistencies(data[[column]].pct_change(), fill_value=0)\n",
    "\n",
    "def precalculate_ground_truths(data, column='close', threshold=None):\n",
    "    returns = get_returns(data, column=column)\n",
    "    gains = estimate_outliers(returns) if threshold is None else threshold\n",
    "    binary_gains = (returns[column] > gains).astype(int)\n",
    "    return binary_gains\n",
    "\n",
    "def is_null(data):\n",
    "    return data.isnull().sum().sum() > 0\n",
    "\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, \n",
    "                            random_state=1990, \n",
    "                            n_jobs=-1)\n",
    "\n",
    "sel = SelectBySingleFeaturePerformance(variables=None, \n",
    "                                       estimator=rf, \n",
    "                                       scoring=\"roc_auc\", \n",
    "                                       cv=5, \n",
    "                                       threshold=0.65)\n",
    "\n",
    "sel.fit(X_train, precalculate_ground_truths(X_train, column='close'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce149438-26b4-4351-a55f-2b307d122956",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_performance = pd.Series(sel.feature_performance_).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73845b81-1151-4aa0-b372-4901188d9faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# feature_performance.plot.bar(figsize=(40, 10))\n",
    "# plt.title('Performance of ML models trained with individual features')\n",
    "# plt.ylabel('roc-auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "228b820b-f0bf-4288-84e5-6db66c7c8647",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_drop = sel.features_to_drop_\n",
    "to_drop = list(set(features_to_drop) - set(['open', 'high', 'low', 'close', 'volume']))\n",
    "len(to_drop)\n",
    "# features_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49a0a65e-b758-470d-a06e-35fd085b188c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11443, 16), (11443, 16), (11273, 16))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.drop(columns=to_drop)\n",
    "X_test = X_test.drop(columns=to_drop)\n",
    "X_valid = X_valid.drop(columns=to_drop)\n",
    "\n",
    "X_train.shape, X_test.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc593487-0e67-4940-9d06-8f84064470a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'open',\n",
       " 'high',\n",
       " 'low',\n",
       " 'close',\n",
       " 'volume',\n",
       " 'volume_em',\n",
       " 'volume_vpt',\n",
       " 'volatility_kchi',\n",
       " 'trend_aroon_up',\n",
       " 'momentum_stoch_rsi',\n",
       " 'others_dr',\n",
       " 'lr_high',\n",
       " 'lr_close',\n",
       " 'r_volume',\n",
       " 'macd_wolfpack']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6bfb53-d874-4dc9-9d29-abf27d42cff8",
   "metadata": {},
   "source": [
    "## Normalize the dataset subsets to make the model converge faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdef363e-b5ae-49f6-9acf-6a553fdbbcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "\n",
    "scaler_type = MinMaxScaler\n",
    "\n",
    "def get_feature_scalers(X, scaler_type=scaler_type):\n",
    "    scalers = []\n",
    "    for name in list(X.columns[X.columns != 'date']):\n",
    "        scalers.append(scaler_type().fit(X[name].values.reshape(-1, 1)))\n",
    "    return scalers\n",
    "\n",
    "def get_scaler_transforms(X, scalers):\n",
    "    X_scaled = []\n",
    "    for name, scaler in zip(list(X.columns[X.columns != 'date']), scalers):\n",
    "        X_scaled.append(scaler.transform(X[name].values.reshape(-1, 1)))\n",
    "    X_scaled = pd.concat([pd.DataFrame(column, columns=[name]) for name, column in \\\n",
    "                          zip(list(X.columns[X.columns != 'date']), X_scaled)], axis='columns')\n",
    "    return X_scaled\n",
    "\n",
    "def scale_numpy_array(np_arr, scaler_type = scaler_type):\n",
    "    return scaler_type().fit_transform(np_arr, (-1,1))\n",
    "\n",
    "def normalize_data(X_train, X_test, X_valid):\n",
    "    X_train_test = pd.concat([X_train, X_test], axis='index')\n",
    "    X_train_test_valid = pd.concat([X_train_test, X_valid], axis='index')\n",
    "\n",
    "    X_train_test_dates = X_train_test[['date']]\n",
    "    X_train_test_valid_dates = X_train_test_valid[['date']]\n",
    "\n",
    "    X_train_test = X_train_test.drop(columns=['date'])\n",
    "    X_train_test_valid = X_train_test_valid.drop(columns=['date'])\n",
    "\n",
    "    train_test_scalers = \\\n",
    "        get_feature_scalers(X_train_test, \n",
    "                            scaler_type=scaler_type)\n",
    "    train_test_valid_scalers = \\\n",
    "        get_feature_scalers(X_train_test_valid, \n",
    "                            scaler_type=scaler_type)\n",
    "\n",
    "    X_train_test_scaled = \\\n",
    "        get_scaler_transforms(X_train_test, \n",
    "                              train_test_scalers)\n",
    "    X_train_test_valid_scaled = \\\n",
    "        get_scaler_transforms(X_train_test_valid, \n",
    "                              train_test_scalers)\n",
    "    X_train_test_valid_scaled_leaking = \\\n",
    "        get_scaler_transforms(X_train_test_valid, \n",
    "                              train_test_valid_scalers)\n",
    "\n",
    "    X_train_test_scaled = \\\n",
    "        pd.concat([X_train_test_dates, \n",
    "                   X_train_test_scaled], \n",
    "                  axis='columns')\n",
    "    X_train_test_valid_scaled = \\\n",
    "        pd.concat([X_train_test_valid_dates, \n",
    "                   X_train_test_valid_scaled], \n",
    "                  axis='columns')\n",
    "    X_train_test_valid_scaled_leaking = \\\n",
    "        pd.concat([X_train_test_valid_dates, \n",
    "                   X_train_test_valid_scaled_leaking], \n",
    "                  axis='columns')\n",
    "\n",
    "    X_train_scaled = X_train_test_scaled.iloc[:X_train.shape[0]]\n",
    "    X_test_scaled = X_train_test_scaled.iloc[X_train.shape[0]:]\n",
    "    X_valid_scaled = X_train_test_valid_scaled.iloc[X_train_test.shape[0]:]\n",
    "    X_valid_scaled_leaking = X_train_test_valid_scaled_leaking.iloc[X_train_test.shape[0]:]\n",
    "\n",
    "    return (train_test_scalers, \n",
    "            train_test_valid_scalers, \n",
    "            X_train_scaled, \n",
    "            X_test_scaled, \n",
    "            X_valid_scaled, \n",
    "            X_valid_scaled_leaking)\n",
    "\n",
    "train_test_scalers, train_test_valid_scalers, X_train_scaled, X_test_scaled, X_valid_scaled, X_valid_scaled_leaking = \\\n",
    "    normalize_data(X_train, X_test, X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926eccb5",
   "metadata": {},
   "source": [
    "### Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cced7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "\n",
    "\n",
    "train_csv = os.path.join(cwd, 'train.csv')\n",
    "test_csv = os.path.join(cwd, 'test.csv')\n",
    "valid_csv = os.path.join(cwd, 'valid.csv')\n",
    "train_scaled_csv = os.path.join(cwd, 'train_scaled.csv')\n",
    "test_scaled_csv = os.path.join(cwd, 'test_scaled.csv')\n",
    "valid_scaled_csv = os.path.join(cwd, 'valid_scaled.csv')\n",
    "valid_scaled_leaking_csv = os.path.join(cwd, 'valid_scaled_leaking.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aee2204c-640c-4f7e-b082-1392f48c585a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env.ipynb#ch0000023vscode-remote?line=13'>14</a>\u001b[0m valid_scaled_leaking_csv \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(cwd, \u001b[39m'\u001b[39m\u001b[39mvalid_scaled_leaking.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env.ipynb#ch0000023vscode-remote?line=15'>16</a>\u001b[0m \u001b[39m# X_train.to_csv(train_csv, index=False)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env.ipynb#ch0000023vscode-remote?line=16'>17</a>\u001b[0m \u001b[39m# X_test.to_csv(test_csv, index=False)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env.ipynb#ch0000023vscode-remote?line=17'>18</a>\u001b[0m \u001b[39m# X_valid.to_csv(valid_csv, index=False)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env.ipynb#ch0000023vscode-remote?line=20'>21</a>\u001b[0m \u001b[39m# X_valid.to_csv(valid_scaled_csv, index=False)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env.ipynb#ch0000023vscode-remote?line=21'>22</a>\u001b[0m \u001b[39m# X_valid.to_csv(valid_scaled_leaking_csv, index=False)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env.ipynb#ch0000023vscode-remote?line=23'>24</a>\u001b[0m X_train\u001b[39m.\u001b[39mfrom_csv(train_csv, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train.to_csv(train_csv, index=False)\n",
    "X_test.to_csv(test_csv, index=False)\n",
    "X_valid.to_csv(valid_csv, index=False)\n",
    "X_train.to_csv(train_scaled_csv, index=False)\n",
    "X_test.to_csv(test_scaled_csv, index=False)\n",
    "X_valid.to_csv(valid_scaled_csv, index=False)\n",
    "X_valid.to_csv(valid_scaled_leaking_csv, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09d22ef",
   "metadata": {},
   "source": [
    "### Load from CSV if data previously saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e43009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = pd.read_csv(train_csv)\n",
    "X_test = pd.read_csv(test_csv)\n",
    "X_valid = pd.read_csv(valid_csv)\n",
    "X_train_scaled = pd.read_csv(train_scaled_csv)\n",
    "X_test_scaled = pd.read_csv(test_scaled_csv)\n",
    "X_valid_scaled = pd.read_csv(valid_scaled_csv)\n",
    "X_valid_scaled_leaking = pd.read_csv(valid_scaled_leaking_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77071777-9faf-4f19-9f3e-06d52d4805d5",
   "metadata": {
    "id": "77071777-9faf-4f19-9f3e-06d52d4805d5"
   },
   "source": [
    "# Defining the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e14536-e09b-4a1e-b478-9d2c32fc67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "from gym import spaces\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# infinite number in python\n",
    "MAX_NET_WORTH = 2147483647\n",
    "MAX_NUM_QUOTE_OR_BASE_ASSET = 2147483647\n",
    "\n",
    "INITIAL_QUOTE_ASSET = 10000\n",
    "INITIAL_BASE_ASSET = 0\n",
    "OBSERVATION_WINDOW_SIZE = 24 # Probably we should put it as param ?\n",
    "\n",
    "class SimpleTradingEnv(gym.Env):\n",
    "    \n",
    "    metadata = {'render.modes': ['live', 'human', 'none']}\n",
    "    visualization = None\n",
    "\n",
    "    def __init__(self, df_scaled, df_normal, trading_fee):\n",
    "        \n",
    "        self.df_scaled = df_scaled.reset_index(drop=True)\n",
    "        self.df_normal = df_normal.reset_index(drop=True)\n",
    "        self.window_size = OBSERVATION_WINDOW_SIZE\n",
    "        self.prices, self.features = self._process_data(df_scaled)\n",
    "        # The shape of the observation is (window_size * features + environment_features) the environment_features are: quote_asset, base_asset, net_worth. The entire observation is flattened in a 1D np array. \n",
    "        # NOT USED ANYMORE, KEPT FOR REFERENCE\n",
    "        # self.obs_shape = ((OBSERVATION_WINDOW_SIZE * self.features.shape[1] + 3),) \n",
    "\n",
    "        # The shape of the observation is number of candles to look back, and the number of features (candle_features) + 3 (quote_asset, base_asset, net_worth)\n",
    "        self.obs_shape = (OBSERVATION_WINDOW_SIZE, self.features.shape[1] + 3)\n",
    "\n",
    "        # Action space\n",
    "        #self.action_space = spaces.Box(low=np.array([0, 0]), high=np.array([3.0, 1.0]), dtype=np.float32)\n",
    "        self.action_space = spaces.MultiDiscrete([3, 100])\n",
    "        # Observation space\n",
    "        self.observation_space = spaces.Box(low=-1, high=1, shape=self.obs_shape, dtype=np.float32)\n",
    "\n",
    "        # Initialize the episode environment\n",
    "\n",
    "        self._start_candle = OBSERVATION_WINDOW_SIZE # We assume that the first observation is not the first row of the dataframe, in order to avoid the case where there are no calculated indicators.\n",
    "        self._end_candle = len(self.features) - 1\n",
    "        self._trading_fee = trading_fee\n",
    "\n",
    "        self._quote_asset = None\n",
    "        self._base_asset = None\n",
    "        self._done = None\n",
    "        self._current_candle = None\n",
    "        self._net_worth = None\n",
    "        self._previous_net_worth = None\n",
    "\n",
    "        # Array that will contain observation history needed for appending it to the observation space\n",
    "        # It will contain observations consisting of the net_worth, base_asset and quote_asset as list of floats\n",
    "        # Other features (OHLC + Indicators) will be appended to the current observation in the _get_observation method that takes the data directly from the available dataframe\n",
    "        self._obs_env_history = None\n",
    "\n",
    "        # Render and analysis data\n",
    "        self._total_reward_accumulated = None\n",
    "        self.trade_history = None\n",
    "        self._first_rendering = None\n",
    "        \n",
    "\n",
    "    def reset(self):\n",
    "        self._done = False\n",
    "        self._current_candle = self._start_candle\n",
    "        self._quote_asset = INITIAL_QUOTE_ASSET\n",
    "        self._base_asset = INITIAL_BASE_ASSET \n",
    "        self._net_worth = INITIAL_QUOTE_ASSET # at the begining our net worth is the initial quote asset\n",
    "        self._previous_net_worth = INITIAL_QUOTE_ASSET # at the begining our previous net worth is the initial quote asset\n",
    "        self._total_reward_accumulated = 0.\n",
    "        self._first_rendering = True\n",
    "        self.trade_history = []\n",
    "        self._obs_env_history = []\n",
    "        \n",
    "        self._initial_obs_data()\n",
    "\n",
    "        return self._get_observation()\n",
    "\n",
    "    def _take_action(self, action):\n",
    "        self._done = False\n",
    "        current_price = random.uniform(\n",
    "            self.df_normal.loc[self._current_candle, \"low\"], self.df_normal.loc[self._current_candle, \"high\"])\n",
    "\n",
    "\n",
    "        action_type = action[0]\n",
    "        amount = action[1] / 100\n",
    "        \n",
    "        if action_type == 0: # Buy\n",
    "            # Buy % assets\n",
    "            # Determine the maximum amount of quote asset that can be bought\n",
    "            available_amount_to_buy_with = self._quote_asset / current_price\n",
    "            # Buy only the amount that agent chose\n",
    "            assets_bought = available_amount_to_buy_with * amount\n",
    "            # Update the quote asset balance\n",
    "            self._quote_asset -= assets_bought * current_price\n",
    "            # Update the base asset\n",
    "            self._base_asset += assets_bought\n",
    "            # substract trading fee from base asset based on the amount bought\n",
    "            self._base_asset -= self._trading_fee * assets_bought\n",
    "\n",
    "            # Add to trade history the amount bought if greater than 0\n",
    "            if assets_bought > 0:\n",
    "                self.trade_history.append({'step': self._current_candle, 'type': 'Buy', 'amount': assets_bought, 'price': current_price, 'total' : assets_bought * current_price, 'percent_amount': action[1]})\n",
    "        \n",
    "\n",
    "        elif action_type == 1: # Sell\n",
    "            # Sell % assets\n",
    "            # Determine the amount of base asset that can be sold\n",
    "            amount_to_sell = self._base_asset * amount\n",
    "            received_quote_asset = amount_to_sell * current_price\n",
    "            # Update the quote asset\n",
    "            self._quote_asset += received_quote_asset\n",
    "            # Update the base asset\n",
    "            self._base_asset -= amount_to_sell\n",
    "            \n",
    "            # substract trading fee from quote asset based on the amount sold\n",
    "            self._quote_asset -= self._trading_fee * received_quote_asset\n",
    "\n",
    "            # Add to trade history the amount sold if greater than 0\n",
    "            if amount_to_sell > 0:\n",
    "                self.trade_history.append({'step': self._current_candle, 'type': 'Sell', 'amount': amount_to_sell, 'price': current_price, 'total' : received_quote_asset, 'percent_amount': action[1]})\n",
    "\n",
    "        else:\n",
    "            # Hold\n",
    "            self.trade_history.append({'step': self._current_candle, 'type': 'Hold', 'amount': '0', 'price': current_price, 'total' : 0, 'percent_amount': action[1]})\n",
    "\n",
    "\n",
    "        # Update the current net worth\n",
    "        self._net_worth = self._base_asset * current_price + self._quote_asset\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Returns the next observation, reward, done and info.\n",
    "        \"\"\"\n",
    "        \n",
    "        self._take_action(action)\n",
    "\n",
    "        # Calculate reward comparing the current net worth with the previous net worth\n",
    "        reward = self._net_worth - self._previous_net_worth\n",
    "\n",
    "        self._total_reward_accumulated += reward\n",
    "\n",
    "        # Update the previous net worth to be the current net worth after the reward has been applied\n",
    "        self._previous_net_worth = self._net_worth\n",
    "\n",
    "        obs = self._get_observation()\n",
    "        # Update the info and add it to history data\n",
    "        info = dict (\n",
    "            total_reward_accumulated = self._total_reward_accumulated,\n",
    "            net_worth = self._net_worth,\n",
    "            last_action_type = self.trade_history[-1]['type'] if len(self.trade_history) > 0 else None,\n",
    "            last_action_amount = self.trade_history[-1]['amount'] if len(self.trade_history) > 0 else None,\n",
    "            current_step = self._current_candle\n",
    "        )\n",
    "\n",
    "        self._current_candle += 1\n",
    "\n",
    "        # Update observation history\n",
    "        self._obs_env_history.append([self._net_worth, self._base_asset, self._quote_asset])\n",
    "\n",
    "        self._done = self._net_worth <= 0 or self._current_candle >= len(\n",
    "            self.df_scaled.loc[:, 'open'].values)\n",
    "        \n",
    "        return obs, reward, self._done, info\n",
    "\n",
    "\n",
    "    def _get_observation(self):\n",
    "        \"\"\"\n",
    "        Returns the current observation.\n",
    "        \"\"\"\n",
    "        data_frame = self.features[(self._current_candle - self.window_size):self._current_candle]\n",
    "\n",
    "        obs_env_history = np.array(self._obs_env_history).astype(np.float32)\n",
    "\n",
    "        #TODO We definetely need to scale the observation history in a better way, this might influence training results\n",
    "        # Doing it ad-hoc might change the scale of the min and max, thus changing the results\n",
    "        obs_env_history = preprocessing.minmax_scale(obs_env_history, (-1,1)) \n",
    "\n",
    "        obs = np.hstack((data_frame, obs_env_history[(self._current_candle - self.window_size):self._current_candle]))\n",
    "\n",
    "\n",
    "        return obs\n",
    "\n",
    "\n",
    "    def render(self, mode='human', **kwargs):\n",
    "        \"\"\"\n",
    "        Renders a plot with trades made by the agent.\n",
    "        \"\"\"\n",
    "        \n",
    "        if mode == 'human':\n",
    "            print(f'Accumulated Reward: {self._total_reward_accumulated} ---- Current Net Worth: {self._net_worth}')\n",
    "            print(f'Current Quote asset: {self._quote_asset} ---- Current Base asset: {self._base_asset}')\n",
    "            print(f'Number of trades: {len(self.trade_history)}')\n",
    "        \n",
    "            if(len(self.trade_history) > 0):\n",
    "                print(f'Last Action: {self.trade_history[-1][\"type\"]} {self.trade_history[-1][\"amount\"]} assets ({self.trade_history[-1][\"percent_amount\"]} %) at price {self.trade_history[-1][\"price\"]}, total: {self.trade_history[-1][\"total\"]}')\n",
    "            print(f'--------------------------------------------------------------------------------------')\n",
    "        elif mode == 'live':\n",
    "            if self.visualization == None:\n",
    "                self.visualization = LiveTradingGraph(self.df_normal, kwargs.get('title', None))\n",
    "\n",
    "            if self._current_candle > OBSERVATION_WINDOW_SIZE:\n",
    "                self.visualization.render(self._current_candle, self._net_worth, self.trade_history, window_size=OBSERVATION_WINDOW_SIZE)\n",
    "\n",
    "    def close(self):\n",
    "        if self.visualization != None:\n",
    "            self.visualization.close()\n",
    "            self.visualization = None\n",
    "         \n",
    "\n",
    "    def _process_data(self, df_scaled):\n",
    "        \"\"\"\n",
    "        Processes the dataframe into features.\n",
    "        \"\"\"\n",
    "        \n",
    "        prices = self.df_scaled.loc[:, 'close'].to_numpy(dtype=np.float32)\n",
    "\n",
    "        data_frame = df_scaled.iloc[:, 1:] # drop first column which is date TODO: Should be probably fixed outside of this class\n",
    "        # Convert df to numpy array\n",
    "        return prices, data_frame.to_numpy(dtype=np.float32)\n",
    "\n",
    "    def _initial_obs_data(self):\n",
    "        for i in range(self.window_size - len(self._obs_env_history)):\n",
    "            self._obs_env_history.append([self._net_worth, self._base_asset, self._quote_asset])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b670e8a2",
   "metadata": {},
   "source": [
    "### Initialize, validate the environment and run a random test of x steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8fc3bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SimpleTradingEnv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env_stablebaselines.ipynb Cell 32'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env_stablebaselines.ipynb#ch0000031vscode-remote?line=10'>11</a>\u001b[0m n_envs \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env_stablebaselines.ipynb#ch0000031vscode-remote?line=11'>12</a>\u001b[0m trading_fee \u001b[39m=\u001b[39m \u001b[39m0.0075\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env_stablebaselines.ipynb#ch0000031vscode-remote?line=12'>13</a>\u001b[0m env \u001b[39m=\u001b[39m SimpleTradingEnv(X_train_scaled, X_train, trading_fee)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env_stablebaselines.ipynb#ch0000031vscode-remote?line=13'>14</a>\u001b[0m \u001b[39m#check_env(env) ### Already tested and working :)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/alexandrustefan/Projects/rl-algos/PPO_RL_simple_env_stablebaselines.ipynb#ch0000031vscode-remote?line=14'>15</a>\u001b[0m env \u001b[39m=\u001b[39m make_vec_env(\u001b[39mlambda\u001b[39;00m: env,vec_env_cls\u001b[39m=\u001b[39mSubprocVecEnv, n_envs\u001b[39m=\u001b[39mn_envs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SimpleTradingEnv' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.logger import configure\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv, VecFrameStack\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "n_envs = 8\n",
    "trading_fee = 0.0075\n",
    "env = SimpleTradingEnv(X_train_scaled, X_train, trading_fee)\n",
    "#check_env(env) ### Already tested and working :)\n",
    "env = make_vec_env(lambda: env,vec_env_cls=SubprocVecEnv, n_envs=n_envs)\n",
    "\n",
    "\n",
    "# obs = env.reset()\n",
    "# #Trying some random action sample\n",
    "# for i in range(5):\n",
    "#     # Take a random action\n",
    "#     actions = np.array([env.action_space.sample() for _ in range(env.num_envs)])\n",
    "#     print(actions)\n",
    "#     env.step_async(actions)\n",
    "#     obs, reward, done, info = env.step_wait()\n",
    "#     print(info)\n",
    "#     if done[0]:\n",
    "#         break\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219979f3",
   "metadata": {},
   "source": [
    "### Create an evaluation environment used to save only the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea018b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "# Separate evaluation env\n",
    "eval_env = SimpleTradingEnv(X_valid_scaled, X_valid, trading_fee)\n",
    "# check_env(eval_env) ### Already tested and working :)\n",
    "eval_env = make_vec_env(lambda: eval_env,vec_env_cls=SubprocVecEnv, n_envs=n_envs)\n",
    "# Use deterministic actions for evaluation\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path='model/PPO_best/',\n",
    "                             log_path='model/logs/', eval_freq=max(500000 // n_envs, 1),\n",
    "                             deterministic=False, render=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0adeedc",
   "metadata": {},
   "source": [
    "### Create a checkpoint callback to save the model periodically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f260298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(save_freq=max(500000 // n_envs, 1), save_path='model/PPO/',\n",
    "                                         name_prefix='rl_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c019b2b-943a-4889-927f-38b34e52ac67",
   "metadata": {},
   "source": [
    "# Initialize the model and start learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xEE0eNix7KSh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "xEE0eNix7KSh",
    "outputId": "16059380-7c2e-4b06-c4c6-ee28b0492ee8"
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import CallbackList\n",
    "\n",
    "cwd = os.getcwd()\n",
    "logdir = \"logs\"\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "\n",
    "\n",
    "callback_list = CallbackList([checkpoint_callback, eval_callback])\n",
    "\n",
    "number_of_epochs = 10000\n",
    "total_timesteps = len(X_train_scaled) * number_of_epochs\n",
    "\n",
    "model = PPO(MlpPolicy, env, verbose=1, tensorboard_log=logdir, device='cuda')\n",
    "\n",
    "model.learn(total_timesteps=total_timesteps, tb_log_name=\"PPO\", callback=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76622b8-b54e-4376-ad23-1d7e2f538b70",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bfdf445-13cb-4890-8524-209e8fca979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# Create a new non-vectorized environment to avoid multiprocessing while evaluating (easier to debug and to use)\n",
    "env_to_test_against = Monitor(SimpleTradingEnv(X_train_scaled, X_train, trading_fee))\n",
    "model_path = \"model/PPO_30M_Steps_Shaped_OBS/rl_model_29500000_steps.zip\"\n",
    "loaded_model = PPO.load(model_path, env=env_to_test_against)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1d1659-27b9-451a-b575-648a77db069b",
   "metadata": {},
   "source": [
    "# Run an evaluation test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ce9eb9e-a3d3-41ef-b615-6a23eb9db0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward:406.02 +/- 0.00\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(loaded_model, env_to_test_against, n_eval_episodes=1, deterministic=True)\n",
    "print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0e12541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83707a6-6586-4d43-a757-f4b249795735",
   "metadata": {},
   "source": [
    "# Render results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85483ff5-7229-493a-9150-87f583e8b504",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net worth at the end of the episode: 10014.231377474227\n",
      "Largest net worth: 11683.862639854251\n"
     ]
    }
   ],
   "source": [
    "steps = len(env_to_test_against.df_normal) - 30\n",
    "render_interval = steps // 10\n",
    "obs = env_to_test_against.reset()\n",
    "net_worths = []\n",
    "for i in range(steps):\n",
    "    action, _state = loaded_model.predict(obs, deterministic=True)\n",
    "    # if action[0][0] < 2 :\n",
    "    #     print(f\"Action: {action[0]}\")\n",
    "    # env_to_test_against.step_async(action)\n",
    "    # obs, reward, done, info =  env_to_test_against.step_wait()\n",
    "    obs, reward, done, info =  env_to_test_against.step(action)\n",
    "    # print('obs:', obs)\n",
    "    # print('action:', action)\n",
    "    # env_to_test_against.env_method('render')\n",
    "    # env_to_test_against.render()\n",
    "    if(info['net_worth'] > 10000):\n",
    "        net_worths.append(info['net_worth'])\n",
    "    if done:\n",
    "        env_to_test_against.reset()\n",
    "    # print('done:', done)\n",
    "    # print('info:', info)\n",
    "    # # if (i % render_interval) == 0:\n",
    "    # #     env_to_test_against.env_to_test_against_method('render')\n",
    "    # # if done:\n",
    "    # #     obs = env_to_test_against.env_to_test_against_method('reset')\n",
    "env_to_test_against.close()\n",
    "print(f\"Net worth at the end of the episode: {net_worths[-1]}\")\n",
    "net_worths.sort()\n",
    "print(f\"Largest net worth: {net_worths[-1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873d2376",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning using optuna\n",
    "### Heavily inspired from rl-baselines3-zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b23346b2-bbbc-4a96-9dfe-9c9c60440987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, Union\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from torch import nn as nn\n",
    "\n",
    "def linear_schedule(initial_value: Union[float, str]) -> Callable[[float], float]:\n",
    "    \"\"\"\n",
    "    Linear learning rate schedule.\n",
    "    :param initial_value: (float or str)\n",
    "    :return: (function)\n",
    "    \"\"\"\n",
    "    if isinstance(initial_value, str):\n",
    "        initial_value = float(initial_value)\n",
    "\n",
    "    def func(progress_remaining: float) -> float:\n",
    "        \"\"\"\n",
    "        Progress will decrease from 1 (beginning) to 0\n",
    "        :param progress_remaining: (float)\n",
    "        :return: (float)\n",
    "        \"\"\"\n",
    "        return progress_remaining * initial_value\n",
    "\n",
    "    return func\n",
    "\n",
    "\n",
    "def sample_ppo_params(trial: optuna.Trial, env: gym.Env) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Sampler for PPO hyperparams.\n",
    "    :param trial:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    env = Monitor(env)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 128, 256, 512])\n",
    "    n_steps = trial.suggest_categorical(\"n_steps\", [8, 16, 32, 64, 128, 256, 512, 1024, 2048])\n",
    "    gamma = trial.suggest_categorical(\"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999])\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
    "    lr_schedule = \"constant\"\n",
    "    # Uncomment to enable learning rate schedule\n",
    "    # lr_schedule = trial.suggest_categorical('lr_schedule', ['linear', 'constant'])\n",
    "    ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
    "    clip_range = trial.suggest_categorical(\"clip_range\", [0.1, 0.2, 0.3, 0.4])\n",
    "    n_epochs = trial.suggest_categorical(\"n_epochs\", [1, 5, 10, 20])\n",
    "    gae_lambda = trial.suggest_categorical(\"gae_lambda\", [0.8, 0.9, 0.92, 0.95, 0.98, 0.99, 1.0])\n",
    "    max_grad_norm = trial.suggest_categorical(\"max_grad_norm\", [0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 5])\n",
    "    vf_coef = trial.suggest_uniform(\"vf_coef\", 0, 1)\n",
    "    net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"medium\"])\n",
    "    # Uncomment for gSDE (continuous actions)\n",
    "    # log_std_init = trial.suggest_uniform(\"log_std_init\", -4, 1)\n",
    "    # Uncomment for gSDE (continuous action)\n",
    "    # sde_sample_freq = trial.suggest_categorical(\"sde_sample_freq\", [-1, 8, 16, 32, 64, 128, 256])\n",
    "    # Orthogonal initialization\n",
    "    ortho_init = False\n",
    "    # ortho_init = trial.suggest_categorical('ortho_init', [False, True])\n",
    "    # activation_fn = trial.suggest_categorical('activation_fn', ['tanh', 'relu', 'elu', 'leaky_relu'])\n",
    "    activation_fn = trial.suggest_categorical(\"activation_fn\", [\"tanh\", \"relu\"])\n",
    "\n",
    "    # TODO: account when using multiple envs\n",
    "    if batch_size > n_steps:\n",
    "        batch_size = n_steps\n",
    "\n",
    "    if lr_schedule == \"linear\":\n",
    "        learning_rate = linear_schedule(learning_rate)\n",
    "\n",
    "    # Independent networks usually work best\n",
    "    # when not working with images\n",
    "    net_arch = {\n",
    "        \"small\": [dict(pi=[64, 64], vf=[64, 64])],\n",
    "        \"medium\": [dict(pi=[256, 256], vf=[256, 256])],\n",
    "    }[net_arch]\n",
    "\n",
    "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU, \"elu\": nn.ELU, \"leaky_relu\": nn.LeakyReLU}[activation_fn]\n",
    "\n",
    "    return {\n",
    "        \"env\": env,\n",
    "        \"n_steps\": n_steps,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"gamma\": gamma,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"ent_coef\": ent_coef,\n",
    "        \"clip_range\": clip_range,\n",
    "        \"n_epochs\": n_epochs,\n",
    "        \"gae_lambda\": gae_lambda,\n",
    "        \"max_grad_norm\": max_grad_norm,\n",
    "        \"vf_coef\": vf_coef,\n",
    "        # \"sde_sample_freq\": sde_sample_freq,\n",
    "        \"policy_kwargs\": dict(\n",
    "            # log_std_init=log_std_init,\n",
    "            net_arch=net_arch,\n",
    "            activation_fn=activation_fn,\n",
    "            ortho_init=ortho_init,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "class TrialEvalCallback(EvalCallback):\n",
    "    \"\"\"Callback used for evaluating and reporting a trial.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_env: gym.Env,\n",
    "        trial: optuna.Trial,\n",
    "        n_eval_episodes: int = 5,\n",
    "        eval_freq: int = 10000,\n",
    "        deterministic: bool = True,\n",
    "        verbose: int = 0,\n",
    "    ):\n",
    "\n",
    "        super().__init__(\n",
    "            eval_env=eval_env,\n",
    "            n_eval_episodes=n_eval_episodes,\n",
    "            eval_freq=eval_freq,\n",
    "            deterministic=deterministic,\n",
    "            verbose=verbose,\n",
    "        )\n",
    "        self.trial = trial\n",
    "        self.eval_idx = 0\n",
    "        self.is_pruned = False\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
    "            super()._on_step()\n",
    "            self.eval_idx += 1\n",
    "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
    "            # Prune trial if need\n",
    "            if self.trial.should_prune():\n",
    "                self.is_pruned = True\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c1f059",
   "metadata": {},
   "source": [
    "### Initialize the PPO algorithm and environment together with optuna objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04cf34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration.tensorboard import TensorBoardCallback\n",
    "\n",
    "\n",
    "N_TRIALS = 100\n",
    "N_JOBS = 2\n",
    "N_STARTUP_TRIALS = 5\n",
    "N_EVALUATIONS = 2\n",
    "N_TIMESTEPS = int(2e4)\n",
    "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
    "N_EVAL_EPISODES = 3\n",
    "\n",
    "ENV_ID = \"CartPole-v1\"\n",
    "\n",
    "DEFAULT_HYPERPARAMS = {\n",
    "    \"policy\": \"MlpPolicy\",\n",
    "    \"tensorboard_log\": \"logs/optuna/\", \n",
    "    \"device\": \"cpu\"\n",
    "}\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "\n",
    "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
    "    env = SimpleTradingEnv(X_train_scaled, X_train, trading_fee)\n",
    "    kwargs.update(sample_ppo_params(trial, env))\n",
    "    \n",
    "    \n",
    "    model = PPO(**kwargs)\n",
    "    # Create env used for evaluation\n",
    "    eval_env = Monitor(SimpleTradingEnv(X_train_scaled, X_train, trading_fee))\n",
    "    # Create the callback that will periodically evaluate\n",
    "    # and report the performance\n",
    "    eval_callback = TrialEvalCallback(\n",
    "        eval_env, trial, n_eval_episodes=N_EVAL_EPISODES, eval_freq=EVAL_FREQ, deterministic=True\n",
    "    )\n",
    "\n",
    "    nan_encountered = False\n",
    "    try:\n",
    "        model.learn(N_TIMESTEPS, callback=eval_callback)\n",
    "    except AssertionError as e:\n",
    "        # Sometimes, random hyperparams can generate NaN\n",
    "        print(e)\n",
    "        nan_encountered = True\n",
    "    finally:\n",
    "        # Free memory\n",
    "        model.env.close()\n",
    "        eval_env.close()\n",
    "\n",
    "    # Tell the optimizer that the trial failed\n",
    "    if nan_encountered:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    if eval_callback.is_pruned:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return eval_callback.last_mean_reward\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    tensorboard_callback = TensorBoardCallback(\"logs/optuna/\", metric_name=\"accuracy\")\n",
    "    # Set pytorch num threads to 1 for faster training\n",
    "    torch.set_num_threads(1)\n",
    "\n",
    "    sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
    "    # Do not prune before 1/3 of the max budget is used\n",
    "    pruner = MedianPruner(n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3)\n",
    "\n",
    "    study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
    "    try:\n",
    "        study.optimize(objective, n_trials=N_TRIALS, n_jobs=N_JOBS, timeout=600)\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    print(\"  User attrs:\")\n",
    "    for key, value in trial.user_attrs.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TensorTrade.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
